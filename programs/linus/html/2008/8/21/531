    </div></td><td width="32">Â </td></tr><tr><td valign="top"><div class="es-jasper-simpleCalendar" baseurl="/lkml/"></div><div class="threadlist">Messages in this thread</div><ul class="threadlist"><li class="root"><a href="/lkml/2008/8/16/49">First message in thread</a></li><li><a href="/lkml/2008/8/21/495">Linus Torvalds</a><ul><li><a href="/lkml/2008/8/21/505">Linus Torvalds</a><ul><li class="origin"><a href="">Linus Torvalds</a></li><li><a href="/lkml/2008/8/23/3">Mathieu Desnoyers</a><ul><li><a href="/lkml/2008/8/23/97">Linus Torvalds</a><ul><li><a href="/lkml/2008/8/23/170">Mathieu Desnoyers</a></li></ul></li></ul></li></ul></li><li><a href="/lkml/2008/8/21/513">"H. Peter Anvin"</a><ul><li><a href="/lkml/2008/8/21/516">Linus Torvalds</a></li></ul></li></ul></li></ul></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerl.gif" width="32" height="32" alt="/" /></td><td class="c" rowspan="2" valign="top" style="padding-top: 1em"><table><tr><td colspan="2"><!--BuySellAds Zone Code--><div id="bsap_1297613" class="bsarocks bsap_5aa49c00cc06c882289a1dd6a5e50b62"></div><!--End BuySellAds Zone Code--></td></tr><tr><td><table><tr><td class="lp">Date</td><td class="rp" itemprop="datePublished">Thu, 21 Aug 2008 15:22:56 -0700 (PDT)</td></tr><tr><td class="lp">From</td><td class="rp" itemprop="author">Linus Torvalds &lt;&gt;</td></tr><tr><td class="lp">Subject</td><td class="rp" itemprop="name">Re: [RFC PATCH] Writer-biased low-latency rwlock v8</td></tr></table></td><td><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></td></tr></table><pre itemprop="articleBody"><br /><br />On Thu, 21 Aug 2008, Linus Torvalds wrote:<br />&gt; <br />&gt;  rdlock:<br />&gt; 	movl $4,%eax<br />&gt; 	lock ; xaddl %eax,(%rdi)<br />&gt; 	testl $3,%eax<br />&gt; 	jne __rdlock_slowpath<br />&gt; 	ret<br /><br /><br />Ok, so change that "testl" to "andl" to shave two bytes, and then make the <br />whole lock structure look something like this:<br /><br />	struct rwlock {<br />		u32 fastpath;<br />		u32 pending_readers;<br />		u32 pending_writers;<br />	};<br /><br />and then the slowpath would look something like this:<br /><br />	void __rdlock_slowpath(struct rwlock *lock)<br />	{<br />		/* Move the read count to the pending path and undo our xadd */<br />		atomic_add(1, &amp;lock-&gt;pending_readers);<br />		atomic_sub(4, &amp;lock-&gt;fastpath);<br /><br />		for (;;) {<br />			unsigned fastpath;<br />			while (lock-&gt;pending_writers)<br />				cpu_relax();<br />			while ((fastpath = lock-&gt;fastpath) &amp; 1)<br />				cpu_relax();<br />			/* This will also undo the contention bit */<br />			if (atomic_cmpxchg(&amp;lock-&gt;fastpath, fastpath, (fastpath &amp; ~2)+4)) == fastpath);<br />				break;<br />		}<br />		atomic_sub(1, &amp;lock-&gt;pending_readers);<br />	}<br /><br />and yes, there are more atomic accesses in there than would be necessary, <br />in that if you can cram the whole thing into a single 64-bit word you can <br />do both the initial pending fixup and the final cmpxchg/pending_readers <br />thing as a single locked 64-bit op, but hey, the above is fairly simple.<br /><br />You could also just use a spinlock to protect all the other data, of <br />course.<br /><br />There are fairness issues here too - do you really want to wait for <br />pending writes every time, or just the first time through the loop? It <br />depends on just how much you want to prefer writers.<br /><br />The slow-paths for writers is similar, and has similar issues for the <br />fairness issue. For example, instead of a simple "pending_writers" count, <br />maybe you want to use a ticket lock there, to make writers be fair among <br />themselves? Of course, the hope would be that there would never be that <br />kind of contention by pure writers, so that sounds like overdesign, but <br />the thing I'm trying to point out here is that this is all a separate <br />decision from the actual fast-path, and having fair writers doesn't <br />necessarily mean that the fastpath has to even know/care.<br /><br />The placement of the counts is also something that can be optimized. For <br />example, on teh assumption that readers are much more common than writers, <br />I put the "pending_readers" next to the "fastpath" lock, exactly so that <br />you -can- do the update of both with a single 64-bit locked access, even <br />if the fastpath just used a 32-bit one. But then you should at least add a <br />"__attribute__((aligned(8)))" to the structure definition.<br /><br />And maybe you want to share the slowpath between all the irq-off etc <br />versions, in which case you need to make the "irq enable while waiting" <br />thing be conditional. <br /><br />And if the write path wants to wait for pending readers, and you want to <br />make _that_ fair too, then you want to have that punch through if the <br />writer is in an interrupt, to avoid deadlocks. And again, you might want <br />to make the reader thing be some kind of ticket-based system, so that <br />writers can wait for the readers that came in _before_ that writer, but <br />not to later ones.<br /><br />But again - none of that has anything to do with the fast-path. The <br />fast-path remains exactly the same for all these issues.<br /><br />And finally: NONE of the code is at all tested. It's all just written in <br />my MUA. Caveat emptor.<br /><br />			Linus<br /><br /><br /></pre><div align="center"><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></div></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerr.gif" width="32" height="32" alt="\" /></td></tr><tr><td align="right" valign="bottom">
