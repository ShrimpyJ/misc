    </div></td><td width="32">Â </td></tr><tr><td valign="top"><div class="es-jasper-simpleCalendar" baseurl="/lkml/"></div><div class="threadlist">Messages in this thread</div><ul class="threadlist"><li class="root"><a href="/lkml/2008/8/7/270">First message in thread</a></li><li><a href="/lkml/2008/8/8/523">Steven Rostedt</a><ul><li><a href="/lkml/2008/8/13/28">Mathieu Desnoyers</a><ul><li><a href="/lkml/2008/8/13/253">Mathieu Desnoyers</a></li></ul></li><li><a href="/lkml/2008/8/13/317">Mathieu Desnoyers</a><ul><li class="origin"><a href="/lkml/2008/8/13/347">Linus Torvalds</a><ul><li><a href="/lkml/2008/8/13/347">Andi Kleen</a><ul><li><a href="/lkml/2008/8/13/353">Avi Kivity</a></li><li><a href="/lkml/2008/8/13/371">Mathieu Desnoyers</a></li></ul></li><li><a href="/lkml/2008/8/13/364">Mathieu Desnoyers</a></li></ul></li></ul></li></ul></li></ul></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerl.gif" width="32" height="32" alt="/" /></td><td class="c" rowspan="2" valign="top" style="padding-top: 1em"><table><tr><td colspan="2"><!--BuySellAds Zone Code--><div id="bsap_1297613" class="bsarocks bsap_5aa49c00cc06c882289a1dd6a5e50b62"></div><!--End BuySellAds Zone Code--></td></tr><tr><td><table><tr><td class="lp">Date</td><td class="rp" itemprop="datePublished">Wed, 13 Aug 2008 11:27:14 -0700 (PDT)</td></tr><tr><td class="lp">From</td><td class="rp" itemprop="author">Linus Torvalds &lt;&gt;</td></tr><tr><td class="lp">Subject</td><td class="rp" itemprop="name">Re: Efficient x86 and x86_64 NOP microbenchmarks</td></tr></table></td><td><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></td></tr></table><pre itemprop="articleBody"><br /><br />On Wed, 13 Aug 2008, Mathieu Desnoyers wrote:<br />&gt; <br />&gt; I also did some microbenchmarks on my Intel Xeon 64 bits, AMD64 and<br />&gt; Intel Pentium 4 boxes to compare a baseline<br /><br />Note that the biggest problems of a jump-based nop are likely to happen <br />when there are I$ misses and/or when there are other jumps involved. Ie a <br />some microarchitectures tend to have issues with jumps to jumps, or when <br />there are multiple control changes in the same (possibly partial) <br />cacheline because the instruction stream prediction may be predecoded in <br />the L1 I$, and multiple branches in the same cacheline - or in the same <br />execution cycle - can pollute that kind of thing.<br /><br />So microbenchmarking this way will probably make some things look <br />unrealistically good. <br /><br />On the P4, the trace cache makes things even more interesting, since it's <br />another level of I$ entirely, with very different behavior for the hit <br />case vs the miss case.<br /><br />And I$ misses for the kernel are actually fairly high. Not in <br />microbenchmarks that tend to have very repetive behavior and a small I$ <br />footprint, but in a lot of real-life loads the *bulk* of all action is in <br />user space, and then the kernel side is often invoced with few loops (the <br />kernel has very few loops indeed) and a cold I$.<br /><br />So your numbers are interesting, but it would be really good to also get <br />some info from Intel/AMD who may know about microarchitectural issues for <br />the cases that don't show up in the hot-I$-cache environment.<br /><br />			Linus<br /><br /><br /></pre><div align="center"><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></div></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerr.gif" width="32" height="32" alt="\" /></td></tr><tr><td align="right" valign="bottom">
