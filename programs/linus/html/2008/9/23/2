    </div></td><td width="32">Â </td></tr><tr><td valign="top"><div class="es-jasper-simpleCalendar" baseurl="/lkml/"></div><div class="threadlist">Messages in this thread</div><ul class="threadlist"><li class="root"><a href="/lkml/2008/9/19/275">First message in thread</a></li><li><a href="/lkml/2008/9/22/468">Linus Torvalds</a><ul><li><a href="/lkml/2008/9/22/470">Mathieu Desnoyers</a><ul><li class="origin"><a href="">Linus Torvalds</a></li></ul></li><li><a href="/lkml/2008/9/22/471">Steven Rostedt</a><ul><li><a href="/lkml/2008/9/23/3">Masami Hiramatsu</a><ul><li><a href="/lkml/2008/9/23/4">"Martin Bligh"</a><ul><li><a href="/lkml/2008/9/23/209">Masami Hiramatsu</a></li></ul></li><li><a href="/lkml/2008/9/23/89">Steven Rostedt</a></li></ul></li><li><a href="/lkml/2008/9/23/5">Linus Torvalds</a><ul><li><a href="/lkml/2008/9/23/186">Mathieu Desnoyers</a></li></ul></li></ul></li></ul></li></ul></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerl.gif" width="32" height="32" alt="/" /></td><td class="c" rowspan="2" valign="top" style="padding-top: 1em"><table><tr><td colspan="2"><!--BuySellAds Zone Code--><script type="text/javascript" src="//pagead2.googlesyndication.com/pagead/show_ads.js"></script><!--End BuySellAds Zone Code--></td></tr><tr><td><table><tr><td class="lp">Date</td><td class="rp" itemprop="datePublished">Mon, 22 Sep 2008 21:05:20 -0700 (PDT)</td></tr><tr><td class="lp">From</td><td class="rp" itemprop="author">Linus Torvalds &lt;&gt;</td></tr><tr><td class="lp">Subject</td><td class="rp" itemprop="name">Re: Unified tracing buffer</td></tr></table></td><td><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></td></tr></table><pre itemprop="articleBody"><br /><br />On Mon, 22 Sep 2008, Mathieu Desnoyers wrote:<br />&gt; <br />&gt; Unless I am missing something, in the case we use an atomic operation<br />&gt; which implies memory barriers (cmpxchg and atomic_add_return does), one<br />&gt; can be sure that all memory operations done before the barrier are<br />&gt; completed at the barrier and that all memory ops following the barrier<br />&gt; will happen after.<br /><br />Sure (if you have a barrier - not all architectures will imply that for an <br />incrment).<br /><br />But that still doesn't mean a thing.<br /><br />You have two events (a) and (b), and you put trace-points on each. In your <br />trace, you see (a) before (b) by comparing the numbers. But what does that <br />mean? <br /><br />The actual event that you traced is not the trace-point - the trace-point <br />is more like a fancy "printk". And the fact that one showed up before <br />another in the trace buffer, doesn't mean that the events _around_ the <br />trace happened in the same order.<br /><br />You can use the barriers to make a partial ordering, and if you have a <br />separate tracepoint for entry into a region and exit, you can perhaps show <br />that they were totally disjoint. Or maybe they were partially overlapping, <br />and you'll never know exactly how they overlapped.<br /><br />Example:<br /><br />	trace(..);<br />	do_X();<br /><br />being executed on two different CPU's. In the trace, CPU#1 was before <br />CPU#2. Does that mean that "do_X()" happened first on CPU#1?<br /><br />No.<br /><br />The only way to show that would be to put a lock around the whole trace <br />_and_ operation X, ie<br /><br />	spin_lock(..);<br />	trace(..);<br />	do_X();<br />	spin_unlock(..);<br /><br />and now, if CPU#1 shows up in the trace first, then you know that do_X() <br />really did happen first on CPU#1. Otherwise you basically know *nothing*, <br />and the ordering of the trace events was totally and utterly meaningless.<br /><br />See? Trace events themselves may be ordered, but the point of the trace <br />event is never to know the ordering of the trace itself - it's to know the <br />ordering of the code we're interested in tracing. The ordering of the <br />trace events themselves is irrelevant and not useful.<br /><br />And I'd rather see people _understand_ that, than if they think the <br />ordering is somehow something they can trust.<br /><br />Btw, if you _do_ have locking, then you can also know that the "do_X()" <br />operations will be essentially as far apart in some theoretical notion of <br />"time" (let's imagine that we do have global time, even if we don't) as <br />the cost of the trace operation and do_X() itself.<br /><br />So if we _do_ have locking (and thus a valid ordering that actually can <br />matter), then the TSC doesn't even have to be synchronized on a cycle <br />basis across CPU's - it just needs to be close enough that you can tell <br />which one happened first (and with ordering, that's a valid thing to do). <br /><br />So you don't even need "perfect" synchronization, you just need something <br />reasonably close, and you'll be able to see ordering from TSC counts <br />without having that horrible bouncing cross-CPU thing that will impact <br />performance a lot.<br /><br />Quite frankly, I suspect that anybody who wants to have a global counter <br />might as well almost just have a global ring-buffer. The trace events <br />aren't going to be CPU-local anyway if you need to always update a shared <br />cacheline - and you might as well make the shared cacheline be the ring <br />buffer head with a spinlock in it.<br /><br />That may not be _quite_ true, but it's probably close enough.<br /><br />		Linus<br /><br /><br /></pre><div align="center"><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></div></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerr.gif" width="32" height="32" alt="\" /></td></tr><tr><td align="right" valign="bottom">
