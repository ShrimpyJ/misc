    </div></td><td width="32">Â </td></tr><tr><td valign="top"><div class="es-jasper-simpleCalendar" baseurl="/lkml/"></div><div class="threadlist">Messages in this thread</div><ul class="threadlist"><li class="root"><a href="/lkml/2008/10/17/465">First message in thread</a></li><li><a href="/lkml/2008/10/17/530">Paul Mackerras</a><ul><li><a href="/lkml/2008/10/17/527">Linus Torvalds</a></li><li><a href="/lkml/2008/10/18/12">Nick Piggin</a><ul><li><a href="/lkml/2008/10/18/45">Paul Mackerras</a></li><li class="origin"><a href="/lkml/2008/10/18/101">Linus Torvalds</a><ul><li><a href="/lkml/2008/10/18/101">Matthew Wilcox</a><ul><li><a href="/lkml/2008/10/18/222">Nick Piggin</a></li></ul></li><li><a href="/lkml/2008/10/18/221">Nick Piggin</a></li></ul></li></ul></li></ul></li></ul></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerl.gif" width="32" height="32" alt="/" /></td><td class="c" rowspan="2" valign="top" style="padding-top: 1em"><table><tr><td colspan="2"><!--BuySellAds Zone Code--><script type="text/javascript" src="//pagead2.googlesyndication.com/pagead/show_ads.js"></script><!--End BuySellAds Zone Code--></td></tr><tr><td><table><tr><td class="lp">Date</td><td class="rp" itemprop="datePublished">Sat, 18 Oct 2008 10:00:30 -0700 (PDT)</td></tr><tr><td class="lp">From</td><td class="rp" itemprop="author">Linus Torvalds &lt;&gt;</td></tr><tr><td class="lp">Subject</td><td class="rp" itemprop="name">Re: [patch] mm: fix anon_vma races</td></tr></table></td><td><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></td></tr></table><pre itemprop="articleBody"><br /><br />On Sat, 18 Oct 2008, Nick Piggin wrote:<br />&gt; <br />&gt; I think it can be called transitive. Basically (assumememory starts off zeroed)<br /><br />Alpha is transitive. It has a notion of "processor issue order" and <br />"location access order", and the ordering those two creates is a <br />transitive "before" and "after" ordering.<br /><br />The issue with alpha is not that it wouldn't be transitive - the issue is <br />that *local* read dependencies do not cause a "processor issue order"!<br /><br />So the real issue with alpha is not about any big pair-wise ordering vs <br />transitive thing, the big issue is that alpha's totally _local_ and <br />per-core orderings are so totally screwed up, and are defined to be very <br />loose - because back when alpha was designed, loose memory ordering was <br />thought to be a good thing for performance.<br /><br />They were wrong, but that was mainly because the alpha designers lived in <br />a time when threading wasn't really even an issue. They were optimizing <br />purely for the case where memory ordering doesn't matter, and considered <br />locking etc to be one of those non-RISCy rare operations that can be <br />basically ignored.<br /><br />&gt; CPU0<br />&gt; x := 1<br /><br />So this creates a "location access" event on 'x' on alpha, call it "event <br />A".<br /><br />&gt; CPU1<br />&gt; if (x == 1) {<br />&gt;   fence<br />&gt;   y := 1<br />&gt; }<br /><br />This has two events: let's call the read of 'x' "B", and "C" is the write <br />to 'y'.<br /><br />And according to the alpha rules, we now have:<br /><br /> - A &lt;&lt; B<br /><br />   Because we saw a '1' in B, we now have a "location access ordering" <br />   on the _same_ variable between A and B.<br /><br /> - B &lt; C<br /><br />   Because we have the fence in between the read and the write, we now <br />   have a "processor issue order" between B and C (despite the fact that <br />   they are different variables).<br /><br />And now, the alpha definition of "before" means that we can declare that A <br />is before C.<br /><br />But on alpha, we really do need that fence, even if the address of 'y' was <br />somehow directly data-dependent on 'x'. THAT is what makes alpha special, <br />not any odd ordering rules.<br /><br />&gt; CPU2<br />&gt; if (y == 1) {<br />&gt;   fence<br />&gt;   assert(x == 1)<br />&gt; }<br /><br />So again, we now have two events: the access of 'y' is "D", and the access <br />of x is "E". And again, according to the alpha rules, we have two <br />orderings:<br /><br /> - C &lt;&lt; D<br /><br />   Because we saw a '1' in D, we have another "location access ordering" <br />   on the variably 'y' between C and D.<br /><br /> - D &lt; E<br /><br />   Because of the fence, we have a "processor issue ordering" between D <br />   and E.<br /><br />And for the same reason as above, we now get that C is "before" E <br />according to the alpha ordering rules. And because the definition of <br />"before" is transitive, then A is before E.<br /><br />And that, in turn, means that that assert() can never trigger, because if <br />it triggered, then by the access ordering rules that would imply that E &lt;&lt; <br />A, which would mean that E is "before" A, which in turn would violate the <br />whole chain we just got to.<br /><br />So while the alpha architecture manual doesn't have the exact sequence <br />mentioned above (it only has nine so-called "Litmus tests"), it's fairly <br />close to Litmus test 3, and the ordering on alpha is very clear: it's all <br />transitive and causal (ie "before" can never be "after").<br /><br />&gt; Apparently pairwise ordering is more interesting than just a theoretical<br />&gt; thing, and not just restricted to Alpha's funny caches.<br /><br />Nobody does just pairwise ordering, afaik. It's an insane model. Everybody <br />does some form of transitive ordering.<br /><br />The real (and only really odd) issue with alpha is that for everybody <br />else, if you have<br /><br />	read x -&gt; data dependency -&gt; read y<br /><br />(ie you read a pointer and dereference it, or you read an index and <br />dereference an array through it), then on all other architectures that <br />will imply a local processor ordering, which in turn will be part of the <br />whole transitive order of operations. <br /><br />On alpha, it doesn't. You can think of it as alpha doing value speculation <br />(ie allowing speculative reads even across data dependencies), so on <br />alpha, you could imagine a CPU doing address speculation, and turning the <br />two reads into a sequence of<br /><br /> (a) read off speculative pointer '*p'<br /> (b) read x<br /> (c) verify that that x == p<br /><br />and THAT is what "smp_read_barrier_depends()" will basically stop on <br />alpha. Nothing else. Other CPU's will always basically do<br /><br /> (a) read x<br /> (b) read *x<br /><br />so they have an implied read barrier between those two events thanks to <br />simply the causal relationship.<br /><br />Some more notes:<br /><br /> - The reason that alpha has this odd thing is not actually that any alpha <br />   implementation does value speculation, but the way the caches are <br />   invalidated, the invalidates can be delayed and re-ordered almost <br />   arbitrarily on the local CPU, and in the absense of a memory barrier <br />   the second read (that does happen "after" the first read in some local <br />   internal CPU sense and wasn't really speculative in that way) can get <br />   stale data because one cacheline has been updated before another one <br />   has.<br /><br />   So while you can think of it a value speculation, the underlying cause <br />   is actually not some fancy speculation infrastructure, just an internal <br />   implementation issue.<br /><br /> - The _data_ dependency is important, because other architectures _will_ <br />   still speculatively move memory operations around across other "causal" <br />   relationships, notably across control dependencies. IOW, if you have<br /><br />	if (read(x))<br />		read(y)<br /><br />   then there is NOT necessarily any real orderign between the reads, <br />   because the conditional ends up being speculated, and you may well see <br />   "y" being read before "x", and you really need a smp_rmb() on other <br />   architectures than alpha too. So in this sense, alpha is very <br />   "consistent" - for alpha, _no_ amount of local causality matters, and <br />   only accesses to the *same* variable are implicitly locally ordered.<br /><br /> - On x86, the new memory ordering semantics means that _all_ local causal <br />   relationships are honored, so x86, like alpha, is very consistent. It <br />   will consider both the data-dependency and the control dependency to be <br />   100% the same. It just does it differently than alpha: for alpha, <br />   neither matters for ordering, for x86, both matter.<br /><br />Of course, even on x86, the local causal relationships still do allow <br />loads to pass stores, so x86 isn't _totally_ ordered. x86 obviously still <br />does need the smp_mb().<br /><br />So alpha is "more consistent" in the respect of really having very clear <br />rules. The fact that those "clear rules" are totally insane and very <br />inconvenient for threading (and weren't the big performance advantage that <br />people used to think they would be) is a separate matter.<br /><br />		Linus<br /><br /><br /></pre><div align="center"><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></div></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerr.gif" width="32" height="32" alt="\" /></td></tr><tr><td align="right" valign="bottom">
