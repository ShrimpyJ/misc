    </div></td><td width="32">Â </td></tr><tr><td valign="top"><div class="es-jasper-simpleCalendar" baseurl="/lkml/"></div><div class="threadlist">Messages in this thread</div><ul class="threadlist"><li class="root"><a href="/lkml/2010/8/20/443">First message in thread</a></li><li class="origin"><a href="/lkml/2010/8/20/447">Linus Torvalds</a><ul><li><a href="/lkml/2010/8/20/447">Mike Snitzer</a><ul><li><a href="/lkml/2010/8/20/454">Linus Torvalds</a></li></ul></li><li><a href="/lkml/2010/8/21/58">Ian Campbell</a><ul><li><a href="/lkml/2010/8/21/88">Linus Torvalds</a><ul><li><a href="/lkml/2010/8/21/90">Sam Ravnborg</a><ul><li><a href="/lkml/2010/8/23/265">Tony Luck</a></li></ul></li><li><a href="/lkml/2010/8/22/10">Ian Campbell</a><ul><li><a href="/lkml/2010/8/22/13">Ian Campbell</a></li></ul></li></ul></li></ul></li><li><a href="/lkml/2010/8/23/74">Peter Zijlstra</a></li></ul></li></ul><div class="threadlist">Patches in this message</div><ul class="threadlist"><li><a href="/lkml/diff/2010/8/20/443/1">Get diff 1</a></li><li><a href="/lkml/diff/2010/8/20/443/2">Get diff 2</a></li><li><a href="/lkml/diff/2010/8/20/443/3">Get diff 3</a></li></ul></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerl.gif" width="32" height="32" alt="/" /></td><td class="c" rowspan="2" valign="top" style="padding-top: 1em"><table><tr><td colspan="2"><!--BuySellAds Zone Code--><div id="bsap_1297613" class="bsarocks bsap_5aa49c00cc06c882289a1dd6a5e50b62"></div><!--End BuySellAds Zone Code--></td></tr><tr><td><table><tr><td class="lp">From</td><td class="rp" itemprop="author">Linus Torvalds &lt;&gt;</td></tr><tr><td class="lp">Date</td><td class="rp" itemprop="datePublished">Fri, 20 Aug 2010 16:59:55 -0700</td></tr><tr><td class="lp">Subject</td><td class="rp" itemprop="name">[RFC] mlock/stack guard interaction fixup</td></tr></table></td><td><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></td></tr></table><pre itemprop="articleBody">Ian (and others),<br /> here's a three-patch series that uses the doubly linked list to do<br />your mlock() case hopefully correctly.<br /><br />NOTE! It's untested. The first patch (which is the slightly scary one)<br />is tested to some degree, the two other ones I checked that they<br />compile, but that's it.<br /><br />I'm not going to apply them to my main tree unless they get testing<br />and acks. And as mentioned, I've not done any of the changes that<br />having a vm_prev pointer can allow in other places.<br /><br />Comments? Fixes? Braindamage?<br /><br />                               Linus<br />From 66fdf00aad2cf539a66916946ea6fc413c30c805 Mon Sep 17 00:00:00 2001<br />From: Linus Torvalds &lt;torvalds&#64;linux-foundation.org&gt;<br />Date: Fri, 20 Aug 2010 16:24:55 -0700<br />Subject: [PATCH 1/3] mm: make the vma list be doubly linked<br /><br />It's a really simple list, and several of the users want to go backwards<br />in it to find the previous vma.  So rather than have to look up the<br />previous entry with 'find_vma_prev()' or something similar, just make it<br />doubly linked instead.<br /><br />Signed-off-by: Linus Torvalds &lt;torvalds&#64;linux-foundation.org&gt;<br />---<br /> include/linux/mm_types.h |    2 +-<br /> kernel/fork.c            |    7 +++++--<br /> mm/mmap.c                |   21 +++++++++++++++++----<br /> mm/nommu.c               |    7 +++++--<br /> 4 files changed, 28 insertions(+), 9 deletions(-)<br /><br />diff --git a/include/linux/mm_types.h b/include/linux/mm_types.h<br />index b8bb9a6..ee7e258 100644<br />--- a/include/linux/mm_types.h<br />+++ b/include/linux/mm_types.h<br />&#64;&#64; -134,7 +134,7 &#64;&#64; struct vm_area_struct {<br /> 					   within vm_mm. */<br /> <br /> 	/* linked list of VM areas per task, sorted by address */<br />-	struct vm_area_struct *vm_next;<br />+	struct vm_area_struct *vm_next, *vm_prev;<br /> <br /> 	pgprot_t vm_page_prot;		/* Access permissions of this VMA. */<br /> 	unsigned long vm_flags;		/* Flags, see mm.h. */<br />diff --git a/kernel/fork.c b/kernel/fork.c<br />index 856eac3..b7e9d60 100644<br />--- a/kernel/fork.c<br />+++ b/kernel/fork.c<br />&#64;&#64; -300,7 +300,7 &#64;&#64; out:<br /> #ifdef CONFIG_MMU<br /> static int dup_mmap(struct mm_struct *mm, struct mm_struct *oldmm)<br /> {<br />-	struct vm_area_struct *mpnt, *tmp, **pprev;<br />+	struct vm_area_struct *mpnt, *tmp, *prev, **pprev;<br /> 	struct rb_node **rb_link, *rb_parent;<br /> 	int retval;<br /> 	unsigned long charge;<br />&#64;&#64; -328,6 +328,7 &#64;&#64; static int dup_mmap(struct mm_struct *mm, struct mm_struct *oldmm)<br /> 	if (retval)<br /> 		goto out;<br /> <br />+	prev = NULL;<br /> 	for (mpnt = oldmm-&gt;mmap; mpnt; mpnt = mpnt-&gt;vm_next) {<br /> 		struct file *file;<br /> <br />&#64;&#64; -359,7 +360,7 &#64;&#64; static int dup_mmap(struct mm_struct *mm, struct mm_struct *oldmm)<br /> 			goto fail_nomem_anon_vma_fork;<br /> 		tmp-&gt;vm_flags &amp;= ~VM_LOCKED;<br /> 		tmp-&gt;vm_mm = mm;<br />-		tmp-&gt;vm_next = NULL;<br />+		tmp-&gt;vm_next = tmp-&gt;vm_prev = NULL;<br /> 		file = tmp-&gt;vm_file;<br /> 		if (file) {<br /> 			struct inode *inode = file-&gt;f_path.dentry-&gt;d_inode;<br />&#64;&#64; -392,6 +393,8 &#64;&#64; static int dup_mmap(struct mm_struct *mm, struct mm_struct *oldmm)<br /> 		 */<br /> 		*pprev = tmp;<br /> 		pprev = &amp;tmp-&gt;vm_next;<br />+		tmp-&gt;vm_prev = prev;<br />+		prev = tmp;<br /> <br /> 		__vma_link_rb(mm, tmp, rb_link, rb_parent);<br /> 		rb_link = &amp;tmp-&gt;vm_rb.rb_right;<br />diff --git a/mm/mmap.c b/mm/mmap.c<br />index 3100333..331e51a 100644<br />--- a/mm/mmap.c<br />+++ b/mm/mmap.c<br />&#64;&#64; -388,17 +388,23 &#64;&#64; static inline void<br /> __vma_link_list(struct mm_struct *mm, struct vm_area_struct *vma,<br /> 		struct vm_area_struct *prev, struct rb_node *rb_parent)<br /> {<br />+	struct vm_area_struct *next;<br />+<br />+	vma-&gt;vm_prev = prev;<br /> 	if (prev) {<br />-		vma-&gt;vm_next = prev-&gt;vm_next;<br />+		next = prev-&gt;vm_next;<br /> 		prev-&gt;vm_next = vma;<br /> 	} else {<br /> 		mm-&gt;mmap = vma;<br /> 		if (rb_parent)<br />-			vma-&gt;vm_next = rb_entry(rb_parent,<br />+			next = rb_entry(rb_parent,<br /> 					struct vm_area_struct, vm_rb);<br /> 		else<br />-			vma-&gt;vm_next = NULL;<br />+			next = NULL;<br /> 	}<br />+	vma-&gt;vm_next = next;<br />+	if (next)<br />+		next-&gt;vm_prev = vma;<br /> }<br /> <br /> void __vma_link_rb(struct mm_struct *mm, struct vm_area_struct *vma,<br />&#64;&#64; -483,7 +489,11 &#64;&#64; static inline void<br /> __vma_unlink(struct mm_struct *mm, struct vm_area_struct *vma,<br /> 		struct vm_area_struct *prev)<br /> {<br />-	prev-&gt;vm_next = vma-&gt;vm_next;<br />+	struct vm_area_struct *next = vma-&gt;vm_next;<br />+<br />+	prev-&gt;vm_next = next;<br />+	if (next)<br />+		next-&gt;vm_prev = prev;<br /> 	rb_erase(&amp;vma-&gt;vm_rb, &amp;mm-&gt;mm_rb);<br /> 	if (mm-&gt;mmap_cache == vma)<br /> 		mm-&gt;mmap_cache = prev;<br />&#64;&#64; -1915,6 +1925,7 &#64;&#64; detach_vmas_to_be_unmapped(struct mm_struct *mm, struct vm_area_struct *vma,<br /> 	unsigned long addr;<br /> <br /> 	insertion_point = (prev ? &amp;prev-&gt;vm_next : &amp;mm-&gt;mmap);<br />+	vma-&gt;vm_prev = NULL;<br /> 	do {<br /> 		rb_erase(&amp;vma-&gt;vm_rb, &amp;mm-&gt;mm_rb);<br /> 		mm-&gt;map_count--;<br />&#64;&#64; -1922,6 +1933,8 &#64;&#64; detach_vmas_to_be_unmapped(struct mm_struct *mm, struct vm_area_struct *vma,<br /> 		vma = vma-&gt;vm_next;<br /> 	} while (vma &amp;&amp; vma-&gt;vm_start &lt; end);<br /> 	*insertion_point = vma;<br />+	if (vma)<br />+		vma-&gt;vm_prev = prev;<br /> 	tail_vma-&gt;vm_next = NULL;<br /> 	if (mm-&gt;unmap_area == arch_unmap_area)<br /> 		addr = prev ? prev-&gt;vm_end : mm-&gt;mmap_base;<br />diff --git a/mm/nommu.c b/mm/nommu.c<br />index efa9a38..88ff091 100644<br />--- a/mm/nommu.c<br />+++ b/mm/nommu.c<br />&#64;&#64; -604,7 +604,7 &#64;&#64; static void protect_vma(struct vm_area_struct *vma, unsigned long flags)<br />  */<br /> static void add_vma_to_mm(struct mm_struct *mm, struct vm_area_struct *vma)<br /> {<br />-	struct vm_area_struct *pvma, **pp;<br />+	struct vm_area_struct *pvma, **pp, *next;<br /> 	struct address_space *mapping;<br /> 	struct rb_node **p, *parent;<br /> <br />&#64;&#64; -664,8 +664,11 &#64;&#64; static void add_vma_to_mm(struct mm_struct *mm, struct vm_area_struct *vma)<br /> 			break;<br /> 	}<br /> <br />-	vma-&gt;vm_next = *pp;<br />+	next = *pp;<br /> 	*pp = vma;<br />+	vma-&gt;vm_next = next;<br />+	if (next)<br />+		next-&gt;vm_prev = vma;<br /> }<br /> <br /> /*<br />-- <br />1.7.2.1.97.g3235b<br />From efed7a24a162589f7cae4295ee3eb404d2cc002c Mon Sep 17 00:00:00 2001<br />From: Linus Torvalds &lt;torvalds&#64;linux-foundation.org&gt;<br />Date: Fri, 20 Aug 2010 16:39:25 -0700<br />Subject: [PATCH 2/3] mm: make the mlock() stack guard page checks stricter<br /><br />If we've split the stack vma, only the lowest one has the guard page.<br />Now that we have a doubly linked list of vma's, checking this is trivial.<br /><br />Signed-off-by: Linus Torvalds &lt;torvalds&#64;linux-foundation.org&gt;<br />---<br /> mm/mlock.c |   21 ++++++++++++++++-----<br /> 1 files changed, 16 insertions(+), 5 deletions(-)<br /><br />diff --git a/mm/mlock.c b/mm/mlock.c<br />index 49e5e4c..cbae7c5 100644<br />--- a/mm/mlock.c<br />+++ b/mm/mlock.c<br />&#64;&#64; -135,6 +135,19 &#64;&#64; void munlock_vma_page(struct page *page)<br /> 	}<br /> }<br /> <br />+/* Is the vma a continuation of the stack vma above it? */<br />+static inline int vma_stack_continue(struct vm_area_struct *vma, unsigned long addr)<br />+{<br />+	return vma &amp;&amp; (vma-&gt;vm_end == addr) &amp;&amp; (vma-&gt;vm_flags &amp; VM_GROWSDOWN);<br />+}<br />+<br />+static inline int stack_guard_page(struct vm_area_struct *vma, unsigned long addr)<br />+{<br />+	return (vma-&gt;vm_flags &amp; VM_GROWSDOWN) &amp;&amp;<br />+		(vma-&gt;vm_start == addr) &amp;&amp;<br />+		!vma_stack_continue(vma-&gt;vm_prev, addr);<br />+}<br />+<br /> /**<br />  * __mlock_vma_pages_range() -  mlock a range of pages in the vma.<br />  * &#64;vma:   target vma<br />&#64;&#64; -168,11 +181,9 &#64;&#64; static long __mlock_vma_pages_range(struct vm_area_struct *vma,<br /> 		gup_flags |= FOLL_WRITE;<br /> <br /> 	/* We don't try to access the guard page of a stack vma */<br />-	if (vma-&gt;vm_flags &amp; VM_GROWSDOWN) {<br />-		if (start == vma-&gt;vm_start) {<br />-			start += PAGE_SIZE;<br />-			nr_pages--;<br />-		}<br />+	if (stack_guard_page(vma, start)) {<br />+		addr += PAGE_SIZE;<br />+		nr_pages--;<br /> 	}<br /> <br /> 	while (nr_pages &gt; 0) {<br />-- <br />1.7.2.1.97.g3235b<br />From 3c33e04d225ec295eee4f8fb4e7b78b309c3c0c8 Mon Sep 17 00:00:00 2001<br />From: Linus Torvalds &lt;torvalds&#64;linux-foundation.org&gt;<br />Date: Fri, 20 Aug 2010 16:49:40 -0700<br />Subject: [PATCH 3/3] mm: make stack guard page logic use vm_prev pointer<br /><br />Like the mlock() change previously, this makes the stack guard check<br />code use vma-&gt;vm_prev to see what the mapping below the current stack<br />is, rather than have to look it up with find_vma().<br /><br />Also, accept an abutting stack segment, since that happens naturally if<br />you split the stack with mlock or mprotect.<br /><br />Signed-off-by: Linus Torvalds &lt;torvalds&#64;linux-foundation.org&gt;<br />---<br /> mm/memory.c |   15 +++++++++++----<br /> 1 files changed, 11 insertions(+), 4 deletions(-)<br /><br />diff --git a/mm/memory.c b/mm/memory.c<br />index b6e5fd2..2ed2267 100644<br />--- a/mm/memory.c<br />+++ b/mm/memory.c<br />&#64;&#64; -2770,11 +2770,18 &#64;&#64; static inline int check_stack_guard_page(struct vm_area_struct *vma, unsigned lo<br /> {<br /> 	address &amp;= PAGE_MASK;<br /> 	if ((vma-&gt;vm_flags &amp; VM_GROWSDOWN) &amp;&amp; address == vma-&gt;vm_start) {<br />-		address -= PAGE_SIZE;<br />-		if (find_vma(vma-&gt;vm_mm, address) != vma)<br />-			return -ENOMEM;<br />+		struct vm_area_struct *prev = vma-&gt;vm_prev;<br />+<br />+		/*<br />+		 * Is there a mapping abutting this one below?<br />+		 *<br />+		 * That's only ok if it's the same stack mapping<br />+		 * that has gotten split..<br />+		 */<br />+		if (prev &amp;&amp; prev-&gt;vm_end == address)<br />+			return prev-&gt;vm_flags &amp; VM_GROWSDOWN ? 0 : -ENOMEM;<br /> <br />-		expand_stack(vma, address);<br />+		expand_stack(vma, address - PAGE_SIZE);<br /> 	}<br /> 	return 0;<br /> }<br />-- <br />1.7.2.1.97.g3235b<br /></pre><div align="center"><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></div></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerr.gif" width="32" height="32" alt="\" /></td></tr><tr><td align="right" valign="bottom">
