    </div></td><td width="32">Â </td></tr><tr><td valign="top"><div class="es-jasper-simpleCalendar" baseurl="/lkml/"></div><div class="threadlist">Messages in this thread</div><ul class="threadlist"><li class="root"><a href="/lkml/2010/7/14/204">First message in thread</a></li><li><a href="/lkml/2010/7/14/445">Mathieu Desnoyers</a><ul><li><a href="/lkml/2010/7/14/456">Linus Torvalds</a><ul><li><a href="/lkml/2010/7/14/462">Jeremy Fitzhardinge</a><ul><li><a href="/lkml/2010/7/14/469">Linus Torvalds</a><ul><li><a href="/lkml/2010/7/14/489">Jeremy Fitzhardinge</a></li></ul></li></ul></li><li class="origin"><a href="/lkml/2010/7/14/532">Linus Torvalds</a><ul><li><a href="/lkml/2010/7/14/532">Linus Torvalds</a><ul><li><a href="/lkml/2010/7/15/220">Mathieu Desnoyers</a></li></ul></li><li><a href="/lkml/2010/7/15/181">Mathieu Desnoyers</a><ul><li><a href="/lkml/2010/7/15/183">Linus Torvalds</a></li></ul></li><li><a href="/lkml/2010/7/18/52">Avi Kivity</a><ul><li><a href="/lkml/2010/7/18/89">Linus Torvalds</a></li></ul></li></ul></li></ul></li></ul></li></ul></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerl.gif" width="32" height="32" alt="/" /></td><td class="c" rowspan="2" valign="top" style="padding-top: 1em"><table><tr><td colspan="2"><!--BuySellAds Zone Code--><div id="bsap_1297613" class="bsarocks bsap_5aa49c00cc06c882289a1dd6a5e50b62"></div><!--End BuySellAds Zone Code--></td></tr><tr><td><table><tr><td class="lp">Date</td><td class="rp" itemprop="datePublished">Wed, 14 Jul 2010 18:23:29 -0700</td></tr><tr><td class="lp">Subject</td><td class="rp" itemprop="name">Re: [patch 1/2] x86_64 page fault NMI-safe</td></tr><tr><td class="lp">From</td><td class="rp" itemprop="author">Linus Torvalds &lt;&gt;</td></tr></table></td><td><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></td></tr></table><pre itemprop="articleBody">On Wed, Jul 14, 2010 at 3:37 PM, Linus Torvalds<br />&lt;torvalds&#64;linux-foundation.org&gt; wrote:<br />&gt;<br />&gt; I think the %rip check should be pretty simple - exactly because there<br />&gt; is only a single point where the race is open between that 'mov' and<br />&gt; the 'iret'. So it's simpler than the (similar) thing we do for<br />&gt; debug/nmi stack fixup for sysenter that has to check a range.<br /><br />So this is what I think it might look like, with the %rip in place.<br />And I changed the "nmi_stack_ptr" thing to have both the pointer and a<br />flag - because it turns out that in the single-instruction race case,<br />we actually want the old pointer.<br /><br />Totally untested, of course. But _something_ like this might work:<br /><br />#<br /># Two per-cpu variables: a "are we nested" flag (one byte), and<br /># a "if we're nested, what is the %rsp for the nested case".<br />#<br /># The reason for why we can't just clear the saved-rsp field and<br /># use that as the flag is that we actually want to know the saved<br /># rsp for the special case of having a nested NMI happen on the<br /># final iret of the unnested case.<br />#<br />nmi:<br />	cmpb $0,%__percpu_seg:nmi_stack_nesting<br />	jne nmi_nested_corrupt_and_return<br />	cmpq $nmi_iret_address,0(%rsp)<br />	je nmi_might_be_nested<br />	# create new stack<br />is_unnested_nmi:<br />	# Save some space for nested NMI's. The exception itself<br />	# will never use more space, but it might use less (since<br />	# if will be a kernel-kernel transition). But the nested<br />	# exception will want two save registers and a place to<br />	# save the original CS that it will corrupt<br />	subq $64,%rsp<br /><br />	# copy the five words of stack info. 96 = 64 + stack<br />	# offset of ss.<br />	pushq 96(%rsp)   # ss<br />	pushq 96(%rsp)   # rsp<br />	pushq 96(%rsp)   # eflags<br />	pushq 96(%rsp)   # cs<br />	pushq 96(%rsp)   # rip<br /><br />	# and set the nesting flags<br />	movq %rsp,%__percpu_seg:nmi_stack_ptr<br />	movb $0xff,%__percpu_seg:nmi_stack_nesting<br /><br />regular_nmi_code:<br />	...<br />	# regular NMI code goes here, and can take faults,<br />	# because this sequence now has proper nested-nmi<br />	# handling<br />	...<br />nmi_exit:<br />	movb $0,%__percpu_seg:nmi_stack_nesting<br />nmi_iret_address:<br />	iret<br /><br /># The saved rip points to the final NMI iret, after we've cleared<br /># nmi_stack_ptr. Check the CS segment to make sure.<br />nmi_might_be_nested:<br />	cmpw $__KERNEL_CS,8(%rsp)<br />	jne is_unnested_nmi<br /><br /># This is the case when we hit just as we're supposed to do the final<br /># iret of a previous nmi.  We run the NMI using the old return address<br /># that is still on the stack, rather than copy the new one that is bogus<br /># and points to where the nested NMI interrupted the original NMI<br /># handler!<br /># Easy: just reset the stack pointer to the saved one (this is why<br /># we use a separate "valid" flag, so that we can still use the saved<br /># stack pointer)<br />	movq %__percpu_seg:nmi_stack_ptr,%rsp<br />	jmp regular_nmi_code<br /><br /># This is the actual nested case.  Make sure we fault on iret by setting<br /># CS to zero and saving the old CS.  %rax contains the stack pointer to<br /># the original code.<br />nmi_nested_corrupt_and_return:<br />	pushq %rax<br />	pushq %rdx<br />	movq %__percpu_seg:nmi_stack_ptr,%rax<br />	movq 8(%rax),%rdx	# CS of original NMI<br />	testq %rdx,%rdx		# CS already zero?<br />	je nmi_nested_and_already_corrupted<br />	movq %rdx,40(%rax)	# save old CS away<br />	movq $0,8(%rax)<br />nmi_nested_and_already_corrupted:<br />	popq %rdx<br />	popq %rax<br />	popfq<br />	jmp *(%rsp)<br /><br />Hmm?<br /><br />               Linus<br /><br /><br /></pre><div align="center"><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></div></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerr.gif" width="32" height="32" alt="\" /></td></tr><tr><td align="right" valign="bottom">
