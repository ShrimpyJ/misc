    </div></td><td width="32"> </td></tr><tr><td valign="top"><div class="es-jasper-simpleCalendar" baseurl="/lkml/"></div><div class="threadlist">Messages in this thread</div><ul class="threadlist"><li class="root"><a href="/lkml/2010/7/14/204">First message in thread</a></li><li><a href="/lkml/2010/7/14/222">Linus Torvalds</a><ul><li><a href="/lkml/2010/7/14/233">Mathieu Desnoyers</a><ul><li class="origin"><a href="/lkml/2010/7/14/287">Linus Torvalds</a><ul><li><a href="/lkml/2010/7/14/287">Ingo Molnar</a><ul><li><a href="/lkml/2010/7/14/306">Linus Torvalds</a></li></ul></li><li><a href="/lkml/2010/7/14/380">Mathieu Desnoyers</a><ul><li><a href="/lkml/2010/7/14/417">Linus Torvalds</a></li></ul></li></ul></li></ul></li></ul></li></ul></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerl.gif" width="32" height="32" alt="/" /></td><td class="c" rowspan="2" valign="top" style="padding-top: 1em"><table><tr><td colspan="2"><!--BuySellAds Zone Code--><div id="bsap_1297613" class="bsarocks bsap_5aa49c00cc06c882289a1dd6a5e50b62"></div><!--End BuySellAds Zone Code--></td></tr><tr><td><table><tr><td class="lp">Date</td><td class="rp" itemprop="datePublished">Wed, 14 Jul 2010 11:10:20 -0700</td></tr><tr><td class="lp">Subject</td><td class="rp" itemprop="name">Re: [patch 1/2] x86_64 page fault NMI-safe</td></tr><tr><td class="lp">From</td><td class="rp" itemprop="author">Linus Torvalds &lt;&gt;</td></tr></table></td><td><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></td></tr></table><pre itemprop="articleBody">On Wed, Jul 14, 2010 at 10:06 AM, Mathieu Desnoyers<br />&lt;mathieu.desnoyers&#64;efficios.com&gt; wrote:<br />&gt;&gt;<br />&gt;&gt; This patch (1/2) doesn't look horrible per se. I have no problems with<br />&gt;&gt; it. I just want to understand why it is needed.<br /><br />[ And patch 2/2 is much more intrusive, and touches a critical path<br />too.. If it was just the 1/2 series, I don't think I would care. For<br />the 2/2, I think I'd want to explore all the alternative options ]<br /><br />&gt; The problem originally addressed by this patch is the case where a NMI handler<br />&gt; try to access vmalloc'd per-cpu data, which goes as follow:<br />&gt;<br />&gt; - One CPU does a fork(), which copies the basic kernel mappings.<br />&gt; - Perf allocates percpu memory for buffer control data structures.<br />&gt;  This mapping does not get copied.<br />&gt; - Tracing is activated.<br />&gt; - switch_to() to the newly forked process which missed the new percpu<br />&gt;  allocation.<br />&gt; - We take a NMI, which touches the vmalloc'd percpu memory in the Perf tracing<br />&gt;  handler, therefore leading to a page fault in NMI context. Here, we might be<br />&gt;  in the middle of switch_to(), where -&gt;current might not be in sync with the<br />&gt;  current cr3 register.<br /><br />Ok. I was wondering why anybody would allocate core percpu variables<br />so late that this would ever be an issue, but I guess perf is a<br />reasonable such case. And reasonable to do from NMI.<br /><br />That said - grr. I really wish there was some other alternative than<br />adding yet more complexity to the exception return path. That "iret<br />re-enables NMI's unconditionally" thing annoys me.<br /><br />In fact, I wonder if we couldn't just do a software NMI disable<br />instead? Hav ea per-cpu variable (in the _core_ percpu areas that get<br />allocated statically) that points to the NMI stack frame, and just<br />make the NMI code itself do something like<br /><br /> NMI entry:<br /> - load percpu NMI stack frame pointer<br /> - if non-zero we know we're nested, and should ignore this NMI:<br />    - we're returning to kernel mode, so return immediately by using<br />"popf/ret", which also keeps NMI's disabled in the hardware until the<br />"real" NMI iret happens.<br />    - before the popf/iret, use the NMI stack pointer to make the NMI<br />return stack be invalid and cause a fault<br />  - set the NMI stack pointer to the current stack pointer<br /><br /> NMI exit (not the above "immediate exit because we nested"):<br />   clear the percpu NMI stack pointer<br />   Just do the iret.<br /><br />Now, the thing is, now the "iret" is atomic. If we had a nested NMI,<br />we'll take a fault, and that re-does our "delayed" NMI - and NMI's<br />will stay masked.<br /><br />And if we didn't have a nested NMI, that iret will now unmask NMI's,<br />and everything is happy.<br /><br />Doesn't the above sound like a good solution? In other words, we solve<br />the whole problem by simply _fixing_ the crazy Intel "iret-vs-NMI"<br />semantics. And we don't need to change the hotpath, and we'll just<br />_allow_ nested faults within NMI's.<br /><br />Am I missing something? Maybe I'm not as clever as I think I am... But<br />I _feel_ clever.<br /><br />                   Linus<br />--<br />To unsubscribe from this list: send the line "unsubscribe linux-kernel" in<br />the body of a message to majordomo&#64;vger.kernel.org<br />More majordomo info at  <a href="http://vger.kernel.org/majordomo-info.html">http://vger.kernel.org/majordomo-info.html</a><br />Please read the FAQ at  <a href="http://www.tux.org/lkml/">http://www.tux.org/lkml/</a><br /><br /></pre><div align="center"><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></div></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerr.gif" width="32" height="32" alt="\" /></td></tr><tr><td align="right" valign="bottom">
