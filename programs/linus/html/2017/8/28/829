    </div></td><td width="32">Â </td></tr><tr><td valign="top"><div class="es-jasper-simpleCalendar" baseurl="/lkml/"></div><div class="threadlist">Messages in this thread</div><ul class="threadlist"><li class="root"><a href="/lkml/2017/8/25/542">First message in thread</a></li><li><a href="/lkml/2017/8/26/164">Linus Torvalds</a><ul><li><a href="/lkml/2017/8/27/213">Linus Torvalds</a><ul><li><a href="/lkml/2017/8/27/214">Linus Torvalds</a></li><li><a href="/lkml/2017/8/27/222">Linus Torvalds</a><ul><li><a href="/lkml/2017/8/27/240">Nicholas Piggin</a><ul><li><a href="/lkml/2017/8/27/243">Nicholas Piggin</a></li></ul></li></ul></li></ul></li><li><a href="/lkml/2017/8/28/713">"Liang, Kan"</a><ul><li class="origin"><a href="/lkml/2017/8/28/969">Linus Torvalds</a><ul><li><a href="/lkml/2017/8/28/969">Tim Chen</a></li><li><a href="/lkml/2017/8/29/333">"Liang, Kan"</a><ul><li><a href="/lkml/2017/8/29/473">Linus Torvalds</a></li></ul></li><li><a href="/lkml/2017/8/29/486">Tim Chen</a><ul><li><a href="/lkml/2017/8/29/487">Linus Torvalds</a></li></ul></li></ul></li></ul></li></ul></li></ul><div class="threadlist">Patches in this message</div><ul class="threadlist"><li><a href="/lkml/diff/2017/8/28/829/1">Get diff 1</a></li><li><a href="/lkml/diff/2017/8/28/829/2">Get diff 2</a></li></ul></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerl.gif" width="32" height="32" alt="/" /></td><td class="c" rowspan="2" valign="top" style="padding-top: 1em"><table><tr><td colspan="2"><!--BuySellAds Zone Code--><div id="bsap_1297613" class="bsarocks bsap_5aa49c00cc06c882289a1dd6a5e50b62"></div><!--End BuySellAds Zone Code--></td></tr><tr><td><table><tr><td class="lp">From</td><td class="rp" itemprop="author">Linus Torvalds &lt;&gt;</td></tr><tr><td class="lp">Date</td><td class="rp" itemprop="datePublished">Mon, 28 Aug 2017 09:48:34 -0700</td></tr><tr><td class="lp">Subject</td><td class="rp" itemprop="name">Re: [PATCH 2/2 v2] sched/wait: Introduce lock breaker in wake_up_page_bit</td></tr></table></td><td><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></td></tr></table><pre itemprop="articleBody">On Mon, Aug 28, 2017 at 7:51 AM, Liang, Kan &lt;kan.liang&#64;intel.com&gt; wrote:<br />&gt;<br />&gt; I tried this patch and <a href="https://lkml.org/lkml/2017/8/27/222">https://lkml.org/lkml/2017/8/27/222</a> together.<br />&gt; But they don't fix the issue. I can still get the similar call stack.<br /><br />So the main issue was that I *really* hated Tim's patch #2, and the<br />patch to clean up the page wait queue should now make his patch series<br />much more palatable.<br /><br />Attached is an ALMOST COMPLETELY UNTESTED forward-port of those two<br />patches, now without that nasty WQ_FLAG_ARRIVALS logic, because we now<br />always put the new entries at the end of the waitqueue.<br /><br />The attached patches just apply directly on top of plain 4.13-rc7.<br /><br />That makes patch #2 much more palatable, since it now doesn't need to<br />play games and worry about new arrivals.<br /><br />But note the lack of testing. I've actually booted this and am running<br />these two patches right now, but honestly, you should consider them<br />"untested" simply because I can't trigger the page waiters contention<br />case to begin with.<br /><br />But it's really just Tim's patches, modified for the page waitqueue<br />cleanup which makes patch #2 become much simpler, and now it's<br />palatable: it's just using the same bookmark thing that the normal<br />wakeup uses, no extra hacks.<br /><br />So Tim should look these over, and they should definitely be tested on<br />that load-from-hell that you guys have, but if this set works, at<br />least I'm ok with it now.<br /><br />Tim - did I miss anything? I added a "cpu_relax()" in there between<br />the release lock and irq and re-take it, I'm not convinced it makes<br />any difference, but I wanted to mark that "take a breather" thing.<br /><br />Oh, there's one more case I only realized after the patches: the<br />stupid add_page_wait_queue() code still adds to the head of the list.<br />So technically you need this too:<br /><br />    diff --git a/mm/filemap.c b/mm/filemap.c<br />    index 74123a298f53..598c3be57509 100644<br />    --- a/mm/filemap.c<br />    +++ b/mm/filemap.c<br />    &#64;&#64; -1061,7 +1061,7 &#64;&#64; void add_page_wait_queue(struct page *page,<br />wait_queue_entry_t *waiter)<br />        unsigned long flags;<br /><br />        spin_lock_irqsave(&amp;q-&gt;lock, flags);<br />    -   __add_wait_queue(q, waiter);<br />    +   __add_wait_queue_entry_tail(q, waiter);<br />        SetPageWaiters(page);<br />        spin_unlock_irqrestore(&amp;q-&gt;lock, flags);<br />     }<br /><br />but that only matters if you actually use the cachefiles thing, which<br />I hope/assume you don't.<br /><br />       Linus<br />From 59e4341e041d7aa1f9339a03f876eee566768c84 Mon Sep 17 00:00:00 2001<br />From: Tim Chen &lt;tim.c.chen&#64;linux.intel.com&gt;<br />Date: Fri, 25 Aug 2017 09:13:54 -0700<br />Subject: [PATCH 1/2] sched/wait: Break up long wake list walk<br /><br />We encountered workloads that have very long wake up list on large<br />systems. A waker takes a long time to traverse the entire wake list and<br />execute all the wake functions.<br /><br />We saw page wait list that are up to 3700+ entries long in tests of<br />large 4 and 8 socket systems. It took 0.8 sec to traverse such list<br />during wake up. Any other CPU that contends for the list spin lock will<br />spin for a long time. It is a result of the numa balancing migration of<br />hot pages that are shared by many threads.<br /><br />Multiple CPUs waking are queued up behind the lock, and the last one<br />queued has to wait until all CPUs did all the wakeups.<br /><br />The page wait list is traversed with interrupt disabled, which caused<br />various problems. This was the original cause that triggered the NMI<br />watch dog timer in: <a href="https://patchwork.kernel.org/patch/9800303/">https://patchwork.kernel.org/patch/9800303/</a> . Only<br />extending the NMI watch dog timer there helped.<br /><br />This patch bookmarks the waker's scan position in wake list and break<br />the wake up walk, to allow access to the list before the waker resume<br />its walk down the rest of the wait list. It lowers the interrupt and<br />rescheduling latency.<br /><br />This patch also provides a performance boost when combined with the next<br />patch to break up page wakeup list walk. We saw 22% improvement in the<br />will-it-scale file pread2 test on a Xeon Phi system running 256 threads.<br /><br />[ v2: Merged in Linus' changes to remove the bookmark_wake_function, and<br />  simply access to flags. ]<br /><br />Reported-by: Kan Liang &lt;kan.liang&#64;intel.com&gt;<br />Tested-by: Kan Liang &lt;kan.liang&#64;intel.com&gt;<br />Signed-off-by: Tim Chen &lt;tim.c.chen&#64;linux.intel.com&gt;<br />Signed-off-by: Linus Torvalds &lt;torvalds&#64;linux-foundation.org&gt;<br />---<br /> include/linux/wait.h |  1 +<br /> kernel/sched/wait.c  | 78 ++++++++++++++++++++++++++++++++++++++++++----------<br /> 2 files changed, 64 insertions(+), 15 deletions(-)<br /><br />diff --git a/include/linux/wait.h b/include/linux/wait.h<br />index dc19880c02f5..78401ef02d29 100644<br />--- a/include/linux/wait.h<br />+++ b/include/linux/wait.h<br />&#64;&#64; -18,6 +18,7 &#64;&#64; int default_wake_function(struct wait_queue_entry *wq_entry, unsigned mode, int<br /> /* wait_queue_entry::flags */<br /> #define WQ_FLAG_EXCLUSIVE	0x01<br /> #define WQ_FLAG_WOKEN		0x02<br />+#define WQ_FLAG_BOOKMARK	0x04<br /> <br /> /*<br />  * A single wait-queue entry structure:<br />diff --git a/kernel/sched/wait.c b/kernel/sched/wait.c<br />index d6afed6d0752..70701ef50465 100644<br />--- a/kernel/sched/wait.c<br />+++ b/kernel/sched/wait.c<br />&#64;&#64; -53,6 +53,12 &#64;&#64; void remove_wait_queue(struct wait_queue_head *wq_head, struct wait_queue_entry<br /> }<br /> EXPORT_SYMBOL(remove_wait_queue);<br /> <br />+/*<br />+ * Scan threshold to break wait queue walk.<br />+ * This allows a waker to take a break from holding the<br />+ * wait queue lock during the wait queue walk.<br />+ */<br />+#define WAITQUEUE_WALK_BREAK_CNT 64<br /> <br /> /*<br />  * The core wakeup function. Non-exclusive wakeups (nr_exclusive == 0) just<br />&#64;&#64; -63,18 +69,67 &#64;&#64; EXPORT_SYMBOL(remove_wait_queue);<br />  * started to run but is not in state TASK_RUNNING. try_to_wake_up() returns<br />  * zero in this (rare) case, and we handle it by continuing to scan the queue.<br />  */<br />-static void __wake_up_common(struct wait_queue_head *wq_head, unsigned int mode,<br />-			int nr_exclusive, int wake_flags, void *key)<br />+static int __wake_up_common(struct wait_queue_head *wq_head, unsigned int mode,<br />+			int nr_exclusive, int wake_flags, void *key,<br />+			wait_queue_entry_t *bookmark)<br /> {<br /> 	wait_queue_entry_t *curr, *next;<br />+	int cnt = 0;<br />+<br />+	if (bookmark &amp;&amp; (bookmark-&gt;flags &amp; WQ_FLAG_BOOKMARK)) {<br />+		curr = list_next_entry(bookmark, entry);<br /> <br />-	list_for_each_entry_safe(curr, next, &amp;wq_head-&gt;head, entry) {<br />+		list_del(&amp;bookmark-&gt;entry);<br />+		bookmark-&gt;flags = 0;<br />+	} else<br />+		curr = list_first_entry(&amp;wq_head-&gt;head, wait_queue_entry_t, entry);<br />+<br />+	if (&amp;curr-&gt;entry == &amp;wq_head-&gt;head)<br />+		return nr_exclusive;<br />+<br />+	list_for_each_entry_safe_from(curr, next, &amp;wq_head-&gt;head, entry) {<br /> 		unsigned flags = curr-&gt;flags;<br />-		int ret = curr-&gt;func(curr, mode, wake_flags, key);<br />+		int ret;<br />+<br />+		if (flags &amp; WQ_FLAG_BOOKMARK)<br />+			continue;<br />+<br />+		ret = curr-&gt;func(curr, mode, wake_flags, key);<br /> 		if (ret &lt; 0)<br /> 			break;<br /> 		if (ret &amp;&amp; (flags &amp; WQ_FLAG_EXCLUSIVE) &amp;&amp; !--nr_exclusive)<br /> 			break;<br />+<br />+		if (bookmark &amp;&amp; (++cnt &gt; WAITQUEUE_WALK_BREAK_CNT) &amp;&amp;<br />+				(&amp;next-&gt;entry != &amp;wq_head-&gt;head)) {<br />+			bookmark-&gt;flags = WQ_FLAG_BOOKMARK;<br />+			list_add_tail(&amp;bookmark-&gt;entry, &amp;next-&gt;entry);<br />+			break;<br />+		}<br />+	}<br />+	return nr_exclusive;<br />+}<br />+<br />+static void __wake_up_common_lock(struct wait_queue_head *wq_head, unsigned int mode,<br />+			int nr_exclusive, int wake_flags, void *key)<br />+{<br />+	unsigned long flags;<br />+	wait_queue_entry_t bookmark;<br />+<br />+	bookmark.flags = 0;<br />+	bookmark.private = NULL;<br />+	bookmark.func = NULL;<br />+	INIT_LIST_HEAD(&amp;bookmark.entry);<br />+<br />+	spin_lock_irqsave(&amp;wq_head-&gt;lock, flags);<br />+	nr_exclusive = __wake_up_common(wq_head, mode, nr_exclusive, wake_flags, key, &amp;bookmark);<br />+	spin_unlock_irqrestore(&amp;wq_head-&gt;lock, flags);<br />+<br />+	while (bookmark.flags &amp; WQ_FLAG_BOOKMARK) {<br />+		spin_lock_irqsave(&amp;wq_head-&gt;lock, flags);<br />+		nr_exclusive = __wake_up_common(wq_head, mode, nr_exclusive,<br />+						wake_flags, key, &amp;bookmark);<br />+		spin_unlock_irqrestore(&amp;wq_head-&gt;lock, flags);<br /> 	}<br /> }<br /> <br />&#64;&#64; -91,11 +146,7 &#64;&#64; static void __wake_up_common(struct wait_queue_head *wq_head, unsigned int mode,<br /> void __wake_up(struct wait_queue_head *wq_head, unsigned int mode,<br /> 			int nr_exclusive, void *key)<br /> {<br />-	unsigned long flags;<br />-<br />-	spin_lock_irqsave(&amp;wq_head-&gt;lock, flags);<br />-	__wake_up_common(wq_head, mode, nr_exclusive, 0, key);<br />-	spin_unlock_irqrestore(&amp;wq_head-&gt;lock, flags);<br />+	__wake_up_common_lock(wq_head, mode, nr_exclusive, 0, key);<br /> }<br /> EXPORT_SYMBOL(__wake_up);<br /> <br />&#64;&#64; -104,13 +155,13 &#64;&#64; EXPORT_SYMBOL(__wake_up);<br />  */<br /> void __wake_up_locked(struct wait_queue_head *wq_head, unsigned int mode, int nr)<br /> {<br />-	__wake_up_common(wq_head, mode, nr, 0, NULL);<br />+	__wake_up_common(wq_head, mode, nr, 0, NULL, NULL);<br /> }<br /> EXPORT_SYMBOL_GPL(__wake_up_locked);<br /> <br /> void __wake_up_locked_key(struct wait_queue_head *wq_head, unsigned int mode, void *key)<br /> {<br />-	__wake_up_common(wq_head, mode, 1, 0, key);<br />+	__wake_up_common(wq_head, mode, 1, 0, key, NULL);<br /> }<br /> EXPORT_SYMBOL_GPL(__wake_up_locked_key);<br /> <br />&#64;&#64; -134,7 +185,6 &#64;&#64; EXPORT_SYMBOL_GPL(__wake_up_locked_key);<br /> void __wake_up_sync_key(struct wait_queue_head *wq_head, unsigned int mode,<br /> 			int nr_exclusive, void *key)<br /> {<br />-	unsigned long flags;<br /> 	int wake_flags = 1; /* XXX WF_SYNC */<br /> <br /> 	if (unlikely(!wq_head))<br />&#64;&#64; -143,9 +193,7 &#64;&#64; void __wake_up_sync_key(struct wait_queue_head *wq_head, unsigned int mode,<br /> 	if (unlikely(nr_exclusive != 1))<br /> 		wake_flags = 0;<br /> <br />-	spin_lock_irqsave(&amp;wq_head-&gt;lock, flags);<br />-	__wake_up_common(wq_head, mode, nr_exclusive, wake_flags, key);<br />-	spin_unlock_irqrestore(&amp;wq_head-&gt;lock, flags);<br />+	__wake_up_common_lock(wq_head, mode, nr_exclusive, wake_flags, key);<br /> }<br /> EXPORT_SYMBOL_GPL(__wake_up_sync_key);<br /> <br />-- <br />2.14.0.rc1.2.g4c8247ec3<br />From 6a519e86f2042edcf878463ed19e37dfd774f28b Mon Sep 17 00:00:00 2001<br />From: Tim Chen &lt;tim.c.chen&#64;linux.intel.com&gt;<br />Date: Fri, 25 Aug 2017 09:13:55 -0700<br />Subject: [PATCH 2/2] sched/wait: Introduce wakeup boomark in wake_up_page_bit<br /><br />Now that we have added breaks in the wait queue scan and allow bookmark<br />on scan position, we put this logic in the wake_up_page_bit function.<br /><br />We can have very long page wait list in large system where multiple<br />pages share the same wait list. We break the wake up walk here to allow<br />other cpus a chance to access the list, and not to disable the interrupts<br />when traversing the list for too long.  This reduces the interrupt and<br />rescheduling latency, and excessive page wait queue lock hold time.<br /><br />[ v2: Remove bookmark_wake_function ]<br /><br />Signed-off-by: Tim Chen &lt;tim.c.chen&#64;linux.intel.com&gt;<br />Signed-off-by: Linus Torvalds &lt;torvalds&#64;linux-foundation.org&gt;<br />---<br /> include/linux/wait.h |  2 ++<br /> kernel/sched/wait.c  |  7 +++++++<br /> mm/filemap.c         | 22 +++++++++++++++++++++-<br /> 3 files changed, 30 insertions(+), 1 deletion(-)<br /><br />diff --git a/include/linux/wait.h b/include/linux/wait.h<br />index 78401ef02d29..87c4641023fb 100644<br />--- a/include/linux/wait.h<br />+++ b/include/linux/wait.h<br />&#64;&#64; -185,6 +185,8 &#64;&#64; __remove_wait_queue(struct wait_queue_head *wq_head, struct wait_queue_entry *wq<br /> <br /> void __wake_up(struct wait_queue_head *wq_head, unsigned int mode, int nr, void *key);<br /> void __wake_up_locked_key(struct wait_queue_head *wq_head, unsigned int mode, void *key);<br />+void __wake_up_locked_key_bookmark(struct wait_queue_head *wq_head,<br />+		unsigned int mode, void *key, wait_queue_entry_t *bookmark);<br /> void __wake_up_sync_key(struct wait_queue_head *wq_head, unsigned int mode, int nr, void *key);<br /> void __wake_up_locked(struct wait_queue_head *wq_head, unsigned int mode, int nr);<br /> void __wake_up_sync(struct wait_queue_head *wq_head, unsigned int mode, int nr);<br />diff --git a/kernel/sched/wait.c b/kernel/sched/wait.c<br />index 70701ef50465..98feab7933c7 100644<br />--- a/kernel/sched/wait.c<br />+++ b/kernel/sched/wait.c<br />&#64;&#64; -165,6 +165,13 &#64;&#64; void __wake_up_locked_key(struct wait_queue_head *wq_head, unsigned int mode, vo<br /> }<br /> EXPORT_SYMBOL_GPL(__wake_up_locked_key);<br /> <br />+void __wake_up_locked_key_bookmark(struct wait_queue_head *wq_head,<br />+		unsigned int mode, void *key, wait_queue_entry_t *bookmark)<br />+{<br />+	__wake_up_common(wq_head, mode, 1, 0, key, bookmark);<br />+}<br />+EXPORT_SYMBOL_GPL(__wake_up_locked_key_bookmark);<br />+<br /> /**<br />  * __wake_up_sync_key - wake up threads blocked on a waitqueue.<br />  * &#64;wq_head: the waitqueue<br />diff --git a/mm/filemap.c b/mm/filemap.c<br />index 0b41c8cbeabc..74123a298f53 100644<br />--- a/mm/filemap.c<br />+++ b/mm/filemap.c<br />&#64;&#64; -923,13 +923,33 &#64;&#64; static void wake_up_page_bit(struct page *page, int bit_nr)<br /> 	wait_queue_head_t *q = page_waitqueue(page);<br /> 	struct wait_page_key key;<br /> 	unsigned long flags;<br />+	wait_queue_entry_t bookmark;<br /> <br /> 	key.page = page;<br /> 	key.bit_nr = bit_nr;<br /> 	key.page_match = 0;<br /> <br />+	bookmark.flags = 0;<br />+	bookmark.private = NULL;<br />+	bookmark.func = NULL;<br />+	INIT_LIST_HEAD(&amp;bookmark.entry);<br />+<br /> 	spin_lock_irqsave(&amp;q-&gt;lock, flags);<br />-	__wake_up_locked_key(q, TASK_NORMAL, &amp;key);<br />+	__wake_up_locked_key_bookmark(q, TASK_NORMAL, &amp;key, &amp;bookmark);<br />+<br />+	while (bookmark.flags &amp; WQ_FLAG_BOOKMARK) {<br />+		/*<br />+		 * Take a breather from holding the lock,<br />+		 * allow pages that finish wake up asynchronously<br />+		 * to acquire the lock and remove themselves<br />+		 * from wait queue<br />+		 */<br />+		spin_unlock_irqrestore(&amp;q-&gt;lock, flags);<br />+		cpu_relax();<br />+		spin_lock_irqsave(&amp;q-&gt;lock, flags);<br />+		__wake_up_locked_key_bookmark(q, TASK_NORMAL, &amp;key, &amp;bookmark);<br />+	}<br />+<br /> 	/*<br /> 	 * It is possible for other pages to have collided on the waitqueue<br /> 	 * hash, so in that case check for a page match. That prevents a long-<br />-- <br />2.14.0.rc1.2.g4c8247ec3<br /></pre><div align="center"><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></div></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerr.gif" width="32" height="32" alt="\" /></td></tr><tr><td align="right" valign="bottom">
