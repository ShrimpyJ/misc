    </div></td><td width="32">Â </td></tr><tr><td valign="top"><div class="es-jasper-simpleCalendar" baseurl="/lkml/"></div><div class="threadlist">Messages in this thread</div><ul class="threadlist"><li class="root"><a href="/lkml/2017/8/14/1000">First message in thread</a></li><li><a href="/lkml/2017/8/21/717">"Liang, Kan"</a><ul><li><a href="/lkml/2017/8/22/619">"Liang, Kan"</a><ul><li class="origin"><a href="/lkml/2017/8/22/671">Linus Torvalds</a><ul><li><a href="/lkml/2017/8/22/671">Linus Torvalds</a></li><li><a href="/lkml/2017/8/22/687">Peter Zijlstra</a><ul><li><a href="/lkml/2017/8/22/719">Linus Torvalds</a></li></ul></li><li><a href="/lkml/2017/8/22/693">Peter Zijlstra</a><ul><li><a href="/lkml/2017/8/22/779">Linus Torvalds</a></li></ul></li><li><a href="/lkml/2017/8/22/815">"Liang, Kan"</a><ul><li><a href="/lkml/2017/8/22/843">Linus Torvalds</a></li></ul></li><li><a href="/lkml/2017/8/23/492">Mel Gorman</a></li></ul></li></ul></li></ul></li></ul><div class="threadlist">Patch in this message</div><ul class="threadlist"><li><a href="/lkml/diff/2017/8/22/668/1">Get diff 1</a></li></ul></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerl.gif" width="32" height="32" alt="/" /></td><td class="c" rowspan="2" valign="top" style="padding-top: 1em"><table><tr><td colspan="2"><!--BuySellAds Zone Code--><div id="bsap_1297613" class="bsarocks bsap_5aa49c00cc06c882289a1dd6a5e50b62"></div><!--End BuySellAds Zone Code--></td></tr><tr><td><table><tr><td class="lp">From</td><td class="rp" itemprop="author">Linus Torvalds &lt;&gt;</td></tr><tr><td class="lp">Date</td><td class="rp" itemprop="datePublished">Tue, 22 Aug 2017 11:19:12 -0700</td></tr><tr><td class="lp">Subject</td><td class="rp" itemprop="name">Re: [PATCH 1/2] sched/wait: Break up long wake list walk</td></tr></table></td><td><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></td></tr></table><pre itemprop="articleBody">On Tue, Aug 22, 2017 at 10:23 AM, Liang, Kan &lt;kan.liang&#64;intel.com&gt; wrote:<br />&gt;<br />&gt; Although the patch doesn't trigger watchdog, the spin lock wait time<br />&gt; is not small (0.45s).<br />&gt; It may get worse again on larger systems.<br /><br />Yeah, I don't think Mel's patch is great - because I think we could do<br />so much better.<br /><br />What I like about Mel's patch is that it recognizes that<br />"wait_on_page_locked()" there is special, and replaces it with<br />something else. I think that "something else" is worse than my<br />"yield()" call, though.<br /><br />In particular, it wastes CPU time even in the good case, and the<br />process that will unlock the page may actually be waiting for us to<br />reschedule. It may be CPU bound, but it might well have just been<br />preempted out.<br /><br />So if we do busy loops, I really think we should also make sure that<br />the thing we're waiting for is not preempted.<br /><br />HOWEVER, I'm actually starting to think that there is perhaps<br />something else going on.<br /><br />Let me walk you through my thinking:<br /><br />This is the migration logic:<br /><br /> (a) migration locks the page<br /><br /> (b) migration is supposedly CPU-limited<br /><br /> (c) migration then unlocks the page.<br /><br />Ignore all the details, that's the 10.000 ft view. Right?<br /><br />Now, if the above is right, then I have a question for people:<br /><br />  HOW IN THE HELL DO WE HAVE TIME FOR THOUSANDS OF THREADS TO HIT THAT ONE PAGE?<br /><br />That just sounds really sketchy to me. Even if all those thousands of<br />threads are runnable, we need to schedule into them just to get them<br />to wait on that one page.<br /><br />So that sounds really quite odd when migration is supposed to hold the<br />page lock for a relatively short time and get out. Don't you agree?<br /><br />Which is why I started thinking of what the hell could go on for that<br />long wait-queue to happen.<br /><br />One thing that strikes me is that the way wait_on_page_bit() works is<br />that it will NOT wait until the next bit clearing, it will wait until<br />it actively *sees* the page bit being clear.<br /><br />Now, work with me on that. What's the difference?<br /><br />What we could have is some bad NUMA balancing pattern that actually<br />has a page that everybody touches.<br /><br />And hey, we pretty much know that everybody touches that page, since<br />people get stuck on that wait-queue, right?<br /><br />And since everybody touches it, as a result everybody eventually<br />thinks that page should be migrated to their NUMA node.<br /><br />But for all we know, the migration keeps on failing, because one of<br />the points of that "lock page - try to move - unlock page" is that<br />*TRY* in "try to move". There's a number of things that makes it not<br />actually migrate. Like not being movable, or failing to isolate the<br />page, or whatever.<br /><br />So we could have some situation where we end up locking and unlocking<br />the page over and over again (which admittedly is already a sign of<br />something wrong in the NUMA balancing, but that's a separate issue).<br /><br />And if we get into that situation, where everybody wants that one hot<br />page, what happens to the waiters?<br /><br />One of the thousands of waiters is unlucky (remember, this argument<br />started with the whole "you shouldn't get that many waiters on one<br />single page that isn't even locked for that long"), and goes:<br /><br /> (a) Oh, the page is locked, I will wait for the lock bit to clear<br /><br /> (b) go to sleep<br /><br /> (c) the migration fails, the lock bit is cleared, the waiter is woken<br />up but doesn't get the CPU immediately, and one of the other<br />*thousands* of threads decides to also try to migrate (see above),<br /><br /> (d) the guy waiting for the lock bit to clear will see the page<br />"still" locked (really just "locked again") and continue to wait.<br /><br />In the meantime, one of the other threads happens to be unlucky, also<br />hits the race, and now we have one more thread waiting for that page<br />lock. It keeps getting unlocked, but it also keeps on getting locked,<br />and so the queue can keep growing.<br /><br />See where I'm going here? I think it's really odd how *thousands* of<br />threads can hit that locked window that is supposed to be pretty<br />small. But I think it's much more likely if we have some kind of<br />repeated event going on.<br /><br />So I'm starting to think that part of the problem may be how stupid<br />that "wait_for_page_bit_common()" code is. It really shouldn't wait<br />until it sees that the bit is clear. It could have been cleared and<br />then re-taken.<br /><br />And honestly, we actually have extra code for that "let's go round<br />again". That seems pointless. If the bit has been cleared, we've been<br />woken up, and nothing else would have done so anyway, so if we're not<br />interested in locking, we're simply *done* after we've done the<br />"io_scheduler()".<br /><br />So I propose testing the attached trivial patch. It may not do<br />anything at all. But the existing code is actually doing extra work<br />just to be fragile, in case the scenario above can happen.<br /><br />Comments?<br /><br />                Linus<br /> mm/filemap.c | 12 +++++-------<br /> 1 file changed, 5 insertions(+), 7 deletions(-)<br /><br />diff --git a/mm/filemap.c b/mm/filemap.c<br />index a49702445ce0..75c29a1f90fb 100644<br />--- a/mm/filemap.c<br />+++ b/mm/filemap.c<br />&#64;&#64; -991,13 +991,11 &#64;&#64; static inline int wait_on_page_bit_common(wait_queue_head_t *q,<br /> 			}<br /> 		}<br /> <br />-		if (lock) {<br />-			if (!test_and_set_bit_lock(bit_nr, &amp;page-&gt;flags))<br />-				break;<br />-		} else {<br />-			if (!test_bit(bit_nr, &amp;page-&gt;flags))<br />-				break;<br />-		}<br />+		if (!lock)<br />+			break;<br />+<br />+		if (!test_and_set_bit_lock(bit_nr, &amp;page-&gt;flags))<br />+			break;<br /> 	}<br /> <br /> 	finish_wait(q, wait);</pre><div align="center"><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></div></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerr.gif" width="32" height="32" alt="\" /></td></tr><tr><td align="right" valign="bottom">
