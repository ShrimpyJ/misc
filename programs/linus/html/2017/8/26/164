    </div></td><td width="32">Â </td></tr><tr><td valign="top"><div class="es-jasper-simpleCalendar" baseurl="/lkml/"></div><div class="threadlist">Messages in this thread</div><ul class="threadlist"><li class="root"><a href="/lkml/2017/8/25/542">First message in thread</a></li><li><a href="/lkml/2017/8/25/804">Linus Torvalds</a><ul><li><a href="/lkml/2017/8/25/832">Linus Torvalds</a><ul><li class="origin"><a href="/lkml/2017/8/27/213">Linus Torvalds</a><ul><li><a href="/lkml/2017/8/27/213">Linus Torvalds</a><ul><li><a href="/lkml/2017/8/27/214">Linus Torvalds</a></li><li><a href="/lkml/2017/8/27/222">Linus Torvalds</a></li></ul></li><li><a href="/lkml/2017/8/28/713">"Liang, Kan"</a><ul><li><a href="/lkml/2017/8/28/829">Linus Torvalds</a></li></ul></li></ul></li></ul></li></ul></li></ul><div class="threadlist">Patch in this message</div><ul class="threadlist"><li><a href="/lkml/diff/2017/8/26/164/1">Get diff 1</a></li></ul></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerl.gif" width="32" height="32" alt="/" /></td><td class="c" rowspan="2" valign="top" style="padding-top: 1em"><table><tr><td colspan="2"><!--BuySellAds Zone Code--><div id="bsap_1297613" class="bsarocks bsap_5aa49c00cc06c882289a1dd6a5e50b62"></div><!--End BuySellAds Zone Code--></td></tr><tr><td><table><tr><td class="lp">From</td><td class="rp" itemprop="author">Linus Torvalds &lt;&gt;</td></tr><tr><td class="lp">Date</td><td class="rp" itemprop="datePublished">Sat, 26 Aug 2017 11:15:01 -0700</td></tr><tr><td class="lp">Subject</td><td class="rp" itemprop="name">Re: [PATCH 2/2 v2] sched/wait: Introduce lock breaker in wake_up_page_bit</td></tr></table></td><td><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></td></tr></table><pre itemprop="articleBody">On Fri, Aug 25, 2017 at 7:54 PM, Linus Torvalds<br />&lt;torvalds&#64;linux-foundation.org&gt; wrote:<br />&gt;<br />&gt; Simplify, simplify, simplify.<br /><br />I've now tried three different approaches (I stopped sending broken<br />patches after deciding the first one was unfixable), and they all<br />suck.<br /><br />I was hoping for something lockless to avoid the whole issue with<br />latency over the long list, but anything that has the wait queue entry<br />allocated on the stack needs to synchronize the wakeup due to the<br />stack usage, so once you have lists that are thousands of entries,<br />either you hold the lock for long times (normal wait queues) or take<br />and release them constantly (the swait approach), or you batch things<br />up (Tim's wait-queue patches).<br /><br />Of those three approaches, the batching does seem to be the best of<br />the lot. Allocating non-stack wait entries while waiting for pages<br />seems like a bad idea. We're probably waiting for IO in normal<br />circumstances, possibly because we're low on memory.<br /><br />So I *am* ok with the batching (your patch #1), but I'm *not* ok with<br />the nasty horrible book-keeping to avoid new entries when you batch<br />and release the lock and that allows new entries on the list (your<br />patch #2).<br /><br />That said, I have now stared *way* too much at the page wait code<br />after having unsuccessfully tried to replace that wait-queue with<br />other "clever" approaches (all of which ended up being crap).<br /><br />And I'm starting to see a possible solution, or at least improvement.<br /><br />Let's just assume I take the batching patch. It's not conceptually<br />ugly, it's fairly simple, and there are lots of independent arguments<br />for it (ie latency, but also possible performance from better<br />parallelism).<br /><br />That patch doesn't make any data structures bigger or more<br />complicated, it's just that single "is this a bookmark entry" thing.<br />So that patch just looks fundamentally fine to me, and the only real<br />argument I ever had against it was that I would really really _really_<br />have wanted to root-cause the behavior.<br /><br />So that leaves my fundamental dislike of your other patch.<br /><br />And it turns out that all my looking at the page wait code wasn't<br />entirely unproductive. Yes, I went through three crap approaches<br />before I gave up on rewriting it, but in the meantime I did get way<br />too intimate with looking at that pile of crud.<br /><br />And I think I found the reason why you needed that patch #2 in the first place.<br /><br />Here's what is going on:<br /><br /> - we're going to assume that the problem is all with a single page,<br />not due to hash collisions (as per your earlier reports)<br /><br /> - we also know that the only bit that matters is the PG_locked bit<br /><br /> - that means that the only way to get that "multiple concurrent<br />waker" situation that your patch #2 tries to handle better is because<br />you have multiple people unlocking the page - since that is what<br />causes the wakeups<br /><br /> - that in turn means that you obviously had multiple threads *locking* it too.<br /><br /> - and that means that among those new entries there are lockers<br />coming in in the middle and adding an exclusive entry.<br /><br /> - the exclusive entry already stops the wakeup list walking<br /><br /> - but we add non-exclusive entries TO THE BEGINNING of the page waiters list<br /><br />And I really think that last thing is fundamentally wrong.<br /><br />It's wrong for several reasons:<br /><br /> - because it's unfair: threads that want to lock get put behind<br />threads that just want to see the unlocked state.<br /><br /> - because it's stupid: our non-locking waiters will end up waiting<br />again if the page got locked, so waking up a locker *and* a lot of<br />non-locking waiters will just cause them to go back to sleep anyway<br /><br /> - because it causes us to walk longer lists: we stop walking when we<br />wake up the exclusive waiter, but because we always put the<br />non-exclusive waiters in there first, we always walk the long list of<br />non-exclusive waiters even if we could just stop walking because we<br />woke up an exclusive one.<br /><br />Now the reason we do this seems to be entirely random: for a *normal*<br />wait queue, you really want to always wake up all the non-exclusive<br />waiters, because exclusive waiters are only exclusive wrt each other.<br /><br />But for a page lock, an exclusive waiter really is getting the lock,<br />and the other waiters are going to wait for the lock to clear anyway,<br />so the page wait thing is actually almost exactly the reverse<br />situation. We *could* put exclusive waiters at the beginning of the<br />list instead, and actively try to avoid walking the list at all if we<br />have pending lockers.<br /><br />I'm not doing that, because I think the fair thing to do is to just do<br />things in the order they came in. Plus the code is actually simpler if<br />we just always add to the tail.<br /><br />Now, the other thing to look at is how the wakeup function works. It<br />checks the aliasing information (page and bit number), but then it<br />*also* does:<br /><br />        if (test_bit(key-&gt;bit_nr, &amp;key-&gt;page-&gt;flags))<br />                return 0;<br /><br />basically saying "continue walking if somebody else already got the bit".<br /><br />That's *INSANE*. It's exactly the wrong thing to do. It's basically<br />saying "even if we had an exclusive waiter, let's not wake it up, but<br />do let us continue to walk the list even though the bit we're waiting<br />for to clear is set already".<br /><br />What would be sane is to say "stop walking the list now".. So just do<br />that - by making "negative return from wake function" mean "stop<br />walking".<br /><br />So how about just this fairly trivial patch?<br /><br />In fact, I think this may help even *without* Tim's patch #1. So I<br />think this would be lovely to test on that problem load on its own,<br />and seeing if it makes the wait queues behave better.<br /><br />It might not cut down on the total length of the wait-queue, but it<br />should hopefully cause it to walk it much less. We now hit the<br />exclusive waiters earlier and stop waking things up when we have a new<br />locker thread pending. And when the page ends up being locked again,<br />we stop walking the list entirely, so no unnecessarily traversal.<br /><br />This patch is small and at least minimally works (I'm running it right now).<br /><br />                               Linus<br /> kernel/sched/wait.c |  7 ++++---<br /> mm/filemap.c        | 10 +++++-----<br /> 2 files changed, 9 insertions(+), 8 deletions(-)<br /><br />diff --git a/kernel/sched/wait.c b/kernel/sched/wait.c<br />index 17f11c6b0a9f..d6afed6d0752 100644<br />--- a/kernel/sched/wait.c<br />+++ b/kernel/sched/wait.c<br />&#64;&#64; -70,9 +70,10 &#64;&#64; static void __wake_up_common(struct wait_queue_head *wq_head, unsigned int mode,<br /> <br /> 	list_for_each_entry_safe(curr, next, &amp;wq_head-&gt;head, entry) {<br /> 		unsigned flags = curr-&gt;flags;<br />-<br />-		if (curr-&gt;func(curr, mode, wake_flags, key) &amp;&amp;<br />-				(flags &amp; WQ_FLAG_EXCLUSIVE) &amp;&amp; !--nr_exclusive)<br />+		int ret = curr-&gt;func(curr, mode, wake_flags, key);<br />+		if (ret &lt; 0)<br />+			break;<br />+		if (ret &amp;&amp; (flags &amp; WQ_FLAG_EXCLUSIVE) &amp;&amp; !--nr_exclusive)<br /> 			break;<br /> 	}<br /> }<br />diff --git a/mm/filemap.c b/mm/filemap.c<br />index a49702445ce0..60705b760983 100644<br />--- a/mm/filemap.c<br />+++ b/mm/filemap.c<br />&#64;&#64; -909,8 +909,10 &#64;&#64; static int wake_page_function(wait_queue_entry_t *wait, unsigned mode, int sync,<br /> <br /> 	if (wait_page-&gt;bit_nr != key-&gt;bit_nr)<br /> 		return 0;<br />+<br />+	/* Stop walking if it's locked */<br /> 	if (test_bit(key-&gt;bit_nr, &amp;key-&gt;page-&gt;flags))<br />-		return 0;<br />+		return -1;<br /> <br /> 	return autoremove_wake_function(wait, mode, sync, key);<br /> }<br />&#64;&#64; -964,6 +966,7 &#64;&#64; static inline int wait_on_page_bit_common(wait_queue_head_t *q,<br /> 	int ret = 0;<br /> <br /> 	init_wait(wait);<br />+	wait-&gt;flags = lock ? WQ_FLAG_EXCLUSIVE : 0;<br /> 	wait-&gt;func = wake_page_function;<br /> 	wait_page.page = page;<br /> 	wait_page.bit_nr = bit_nr;<br />&#64;&#64; -972,10 +975,7 &#64;&#64; static inline int wait_on_page_bit_common(wait_queue_head_t *q,<br /> 		spin_lock_irq(&amp;q-&gt;lock);<br /> <br /> 		if (likely(list_empty(&amp;wait-&gt;entry))) {<br />-			if (lock)<br />-				__add_wait_queue_entry_tail_exclusive(q, wait);<br />-			else<br />-				__add_wait_queue(q, wait);<br />+			__add_wait_queue_entry_tail(q, wait);<br /> 			SetPageWaiters(page);<br /> 		}<br /> </pre><div align="center"><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></div></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerr.gif" width="32" height="32" alt="\" /></td></tr><tr><td align="right" valign="bottom">
