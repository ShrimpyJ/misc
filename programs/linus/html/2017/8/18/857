    </div></td><td width="32">Â </td></tr><tr><td valign="top"><div class="es-jasper-simpleCalendar" baseurl="/lkml/"></div><div class="threadlist">Messages in this thread</div><ul class="threadlist"><li class="root"><a href="/lkml/2017/8/14/1000">First message in thread</a></li><li><a href="/lkml/2017/8/18/811">Linus Torvalds</a><ul><li><a href="/lkml/2017/8/18/848">Mel Gorman</a><ul><li class="origin"><a href="/lkml/2017/8/18/887">Linus Torvalds</a><ul><li><a href="/lkml/2017/8/18/887">Andi Kleen</a><ul><li><a href="/lkml/2017/8/18/900">Linus Torvalds</a></li></ul></li><li><a href="/lkml/2017/8/21/709">Mel Gorman</a><ul><li><a href="/lkml/2017/8/21/717">"Liang, Kan"</a></li></ul></li></ul></li></ul></li><li><a href="/lkml/2017/8/18/895">Andi Kleen</a><ul><li><a href="/lkml/2017/8/18/914">Linus Torvalds</a></li></ul></li><li><a href="/lkml/2017/8/18/913">"Liang, Kan"</a><ul><li><a href="/lkml/2017/8/18/916">Linus Torvalds</a></li></ul></li></ul></li></ul><div class="threadlist">Patch in this message</div><ul class="threadlist"><li><a href="/lkml/diff/2017/8/18/857/1">Get diff 1</a></li></ul></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerl.gif" width="32" height="32" alt="/" /></td><td class="c" rowspan="2" valign="top" style="padding-top: 1em"><table><tr><td colspan="2"><!--BuySellAds Zone Code--><div id="bsap_1297613" class="bsarocks bsap_5aa49c00cc06c882289a1dd6a5e50b62"></div><!--End BuySellAds Zone Code--></td></tr><tr><td><table><tr><td class="lp">From</td><td class="rp" itemprop="author">Linus Torvalds &lt;&gt;</td></tr><tr><td class="lp">Date</td><td class="rp" itemprop="datePublished">Fri, 18 Aug 2017 12:14:12 -0700</td></tr><tr><td class="lp">Subject</td><td class="rp" itemprop="name">Re: [PATCH 1/2] sched/wait: Break up long wake list walk</td></tr></table></td><td><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></td></tr></table><pre itemprop="articleBody">On Fri, Aug 18, 2017 at 11:54 AM, Mel Gorman<br />&lt;mgorman&#64;techsingularity.net&gt; wrote:<br />&gt;<br />&gt; One option to mitigate (but not eliminate) the problem is to record when<br />&gt; the page lock is contended and pass in TNF_PAGE_CONTENDED (new flag) to<br />&gt; task_numa_fault().<br /><br />Well, finding it contended is fairly easy - just look at the page wait<br />queue, and if it's not empty, assume it's due to contention.<br /><br />I also wonder if we could be even *more* hacky, and in the whole<br />__migration_entry_wait() path, change the logic from:<br /><br /> - wait on page lock before retrying the fault<br /><br />to<br /><br /> - yield()<br /><br />which is hacky, but there's a rationale for it:<br /><br /> (a) avoid the crazy long wait queues ;)<br /><br /> (b) we know that migration is *supposed* to be CPU-bound (not IO<br />bound), so yielding the CPU and retrying may just be the right thing<br />to do.<br /><br />It's possible that we could just do a hybrid approach, and introduce a<br />"wait_on_page_lock_or_yield()", that does a sleeping wait if the<br />wait-queue is short, and a yield otherwise, but it might be worth just<br />testing the truly stupid patch.<br /><br />Because that code sequence doesn't actually depend on<br />"wait_on_page_lock()" for _correctness_ anyway, afaik. Anybody who<br />does "migration_entry_wait()" _has_ to retry anyway, since the page<br />table contents may have changed by waiting.<br /><br />So I'm not proud of the attached patch, and I don't think it's really<br />acceptable as-is, but maybe it's worth testing? And maybe it's<br />arguably no worse than what we have now?<br /><br />Comments?<br /><br />(Yeah, if we take this approach, we might even just say "screw the<br />spinlock - just do ACCESS_ONCE() and do a yield() if it looks like a<br />migration entry")<br /><br />                     Linus<br /> mm/migrate.c | 15 +--------------<br /> 1 file changed, 1 insertion(+), 14 deletions(-)<br /><br />diff --git a/mm/migrate.c b/mm/migrate.c<br />index d68a41da6abb..a28908305841 100644<br />--- a/mm/migrate.c<br />+++ b/mm/migrate.c<br />&#64;&#64; -284,7 +284,6 &#64;&#64; void __migration_entry_wait(struct mm_struct *mm, pte_t *ptep,<br /> {<br /> 	pte_t pte;<br /> 	swp_entry_t entry;<br />-	struct page *page;<br /> <br /> 	spin_lock(ptl);<br /> 	pte = *ptep;<br />&#64;&#64; -295,20 +294,8 &#64;&#64; void __migration_entry_wait(struct mm_struct *mm, pte_t *ptep,<br /> 	if (!is_migration_entry(entry))<br /> 		goto out;<br /> <br />-	page = migration_entry_to_page(entry);<br />-<br />-	/*<br />-	 * Once radix-tree replacement of page migration started, page_count<br />-	 * *must* be zero. And, we don't want to call wait_on_page_locked()<br />-	 * against a page without get_page().<br />-	 * So, we use get_page_unless_zero(), here. Even failed, page fault<br />-	 * will occur again.<br />-	 */<br />-	if (!get_page_unless_zero(page))<br />-		goto out;<br /> 	pte_unmap_unlock(ptep, ptl);<br />-	wait_on_page_locked(page);<br />-	put_page(page);<br />+	yield();<br /> 	return;<br /> out:<br /> 	pte_unmap_unlock(ptep, ptl);</pre><div align="center"><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></div></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerr.gif" width="32" height="32" alt="\" /></td></tr><tr><td align="right" valign="bottom">
