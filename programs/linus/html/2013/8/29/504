    </div></td><td width="32">Â </td></tr><tr><td valign="top"><div class="es-jasper-simpleCalendar" baseurl="/lkml/"></div><div class="threadlist">Messages in this thread</div><ul class="threadlist"><li class="root"><a href="/lkml/2013/8/5/722">First message in thread</a></li><li><a href="/lkml/2013/8/29/242">Linus Torvalds</a><ul><li><a href="/lkml/2013/8/29/349">Linus Torvalds</a><ul><li class="origin"><a href="/lkml/2013/8/29/574">Linus Torvalds</a><ul><li><a href="/lkml/2013/8/29/574">Waiman Long</a><ul><li><a href="/lkml/2013/8/29/594">Linus Torvalds</a></li></ul></li><li><a href="/lkml/2013/8/29/597">Benjamin Herrenschmidt</a><ul><li><a href="/lkml/2013/8/29/529">Linus Torvalds</a></li><li><a href="/lkml/2013/8/29/555">Michael Neuling</a></li><li><a href="/lkml/2013/8/29/564">Linus Torvalds</a></li><li><a href="/lkml/2013/8/29/565">Benjamin Herrenschmidt</a></li><li><a href="/lkml/2013/8/29/566">Linus Torvalds</a></li><li><a href="/lkml/2013/8/29/568">Benjamin Herrenschmidt</a></li><li><a href="/lkml/2013/8/29/569">Benjamin Herrenschmidt</a></li><li><a href="/lkml/2013/8/30/63">Ingo Molnar</a></li></ul></li><li><a href="/lkml/2013/9/8/158">Linus Torvalds</a><ul><li><a href="/lkml/2013/9/8/169">Al Viro</a></li></ul></li></ul></li></ul></li><li><a href="/lkml/2013/8/30/425">Peter Zijlstra</a><ul><li><a href="/lkml/2013/8/30/420">Linus Torvalds</a></li><li><a href="/lkml/2013/8/30/427">Linus Torvalds</a></li></ul></li></ul></li></ul></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerl.gif" width="32" height="32" alt="/" /></td><td class="c" rowspan="2" valign="top" style="padding-top: 1em"><table><tr><td colspan="2"><!--BuySellAds Zone Code--><div id="bsap_1297613" class="bsarocks bsap_5aa49c00cc06c882289a1dd6a5e50b62"></div><!--End BuySellAds Zone Code--></td></tr><tr><td><table><tr><td class="lp">Date</td><td class="rp" itemprop="datePublished">Thu, 29 Aug 2013 16:42:36 -0700</td></tr><tr><td class="lp">Subject</td><td class="rp" itemprop="name">Re: [PATCH v7 1/4] spinlock: A new lockref structure for lockless update of refcount</td></tr><tr><td class="lp">From</td><td class="rp" itemprop="author">Linus Torvalds &lt;&gt;</td></tr></table></td><td><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></td></tr></table><pre itemprop="articleBody">On Thu, Aug 29, 2013 at 12:25 PM, Linus Torvalds<br />&lt;torvalds&#64;linux-foundation.org&gt; wrote:<br />&gt;<br />&gt; Hmm. I can see it, but it turns out that for normal pathname walking,<br />&gt; one of the main stumbling blocks is the RCU case of complete_walk(),<br />&gt; which cannot be done with the lockless lockref model.<br />&gt; [... snip ...]<br /><br />Ok, here's a patch for people to try out if they want to. It's tested,<br />and works for me, but it is - like the two preparatory patches I<br />already applied - not really based on Waiman's patches except from a<br />conceptual standpoint.<br /><br />For architecture people (ie Ben, if you want to try this on ppc64),<br />the thing that it needs from an architecture:<br /><br /> - the raw_spinlock_t and the "unsigned long" needs to fit in a u64.<br /><br />   This is normally true anyway, but if your architecture code has a<br />big spinlock, you can't use it.<br /><br /> - the architecture needs to support "cmpxchg()" on that "u64" type<br />(so x86-32 does *not* use this, although we could teach it to do so by<br />teaching x86-32 to use "cmpxchg8b" for the 8-byte case)<br /><br />   A 64-bit architecture needs to support cmpxchg() on an u64 anyway,<br />so this is always true on 64-bit. It _can_ be true on 32-bit<br />architectures too.<br /><br /> - the architecture needs to implement a simple<br />"arch_spin_value_unlocked()" macro, which takes a raw_spinlock_t value<br />and says whether it is unlocked or not.<br /><br />   This is a new macro/function. It's generally a one-liner. For the<br />x86 ticket locks, for example, the test is simply "lock.tickets.head<br />== lock.tickets.tail".<br /><br /> - the architecture code needs to let the generic code know that it<br />supports all this by doing a "select ARCH_USE_CMPXCHG_LOCKREF"<br /><br />   Add it to your Kconfig file in the appropriate place. You do *not*<br />need to worry about LOCKDEP etc, you only need to worry about your own<br />architecture details above.<br /><br />That's it. If it does that, the lockref code will use the cmpxchg<br />optimization when appropriate (ie spinlock debugging is not turned on<br />etc etc).<br /><br />For Waiman: your patch had that adaptive waiting thing, and "wait for<br />unlocked" code, and I threw all that away. I didn't like it, and the<br />only reason for it existing was that the spinlock could be taken in a<br />hot path, which I felt was against the whole point of this "lockref"<br />thing.<br /><br />So I fixed the VFS layer instead. With dput() and friends using<br />lockrefs, the only thing remaining in the hot RCU dentry lookup path<br />was the nasty __d_rcu_to_refcount() thing in complete_walk(). I<br />rewrote that to locklessly increment the refcount when it was nonzero,<br />and get the lock if it was zero, and that all seems to work fine.<br /><br />And once the only case that is relevant for the fast-path is "d_lock<br />is unlocked", all your games with waiting for the spinlock to be<br />released are unnecessary. Making everything much simpler. If the<br />spinlock isn't unlocked, we always kick out to the fallback case (with<br />real locking).<br /><br />NOTE! My test-case was very small and simple, so it may not trigger<br />other cases that might trigger d_lock in a hotpath. Anything that<br />kicks us out of rcu mode (like a symlink, for example) will trigger<br />"unlazy_walk()", and I didn't do the same thing there. So there's<br />still details like that to sort out, but I very much think this whole<br />"only an unlocked spinlock is a fastpath" is the right approach.<br /><br />My simple testing shows that this has about the same best-case<br />performance, and the 15% _raw_spin_lock load I was able to trigger is<br />totally gone. That doesn't make things *faster* for me (because the<br />cost of the cmpxchg is pretty much comparable to the cost of the<br />spinlocks), but the big difference is the contended behavior where we<br />don't actually have to wait for the spinlock, we can just locklessly<br />increment the counter.<br /><br />I can't trigger the CPU-eating contention case on my single-socket<br />system, which is why I'm sending out this patch for testing (despite<br />it not having that unlazy_walk() thing etc).<br /><br />Also note that this is one single patch, not split up. Again, that's<br />because what I'm really hoping to get is just "does this fix the<br />contention-case on the 80-core monster machine that I don't have<br />access to?"<br /><br />Side note: the whole cmpxchg() loop is written to basically generate<br />the perfect cmpxchg sequence on x86. The assembly results actually<br />look pretty good. I can't take advantage of the eflag setting of the<br />instruction, because gcc inline asms don't support that (even with<br />"asm goto" - I'd need to have output values for that, and "asm goto"<br />does now allow that). So there's one extra "cmpq" instruction, and gcc<br />makes a mess of "add 1 to structure member in high bytes of a 64-bit<br />stricture", but it's actually fairly readable and short assembly code,<br />which was *not* true of the original patches.<br /><br />Waiman? Mind looking at this and testing?<br /><br />                          Linus<br />[unhandled content-type:application/octet-stream]</pre><div align="center"><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></div></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerr.gif" width="32" height="32" alt="\" /></td></tr><tr><td align="right" valign="bottom">
