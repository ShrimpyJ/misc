    </div></td><td width="32">Â </td></tr><tr><td valign="top"><div class="es-jasper-simpleCalendar" baseurl="/lkml/"></div><div class="threadlist">Messages in this thread</div><ul class="threadlist"><li class="root"><a href="/lkml/2013/7/23/369">First message in thread</a></li><li><a href="/lkml/2013/7/23/369">Dave Jones</a><ul><li class="origin"><a href="/lkml/2013/7/24/308">Linus Torvalds</a><ul><li><a href="/lkml/2013/7/24/308">"Paul E. McKenney"</a></li></ul></li><li><a href="/lkml/2013/7/24/209">"Paul E. McKenney"</a><ul><li><a href="/lkml/2013/7/24/683">"Paul E. McKenney"</a><ul><li><a href="/lkml/2013/7/25/249">Josh Boyer</a><ul><li><a href="/lkml/2013/7/25/289">"Paul E. McKenney"</a></li></ul></li></ul></li></ul></li></ul></li></ul></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerl.gif" width="32" height="32" alt="/" /></td><td class="c" rowspan="2" valign="top" style="padding-top: 1em"><table><tr><td colspan="2"><!--BuySellAds Zone Code--><div id="bsap_1297613" class="bsarocks bsap_5aa49c00cc06c882289a1dd6a5e50b62"></div><!--End BuySellAds Zone Code--></td></tr><tr><td><table><tr><td class="lp">Date</td><td class="rp" itemprop="datePublished">Tue, 23 Jul 2013 19:24:31 -0700</td></tr><tr><td class="lp">Subject</td><td class="rp" itemprop="name">Re: spinlock lockup, rcu stalls etc.</td></tr><tr><td class="lp">From</td><td class="rp" itemprop="author">Linus Torvalds &lt;&gt;</td></tr></table></td><td><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></td></tr></table><pre itemprop="articleBody">[ Added Thomas and Ingo due to that timer/nmi thing. ]<br /><br />On Tue, Jul 23, 2013 at 9:28 AM, Dave Jones &lt;davej&#64;redhat.com&gt; wrote:<br />&gt; Woke up to a box that I could log into, but would hang as soon as I tried to<br />&gt; do any disk IO.  This is what hit the logs before that.<br />&gt;<br />&gt; [28853.503179] hrtimer: interrupt took 4847 ns<br /><br />Ugh. There's some nasty timer congestion there..<br /><br />&gt; [28932.599607] BUG: spinlock lockup suspected on CPU#0, trinity-child2/6990<br />&gt; [28932.600419]  lock: inode_sb_list_lock+0x0/0x80, .magic: dead4ead, .owner: trinity-child1/6763, .owner_cpu: 1<br /><br />So the current owner of the lock is cpu 1. The other CPU's agree:<br /><br />&gt; [28932.606666] BUG: spinlock lockup suspected on CPU#2, trinity-child2/6764<br />&gt; [28932.606669]  lock: inode_sb_list_lock+0x0/0x80, .magic: dead4ead, .owner: trinity-child1/6763, .owner_cpu: 1<br />&gt; [28932.617231] sending NMI to all CPUs:<br />&gt; [28932.635092] BUG: spinlock lockup suspected on CPU#3, trinity-child3/6975<br />&gt; [28932.635095]  lock: inode_sb_list_lock+0x0/0x80, .magic: dead4ead, .owner: trinity-child1/6763, .owner_cpu: 1<br /><br />.. and their backtrace all points to them trying to take that<br />spinlock. So that is all consistent.<br /><br />And here's cpu1, edited down a bit:<br /><br />&gt; [28932.777623] NMI backtrace for cpu 1<br />&gt; [28932.777625] INFO: NMI handler (arch_trigger_all_cpu_backtrace_handler) took too long to run: 91.230 msecs<br /><br />Whee. 91 msec? We have something going on there too. irq entry locks?<br /><br />&gt; [28932.779440] CPU: 1 PID: 6763 Comm: trinity-child1 Not tainted 3.11.0-rc2+ #54<br />&gt; [28932.782283] RIP: 0010:[&lt;ffffffff81710385&gt;]  [&lt;ffffffff81710385&gt;] add_preempt_count+0x25/0xf0<br />&gt; [28932.797761] Call Trace:<br />&gt; [28932.798737]  &lt;IRQ&gt;<br />&gt; [28932.799715]  [&lt;ffffffff81320851&gt;] delay_tsc+0x61/0xe0<br />&gt; [28932.800693]  [&lt;ffffffff81320789&gt;] __const_udelay+0x29/0x30<br />&gt; [28932.801674]  [&lt;ffffffff810816d4&gt;] __rcu_read_unlock+0x54/0xa0<br />&gt; [28932.802657]  [&lt;ffffffff810af531&gt;] cpuacct_account_field+0xf1/0x200<br />&gt; [28932.804613]  [&lt;ffffffff8109e430&gt;] account_system_time+0xb0/0x1b0<br />&gt; [28932.805561]  [&lt;ffffffff8109e565&gt;] __vtime_account_system+0x35/0x40<br />&gt; [28932.806506]  [&lt;ffffffff8109e59d&gt;] vtime_account_system.part.2+0x2d/0x50<br />&gt; [28932.807445]  [&lt;ffffffff8109e8e5&gt;] vtime_account_irq_enter+0x55/0x80<br />&gt; [28932.808365]  [&lt;ffffffff8105f42f&gt;] irq_enter+0x4f/0x90<br />&gt; [28932.809269]  [&lt;ffffffff81716a15&gt;] smp_apic_timer_interrupt+0x35/0x60<br />&gt; [28932.810156]  [&lt;ffffffff817156af&gt;] apic_timer_interrupt+0x6f/0x80<br />&gt; [28932.812756]  [&lt;ffffffff8105f53d&gt;] irq_exit+0xcd/0xe0<br />&gt; [28932.813618]  [&lt;ffffffff81716a25&gt;] smp_apic_timer_interrupt+0x45/0x60<br />&gt; [28932.814483]  [&lt;ffffffff817156af&gt;] apic_timer_interrupt+0x6f/0x80<br />&gt; [28932.815345]  &lt;EOI&gt;<br />&gt; [28932.816207]  [&lt;ffffffff8170c6a0&gt;] ? retint_restore_args+0xe/0xe<br />&gt; [28932.817069]  [&lt;ffffffff810c1275&gt;] ? lock_acquired+0x105/0x3f0<br />&gt; [28932.817924]  [&lt;ffffffff811ec8e2&gt;] ? sync_inodes_sb+0x1c2/0x2a0<br />&gt; [28932.818767]  [&lt;ffffffff8170b62c&gt;] _raw_spin_lock+0x6c/0x80<br />&gt; [28932.819616]  [&lt;ffffffff811ec8e2&gt;] ? sync_inodes_sb+0x1c2/0x2a0<br />&gt; [28932.820468]  [&lt;ffffffff811ec8e2&gt;] sync_inodes_sb+0x1c2/0x2a0<br />&gt; [28932.821310]  [&lt;ffffffff81708c1f&gt;] ? wait_for_completion+0xdf/0x110<br />&gt; [28932.823819]  [&lt;ffffffff811f2a49&gt;] sync_inodes_one_sb+0x19/0x20<br />&gt; [28932.824649]  [&lt;ffffffff811c2b12&gt;] iterate_supers+0xb2/0x110<br />&gt; [28932.825477]  [&lt;ffffffff811f2cb5&gt;] sys_sync+0x35/0x90<br />&gt; [28932.826300]  [&lt;ffffffff81714c54&gt;] tracesys+0xdd/0xe2<br />&gt; [28932.827119]  [&lt;ffffffffa0000000&gt;] ? 0xffffffff9fffffff<br /><br />.. and again, it actually looks like the time is not necessarily spent<br />inside the spinlock in sync_inodes_sb(), but in a timer interrupt that<br />just happened to go off during that. I wonder if this is the same<br />issue that caused that earlier hrtimer long delay.. I'm not<br />necessarily seeing 91 msecs worth, but..<br /><br />You seem to have CONFIG_PROVE_RCU_DELAY enabled, which explains that<br />delay_tsc() call in there. I wonder how much things like that make it<br />worse. Together with the (crazy bad) back-off in __spin_lock_debug(),<br />there might be a *lot* of these delays.<br /><br />That said, the fact that your machine is dead after all this implies<br />that there is something else wrong than just things being very slow.<br />But I suspect at least *part* of your problems may be due to these<br />kinds of debugging options that make things much much worse.<br /><br />              Linus<br /><br /><br /></pre><div align="center"><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></div></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerr.gif" width="32" height="32" alt="\" /></td></tr><tr><td align="right" valign="bottom">
