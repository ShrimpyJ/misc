    </div></td><td width="32">Â </td></tr><tr><td valign="top"><div class="es-jasper-simpleCalendar" baseurl="/lkml/"></div><div class="threadlist">Messages in this thread</div><ul class="threadlist"><li class="root"><a href="/lkml/2001/8/23/213">First message in thread</a></li><li><a href="/lkml/2001/8/27/101">Oliver Neukum</a><ul><li><a href="/lkml/2001/8/27/114">Daniel Phillips</a><ul><li class="origin"><a href="/lkml/2001/8/27/129">Linus Torvalds</a><ul><li><a href="/lkml/2001/8/27/129">Marcelo Tosatti</a><ul><li><a href="/lkml/2001/8/27/135">Linus Torvalds</a></li></ul></li><li><a href="/lkml/2001/8/27/188">Daniel Phillips</a></li></ul></li><li><a href="/lkml/2001/8/27/173"> &lt;Oliver.Neukum&#64;lrz ...</a></li></ul></li></ul></li></ul></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerl.gif" width="32" height="32" alt="/" /></td><td class="c" rowspan="2" valign="top" style="padding-top: 1em"><table><tr><td colspan="2"><!--BuySellAds Zone Code--><div id="bsap_1297613" class="bsarocks bsap_5aa49c00cc06c882289a1dd6a5e50b62"></div><!--End BuySellAds Zone Code--></td></tr><tr><td><table><tr><td class="lp">From</td><td class="rp" itemprop="author">Linus Torvalds &lt;&gt;</td></tr><tr><td class="lp">Date</td><td class="rp" itemprop="datePublished">Mon, 27 Aug 2001 14:44:01 -0700</td></tr><tr><td class="lp">Subject</td><td class="rp" itemprop="name">Re: [resent PATCH] Re: very slow parallel read performance</td></tr></table></td><td><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></td></tr></table><pre itemprop="articleBody">In article &lt;20010827203125Z16070-32383+1731&#64;humbolt.nl.linux.org&gt; you write:<br />&gt;On August 27, 2001 09:43 pm, Oliver Neukum wrote:<br />&gt;&gt; <br />&gt;&gt; If we are optimising for streaming (which readahead is made for) dropping <br />&gt;&gt; only one page will buy you almost nothing in seek time. You might just as <br />&gt;&gt; well drop them all and correct your error in one larger read if necessary.<br />&gt;&gt; Dropping the oldest page is possibly the worst you can do, as you will need <br />&gt;&gt; it soonest.<br />&gt;<br />&gt;Yes, good point.  OK, I'll re-examine the dropping logic.  Bear in mind, <br />&gt;dropping readahead pages is not supposed to happen frequently under <br />&gt;steady-state operation, so it's not that critical what we do here, it's going <br />&gt;to be hard to create a load that shows the impact.  The really big benefit <br />&gt;comes from not overdoing the readahead in the first place, and not underdoing <br />&gt;it either.<br /><br />Note that the big reason why I did _not_ end up just increasing the<br />read-ahead value from 31 to 511 (it was there for a short while) is that<br />large read-ahead does not necessarily improve performance AT ALL,<br />regardless of memory pressure. <br /><br />Why? Because if the IO request queue fills up, the read-ahead actually<br />ends up waiting for requests, and ends up being synchronous. Which<br />totally destroys the whole point of doing read-ahead in the first place.<br />And a large read-ahead only makes this more likely.<br /><br />Also note that doing tons of parallel reads _also_ makes this more<br />likely, and actually ends up also mixing the read-ahead streams which is<br />exactly what you do not want to do.<br /><br />The solution to both problems is to make the read-ahead not wait<br />synchronously on requests - that way the request allocation itself ends<br />up being a partial throttle on memory usage too, so that you actually<br />probably end up fixing the problem of memory pressure _too_.<br /><br />This requires that the read-ahead code would start submitting the blocks<br />using READA, which in turn requires that the readpage() function get a<br />"READ vs READA" argument.  And the ll_rw_block code would obviously have<br />to honour the rw_ahead hint and submit_bh() would have to return an<br />error code - which it currently doesn't do, but which should be trivial<br />to implement. <br /><br />I really think that doing anything else is (a) stupid and (b) wrong.<br />Trying to come up with a complex algorithm on how to change read-ahead<br />based on memory pressure is just bound to be extremely fragile and have<br />strange performance effects. While letting the IO layer throttle the<br />read-ahead on its own is the natural and high-performance approach.<br /><br />		Linus<br />-<br />To unsubscribe from this list: send the line "unsubscribe linux-kernel" in<br />the body of a message to majordomo&#64;vger.kernel.org<br />More majordomo info at  <a href="http://vger.kernel.org/majordomo-info.html">http://vger.kernel.org/majordomo-info.html</a><br />Please read the FAQ at  <a href="http://www.tux.org/lkml/">http://www.tux.org/lkml/</a><br /><br /></pre><div align="center"><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></div></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerr.gif" width="32" height="32" alt="\" /></td></tr><tr><td align="right" valign="bottom">
