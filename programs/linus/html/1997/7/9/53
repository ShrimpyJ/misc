    </div></td><td width="32">Â </td></tr><tr><td valign="top"><div class="es-jasper-simpleCalendar" baseurl="/lkml/"></div><div class="threadlist">Messages in this thread</div><ul class="threadlist"><li class="root"><a href="/lkml/1997/7/7/56">First message in thread</a></li><li><a href="/lkml/1997/7/8/127">(Linus Torvalds)</a><ul><li><a href="/lkml/1997/7/9/26">(Matthias Urlichs)</a></li><li><a href="/lkml/1997/7/9/38">Bill Hawes</a><ul><li class="origin"><a href="">Linus Torvalds</a></li></ul></li></ul></li></ul></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerl.gif" width="32" height="32" alt="/" /></td><td class="c" rowspan="2" valign="top" style="padding-top: 1em"><table><tr><td colspan="2"><!--BuySellAds Zone Code--><div id="bsap_1297613" class="bsarocks bsap_5aa49c00cc06c882289a1dd6a5e50b62"></div><!--End BuySellAds Zone Code--></td></tr><tr><td><table><tr><td class="lp">Date</td><td class="rp" itemprop="datePublished">Wed, 9 Jul 1997 08:43:30 -0700 (PDT)</td></tr><tr><td class="lp">From</td><td class="rp" itemprop="author">Linus Torvalds &lt;&gt;</td></tr><tr><td class="lp">Subject</td><td class="rp" itemprop="name">Re: linux-2.1.44 on i586: Immediate crash on boot</td></tr></table></td><td><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></td></tr></table><pre itemprop="articleBody"><br /><br />On Wed, 9 Jul 1997, Bill Hawes wrote:<br />&gt; <br />&gt; You left some massive race conditions in clear_inode and iput though --<br />&gt; see my recent patches against 2.0.30 for example.  The attached patch<br />&gt; takes care of these.<br />&gt; <br />&gt; The question of whether clear_inode can be called with count == 0 needs<br />&gt; to be resolved.  As it presently stands a filesystem without a put<br />&gt; function will allow the inode count to go to 0 while remaining on the<br />&gt; inuse list.  This is OK, except that when you want to reuse it you need<br />&gt; to call clear_inode, whcih reintroduces race conditions ...<br /><br />Actually, that's not true with the new inode code. If you look carefully,<br />you'll notice that "clear_inode()" is never called just becaus i_count is<br />zero.<br /><br />clear_inode() is called _only_ by filesystems that want to indicate that<br />the inode no longer exists (ie when the filesystem actually deletes the<br />inode). At that point i_count is still 1, actually, as this is done from<br />the "put()" routine before i_count has been decremented. <br /><br />The other way the inode can migrate to the unused list is through<br />"invalidate_inodes()" (seldom) or "try_to_free_inodes()", which just take<br />a look at the in_use list and move any CAN_UNUSE() inodes into the unused<br />list. This operation is atomic, because CAN_UNUSE() essentially makes sure<br />there is _nothing_ the inode needs to care about (no nrpages, no count, no<br />dirty etc). <br /><br />There is one known race: after iput() has done the "put()" operation, it<br />will do a decrement on the inode count. That is generally fine: if the<br />"put()" has not put the inode on the free list then the decrement is the<br />right thing to do, and if it _has_ put it on the free list the decrement<br />doesn't make any difference because i_count is no longer used. <br /><br />However, there is a slight race where the filesystem puts the inode on the<br />free list and then that inode is immediately allocated by something else,<br />and now the i_count decrement is done on somebody else's inode.<br /><br />This race cannot actually currently happen because filesystems do not<br />sleep between the clear_inode() and returning to iput() and the race is<br />protected by the global kernel lock (SMP) or general rescheduling rules<br />(UP). However, I designed the new inode code to be SMP safe even without<br />the current global lock, so this is a "bug" in my books and I'll have to<br />fix it. <br /><br />I'll certainly take a look at your patches, though. Maybe I just had<br />overlooked something. <br /><br />&gt; One minor nit -- you init the inode semaphore in init_once, but then<br />&gt; again in clean_inode.  Once should be enough?<br /><br />There is a lot of initialization I want to remove from clean_inode(). The<br />current code tries to be safe rather than clever, and I worried that maybe<br />somebody does a free on the inode while holding the semaphore (because the<br />old code used to re-initialize it). But you're probably right that it<br />should just be deleted. Anybody care to try and send me results?<br /><br />Oh, final comments, because I really _should_ have warned people about the<br />problems that I knew about when I released it (most of these problems are<br />in 2.1.44 too):<br /><br /> - unmounting of filesystems does not work. The current inode.c doesn't<br />   try to find out whether we can unmount or not, so it takes the "safe" <br />   approach and tells the rest of the kernel that it can never unmount or<br />   re-mount read-only. I need to go through the inodes and look that none<br />   of them are in use.. <br /><br /> - The dcache never free's any dcache entries it has allocated. NEVER. And<br />   it free's the inodes that those dcache entries are associated with only<br />   if the file is actually deleted (but even in that case the dcache entry<br />   itself is not actually free'd).<br /><br />Problem #2 is actually the major reason for #1: because of #2 we have a<br />lot of inodes that look like they are in use, even though they are really<br />only in the directory cache, and as such it's currently impossible to tell<br />whether a filesystem is unused (it _would_ be possible to check whether we<br />can remount read-only, but I decided to punt on that too until #2 is<br />done). <br /><br />Problem #2 also means that 44 and pre-45 can be totally useless depending<br />on how much memory you have and what kinds of filesystem access patterns<br />you have. For example, for the kind of work I mostly do, #2 is usually not<br />a problem, because my access patterns are so regular that even though the<br />dcache never shrinks, it also tends to not grow very much. <br /><br />Problem #1 results in all shutdowns being dirty shutdowns, so the<br />filesystems will be checked at the next boot. This has actually been a<br />"feature" for me personally because that way I can be sure that the<br />filesystems aren't silently and slowly being corrupted (although plain<br />2.1.44 can do that too - I've never seen it in pre-45, though ;)<br /><br />Even despite the above two problems are major showstoppers for most<br />"serious" use of pre-2.1.45, I'd still like people to test it out just to<br />get a feel for any other problems that might be lurking. Fixing the above<br />two problems isn't really hard, but #2 in particular will require quite<br />some attention to details. I want to know whether the kernel otherwise is<br />reasonably stable apart from these issues.. <br /><br />		Linus<br /><br /><br /></pre><div align="center"><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></div></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerr.gif" width="32" height="32" alt="\" /></td></tr><tr><td align="right" valign="bottom">
