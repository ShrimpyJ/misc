    </div></td><td width="32">Â </td></tr><tr><td valign="top"><div class="es-jasper-simpleCalendar" baseurl="/lkml/"></div><div class="threadlist">Messages in this thread</div><ul class="threadlist"><li class="root"><a href="/lkml/2021/5/14/252">First message in thread</a></li><li><a href="/lkml/2021/5/14/252">Arnd Bergmann</a><ul><li><a href="/lkml/2021/5/14/253">Arnd Bergmann</a></li><li><a href="/lkml/2021/5/14/254">Arnd Bergmann</a></li><li><a href="/lkml/2021/5/14/255">Arnd Bergmann</a><ul><li><a href="/lkml/2021/5/14/292">John Paul Adrian Glaubitz</a><ul><li><a href="/lkml/2021/5/14/425">Arnd Bergmann</a><ul><li><a href="/lkml/2021/5/15/186">John Paul Adrian Glaubitz</a></li></ul></li></ul></li></ul></li><li><a href="/lkml/2021/5/14/256">Arnd Bergmann</a></li><li><a href="/lkml/2021/5/14/257">Arnd Bergmann</a><ul><li><a href="/lkml/2021/5/14/395">Segher Boessenkool</a><ul><li><a href="/lkml/2021/5/14/463">Arnd Bergmann</a></li></ul></li></ul></li><li><a href="/lkml/2021/5/14/258">Arnd Bergmann</a></li><li><a href="/lkml/2021/5/14/259">Arnd Bergmann</a><ul><li><a href="/lkml/2021/5/17/2285">Eric Biggers</a><ul><li><a href="/lkml/2021/5/18/143">Arnd Bergmann</a><ul><li><a href="/lkml/2021/5/18/749">Linus Torvalds</a></li></ul></li></ul></li></ul></li><li><a href="/lkml/2021/5/14/260">Arnd Bergmann</a><ul><li><a href="/lkml/2021/5/17/435">Christoph Hellwig</a><ul><li><a href="/lkml/2021/5/17/456">Arnd Bergmann</a></li></ul></li></ul></li><li><a href="/lkml/2021/5/14/261">Arnd Bergmann</a></li><li><a href="/lkml/2021/5/14/262">Arnd Bergmann</a><ul><li><a href="/lkml/2021/5/15/21">Kalle Valo</a><ul><li><a href="/lkml/2021/5/15/67">Arnd Bergmann</a><ul><li><a href="/lkml/2021/5/15/249">Kalle Valo</a></li></ul></li></ul></li></ul></li><li><a href="/lkml/2021/5/14/263">Arnd Bergmann</a></li><li><a href="/lkml/2021/5/14/264">Arnd Bergmann</a><ul><li><a href="/lkml/2021/5/15/252">Randy Dunlap</a><ul><li><a href="/lkml/2021/5/15/270">Arnd Bergmann</a></li></ul></li></ul></li><li><a href="/lkml/2021/5/14/265">Arnd Bergmann</a><ul><li><a href="/lkml/2021/5/14/305">David Laight</a></li></ul></li><li><a href="/lkml/2021/5/14/708">Linus Torvalds</a><ul><li><a href="/lkml/2021/5/14/758">Vineet Gupta</a><ul><li><a href="/lkml/2021/5/14/777">Linus Torvalds</a><ul><li><a href="/lkml/2021/5/14/809">Vineet Gupta</a></li></ul></li></ul></li><li><a href="/lkml/2021/5/14/802">Arnd Bergmann</a></li></ul></li><li><a href="/lkml/2021/12/16/943">Ard Biesheuvel</a><ul><li class="origin"><a href="">Linus Torvalds</a></li><li><a href="/lkml/2021/12/16/976">David Laight</a></li><li><a href="/lkml/2021/12/16/1070">Segher Boessenkool</a><ul><li><a href="/lkml/2021/12/17/405">David Laight</a><ul><li><a href="/lkml/2021/12/17/472">Segher Boessenkool</a></li></ul></li></ul></li></ul></li></ul></li></ul></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerl.gif" width="32" height="32" alt="/" /></td><td class="c" rowspan="2" valign="top" style="padding-top: 1em"><table><tr><td colspan="2"><!--BuySellAds Zone Code--><div id="bsap_1297613" class="bsarocks bsap_5aa49c00cc06c882289a1dd6a5e50b62"></div><!--End BuySellAds Zone Code--></td></tr><tr><td><table><tr><td class="lp">From</td><td class="rp" itemprop="author">Linus Torvalds &lt;&gt;</td></tr><tr><td class="lp">Date</td><td class="rp" itemprop="datePublished">Thu, 16 Dec 2021 09:42:41 -0800</td></tr><tr><td class="lp">Subject</td><td class="rp" itemprop="name">Re: [PATCH v2 00/13] Unify asm/unaligned.h around struct helper</td></tr></table></td><td><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></td></tr></table><pre itemprop="articleBody">On Thu, Dec 16, 2021 at 9:29 AM Ard Biesheuvel &lt;ardb&#64;kernel.org&gt; wrote:<br />&gt;<br />&gt; CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS is used in many places to<br />&gt; conditionally emit code that violates C alignment rules. E.g., there<br />&gt; is this example in Documentation/core-api/unaligned-memory-access.rst:<br />&gt;<br />&gt; bool ether_addr_equal(const u8 *addr1, const u8 *addr2)<br />&gt; {<br />&gt; #ifdef CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS<br />&gt;   u32 fold = ((*(const u32 *)addr1) ^ (*(const u32 *)addr2)) |<br />&gt;              ((*(const u16 *)(addr1 + 4)) ^ (*(const u16 *)(addr2 + 4)));<br />&gt;   return fold == 0;<br />&gt; #else<br /><br />It probably works fine in practice - the one case we had was really<br />pretty special, and about the vectorizer doing odd things.<br /><br />But I think we should strive to convert these to use<br />"get_unaligned()", since code generation is fine. It still often makes<br />sense to have that test for the config variable, simply because the<br />approach might be different if we know unaligned accesses are slow.<br /><br />So I'll happily take patches that do obvious conversions to<br />get_unaligned() where they make sense, but I don't think we should<br />consider this some huge hard requirement.<br /><br />                 Linus<br /><br /></pre><div align="center"><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></div></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerr.gif" width="32" height="32" alt="\" /></td></tr><tr><td align="right" valign="bottom">
