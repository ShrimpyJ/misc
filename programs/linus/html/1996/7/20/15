    </div></td><td width="32">Â </td></tr><tr><td valign="top"><div class="es-jasper-simpleCalendar" baseurl="/lkml/"></div><div class="threadlist">Messages in this thread</div><ul class="threadlist"><li class="root"><a href="/lkml/1996/7/13/16">First message in thread</a></li><li><a href="/lkml/1996/7/16/15">Adam McKee</a><ul><li><a href="/lkml/1996/7/17/2">Linus Torvalds</a><ul><li><a href="/lkml/1996/7/16/52">Adam McKee</a><ul><li><a href="/lkml/1996/7/17/56">"Marty Leisner"</a></li><li><a href="/lkml/1996/7/16/43">Linus Torvalds</a><ul><li><a href="/lkml/1996/7/16/49">Andrew Tridgell</a></li></ul></li></ul></li></ul></li><li><a href="/lkml/1996/7/20/21">"Stephen C. Tweedie"</a><ul><li class="origin"><a href="">Linus Torvalds</a></li><li><a href="/lkml/1996/7/24/5">(Kai Henningsen)</a></li></ul></li></ul></li></ul></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerl.gif" width="32" height="32" alt="/" /></td><td class="c" rowspan="2" valign="top" style="padding-top: 1em"><table><tr><td colspan="2"><!--BuySellAds Zone Code--><div id="bsap_1297613" class="bsarocks bsap_5aa49c00cc06c882289a1dd6a5e50b62"></div><!--End BuySellAds Zone Code--></td></tr><tr><td><table><tr><td class="lp">Date</td><td class="rp" itemprop="datePublished">Fri, 19 Jul 1996 12:34:21 +0300 (EET DST)</td></tr><tr><td class="lp">From</td><td class="rp" itemprop="author">Linus Torvalds &lt;&gt;</td></tr><tr><td class="lp">Subject</td><td class="rp" itemprop="name">Re: Is any file system on Linux appropriate for very large          directories?</td></tr></table></td><td><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></td></tr></table><pre itemprop="articleBody"><br /><br />On Thu, 18 Jul 1996, Stephen C. Tweedie wrote:<br />&gt; <br />&gt; &gt; The problem with hashed directories (or any other kind of "smart"<br />&gt; &gt; directories) is not the lookup phase: that's pretty simple, and is<br />&gt; &gt; almost always speeded up by the hashing (or the hashing is done<br />&gt; &gt; badly).<br />&gt; <br />&gt; &gt; The _real_ complexity comes in when you start adding/deleting<br />&gt; &gt; entries.  You may get faster lookups, but you're almost sure to get<br />&gt; &gt; slower modifications, and what's worse - keeping track of the extra<br />&gt; &gt; state is making the whole thing more complex.<br />&gt; <br />&gt; That's not necessarily true.  Certainly, insert/delete becomes more<br />&gt; complex to code, but it can be made very substantially faster as a<br />&gt; result.<br /><br />Umm.. I'll agree. In theory.<br /><br />However, the discussion is pretty much academic until somebody actually <br />does it, and even then I wouldn't trust the code to do the right thing <br />for the next year or two.<br /><br />What makes especially insert so non-trivial is not so much the actual <br />operations themselves, but the fact that you no longer operate on a local <br />scale: one modification may modify a noticeable amount of the directory. <br /><br />For example, doing a priority queue in memory is trivial. Trying to do <br />the same thing on a directory is complex as h*ll, because you don't ever <br />want the directory to be in a inconsistent state, yet at the same time <br />the IO operations force you to sleep..<br /><br />Oh, you can lock the whole directory for the duration of a operation, but <br />then you run into performance problems due to that (anybody say "news <br />serving"?) and you also get the deadlock issues (rename() is "fun" when <br />you have two processes trying to move files between two different <br />directories).<br /><br />Contrasted to that, a linked list is trivial: all operations are local.  We<br />do a write lock on the directory for the duration of the operation, but that<br />write lock doesn't affect readers, so news is happy. And the actual directory<br />change can be done atomically (in fact, it's hard _not_ to), so rename() is<br />not a large problem (rename is still a horrible, but orders of magnitudes<br />easier than it would be with any "global state" directory structure). <br /><br />Also, "every problem is easy if you don't check for errors". Some of the <br />global state structures will need to split blocks, and a single split can <br />result in more splits lower down - in which case you may have succeeded <br />with the first split, only to notice that you're out of disk blocks for <br />the second one, and then you have to undo the operation.. (I'm told that <br />HFS does this?)<br /><br />I'm not saying that a linked list (or array, rather) is technically <br />superior, but I _am_ saying that it may be the better choice despite the <br />limitations.<br /><br />I'd be more than happy to see more advanced filesystems for Linux, but just<br />as an example: people have been talking about log-based filesystems for years<br />and years, and nothing has come out of it so far. The BSD4.4 LFS is badly<br />broken according to all accounts, and I haven't heard anybody say they'd fix<br />it.<br /><br />The interest is obvious there, but right now all of the better filesystems<br />seem to have access latencies that can be counted in years or decades rather<br />than microseconds. <br /><br />		Linus<br /><br /><br /></pre><div align="center"><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></div></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerr.gif" width="32" height="32" alt="\" /></td></tr><tr><td align="right" valign="bottom">
