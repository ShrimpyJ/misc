    </div></td><td width="32">Â </td></tr><tr><td valign="top"><div class="es-jasper-simpleCalendar" baseurl="/lkml/"></div><div class="threadlist">Messages in this thread</div><ul class="threadlist"><li class="root"><a href="/lkml/1996/6/7/100">First message in thread</a></li><li><a href="/lkml/1996/6/7/100">Jamie Lokier</a><ul><li><a href="/lkml/1996/6/13/6">Tom May</a></li><li><a href="/lkml/1996/6/8/29">Robert L Krawitz</a></li><li><a href="/lkml/1996/6/8/39">(Alan Cox)</a><ul><li class="origin"><a href="/lkml/1996/6/8/52">Linus Torvalds</a><ul><li><a href="/lkml/1996/6/8/52">Robert L Krawitz</a><ul><li><a href="/lkml/1996/6/8/63">(Alan Cox)</a></li></ul></li><li><a href="/lkml/1996/6/8/60">Robert L Krawitz</a><ul><li><a href="/lkml/1996/6/9/17">Linus Torvalds</a></li><li><a href="/lkml/1996/6/8/69">(Alan Cox)</a></li></ul></li></ul></li></ul></li></ul></li></ul></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerl.gif" width="32" height="32" alt="/" /></td><td class="c" rowspan="2" valign="top" style="padding-top: 1em"><table><tr><td colspan="2"><!--BuySellAds Zone Code--><div id="bsap_1297613" class="bsarocks bsap_5aa49c00cc06c882289a1dd6a5e50b62"></div><!--End BuySellAds Zone Code--></td></tr><tr><td><table><tr><td class="lp">Date</td><td class="rp" itemprop="datePublished">Sat, 8 Jun 1996 20:21:15 +0300 (EET DST)</td></tr><tr><td class="lp">From</td><td class="rp" itemprop="author">Linus Torvalds &lt;&gt;</td></tr><tr><td class="lp">Subject</td><td class="rp" itemprop="name">Re: Speed of memcpy, csum_partial and csum_partial_copy</td></tr></table></td><td><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></td></tr></table><pre itemprop="articleBody"><br /><br />On Sat, 8 Jun 1996, Alan Cox wrote:<br />&gt; <br />&gt; &gt; My other point is that csum_partial_copy looks like it could run 33%<br />&gt; &gt; faster, when everything is in the CPU cache, by rearranging the<br />&gt; &gt; instructions in the loop to pair fully -- I think that adcl can pair but<br />&gt; &gt; only in the U pipe.  (I could be wrong about this.  If adcl can pair<br />&gt; &gt; anywhere, there are still write-then-read dependencies that prevent<br />&gt; &gt; pairing in that code).<br />&gt; <br />&gt; Several people have sped the checksum/copy code up over time. If you can<br />&gt; speed it further then you will be number 4, and since the performance of<br />&gt; these routines is very critical then the patches will be welcome.<br /><br />Just to show exactly _how_ important, here's some profiling info of a <br />machine that has been busy doing TCP over loopback (everything &gt;= 0.5% <br />included):<br /><br />        14     0.51% 0010fe10 schedule<br />        14     0.51% 00116194 do_bottom_half<br />        14     0.51% 001365a0 kfree_skbmem<br />        14     0.51% 00191288 csum_partial<br />        15     0.55% 00118c48 do_no_page<br />        15     0.55% 00142fd8 tcp_queue<br />        15     0.55% 00144db8 tcp_send_ack<br />        16     0.59% 00110494 add_timer<br />        16     0.59% 0013ebb8 ip_queue_xmit<br />        16     0.59% 0018ec70 loopback_xmit<br />        17     0.62% 00121c8c get_empty_inode<br />        17     0.62% 0013636c kfree_skb<br />        17     0.62% 0014315c tcp_data<br />        18     0.66% 001104c8 del_timer<br />        19     0.70% 00138320 eth_type_trans<br />        22     0.81% 00143c8c tcp_new_window<br />        23     0.85% 0013734c net_bh<br />        23     0.85% 00138134 eth_header<br />        23     0.85% 0014405c tcp_write_xmit<br />        26     0.96% 0011e8f4 _get_free_pages<br />        26     0.96% 001365f0 skb_clone<br />        31     1.14% 00136454 alloc_skb<br />        34     1.25% 00140e5c tcp_recvmsg<br />        40     1.47% 0011cf14 kmalloc<br />        40     1.47% 001434a4 tcp_rcv<br />        42     1.55% 0013e810 ip_build_header<br />        45     1.66% 0013cb44 ip_rcv<br />        45     1.66% 0014052c do_tcp_sendmsg<br />        48     1.77% 001425e8 tcp_ack<br />        54     1.99% 0011d114 kfree<br />       643    23.78% 00191324 csum_partial_copy_fromuser<br />       997    36.88% 001369c8 memcpy_toiovec<br />      2703   100.00% 00000000 total<br /><br />In short, the two copies that occur in TCP loopback (first from the <br />sender into the kernel, and then from the kernel into the receiver) alone <br />account for 60% of the TCP stack..<br /><br />(This is on a P166 with a reasonably good memory subsystem, and the <br />machine was sending 500MB of data over TCP loopback).<br /><br />Oh, and the "kfree()" number actually is mostly "free_pages()" but due to <br />running with interrupts disabled it shows up in kfree in case you were <br />wondering - I did.<br /><br />		Linus<br /><br /><br /></pre><div align="center"><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></div></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerr.gif" width="32" height="32" alt="\" /></td></tr><tr><td align="right" valign="bottom">
