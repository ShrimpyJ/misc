    </div></td><td width="32">Â </td></tr><tr><td valign="top"><div class="es-jasper-simpleCalendar" baseurl="/lkml/"></div><div class="threadlist">Messages in this thread</div><ul class="threadlist"><li class="root"><a href="/lkml/2020/7/21/76">First message in thread</a></li><li><a href="/lkml/2020/7/22/1199">Linus Torvalds</a><ul><li><a href="/lkml/2020/7/22/1222">Linus Torvalds</a></li><li><a href="/lkml/2020/7/23/527">Oleg Nesterov</a><ul><li class="origin"><a href="/lkml/2020/7/23/919">Linus Torvalds</a><ul><li><a href="/lkml/2020/7/23/919">Oleg Nesterov</a><ul><li><a href="/lkml/2020/7/23/937">Linus Torvalds</a></li></ul></li><li><a href="/lkml/2020/7/23/1039">Linus Torvalds</a><ul><li><a href="/lkml/2020/7/23/1228">Hugh Dickins</a></li></ul></li></ul></li></ul></li></ul></li></ul><div class="threadlist">Patch in this message</div><ul class="threadlist"><li><a href="/lkml/diff/2020/7/23/900/1">Get diff 1</a></li></ul></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerl.gif" width="32" height="32" alt="/" /></td><td class="c" rowspan="2" valign="top" style="padding-top: 1em"><table><tr><td colspan="2"><!--BuySellAds Zone Code--><div id="bsap_1297613" class="bsarocks bsap_5aa49c00cc06c882289a1dd6a5e50b62"></div><!--End BuySellAds Zone Code--></td></tr><tr><td><table><tr><td class="lp">From</td><td class="rp" itemprop="author">Linus Torvalds &lt;&gt;</td></tr><tr><td class="lp">Date</td><td class="rp" itemprop="datePublished">Thu, 23 Jul 2020 10:32:28 -0700</td></tr><tr><td class="lp">Subject</td><td class="rp" itemprop="name">Re: [RFC PATCH] mm: silence soft lockups from unlock_page</td></tr></table></td><td><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></td></tr></table><pre itemprop="articleBody">On Thu, Jul 23, 2020 at 5:47 AM Oleg Nesterov &lt;oleg&#64;redhat.com&gt; wrote:<br />&gt;<br />&gt; I still can't convince myself thatI fully understand this patch but I see<br />&gt; nothing really wrong after a quick glance...<br /><br />I guess my comments should be extended further then.<br /><br />Is there anything in particular you think is unclear?<br /><br />&gt; &gt; +     wake_up_state(target, mode);<br />&gt;<br />&gt; We can no longer use 'target'. If it was already woken up it can notice<br />&gt; list_empty_careful(), return without taking q-&gt;lock, and exit.<br /><br />Good point.<br /><br />And yes, I think using WQ_FLAG_WOKEN is the right thing to do, and I<br />wouldn't call it "abuse". It's exactly what it's for.<br /><br />And that also allows us to just use finish_wait(), since we no longer<br />care as deeply about the waitlist state, we can just test that<br />WQ_FLAG_WOKEN at the end instead.<br /><br />So that actually makes the patch much more straightforward too. I<br />really disliked my open-coding there. Your suggestion fixes<br />everything.<br /><br />&gt; do we need SetPageWaiters() if trylock() succeeds ?<br /><br />We need to set it before the final page flag test, because otherwise<br />we might miss somebody just about to wake us up (ie we see the bit<br />set, but it's getting cleared on another CPU, and if PageWaiters isn't<br />set then that other CPU won't do the wakeup).<br /><br />So here's a v2, now as a "real" commit with a commit message and everything.<br /><br />Is there anything in particular you would like clarified, or something<br />else you find in this?<br /><br />Hugh - this should make your "patch 2" redundant. Is there any way to<br />test that in your environment that triggered it?<br /><br />This v2 isn't tested, but the core of it is the same, just with nice<br />cleanups from Oleg's suggestion, and an added comment about that<br />SetPageWaiters() thing.<br /><br />            Linus<br />From 71c48f2e50fcd56b6e941b46c0ea7dddd30ad146 Mon Sep 17 00:00:00 2001<br />From: Linus Torvalds &lt;torvalds&#64;linux-foundation.org&gt;<br />Date: Thu, 23 Jul 2020 10:16:49 -0700<br />Subject: [PATCH] mm: rewrite wait_on_page_bit_common() logic<br /><br />It turns out that wait_on_page_bit_common() had several problems,<br />ranging from just unfair behavioe due to re-queueing at the end of the<br />wait queue when re-trying, and an outright bug that could result in<br />missed wakeups (but probably never happened in practice).<br /><br />This rewrites the whole logic to avoid both issues, by simply moving the<br />logic to check (and possibly take) the bit lock into the wakeup path<br />instead.<br /><br />That makes everything much more straightforward, and means that we never<br />need to re-queue the wait entry: if we get woken up, we'll be notified<br />through WQ_FLAG_WOKEN, and the wait queue entry will have been removed,<br />and everything will have been done for us.<br /><br />Link: <a href="https://lore.kernel.org/lkml/CAHk-=wjJA2Z3kUFb-5s=6">https://lore.kernel.org/lkml/CAHk-=wjJA2Z3kUFb-5s=6</a>+n0qbTs8ELqKFt9B3pH85a8fGD73w&#64;mail.gmail.com/<br />Link: <a href="https://lore.kernel.org/lkml/alpine.LSU.2.11.2007221359450.1017&#64;eggly.anvils/">https://lore.kernel.org/lkml/alpine.LSU.2.11.2007221359450.1017&#64;eggly.anvils/</a><br />Reported-by: Oleg Nesterov &lt;oleg&#64;redhat.com&gt;<br />Reported-by: Hugh Dickins &lt;hughd&#64;google.com&gt;<br />Cc: Michal Hocko &lt;mhocko&#64;suse.com&gt;<br />Signed-off-by: Linus Torvalds &lt;torvalds&#64;linux-foundation.org&gt;<br />---<br /> mm/filemap.c | 119 ++++++++++++++++++++++++++++++---------------------<br /> 1 file changed, 71 insertions(+), 48 deletions(-)<br /><br />diff --git a/mm/filemap.c b/mm/filemap.c<br />index 385759c4ce4b..37f642c07106 100644<br />--- a/mm/filemap.c<br />+++ b/mm/filemap.c<br />&#64;&#64; -1002,6 +1002,7 &#64;&#64; struct wait_page_queue {<br /> <br /> static int wake_page_function(wait_queue_entry_t *wait, unsigned mode, int sync, void *arg)<br /> {<br />+	int ret;<br /> 	struct wait_page_key *key = arg;<br /> 	struct wait_page_queue *wait_page<br /> 		= container_of(wait, struct wait_page_queue, wait);<br />&#64;&#64; -1013,18 +1014,40 &#64;&#64; static int wake_page_function(wait_queue_entry_t *wait, unsigned mode, int sync,<br /> 	if (wait_page-&gt;bit_nr != key-&gt;bit_nr)<br /> 		return 0;<br /> <br />+	/* Stop walking if it's locked */<br />+	if (wait-&gt;flags &amp; WQ_FLAG_EXCLUSIVE) {<br />+		if (test_and_set_bit(key-&gt;bit_nr, &amp;key-&gt;page-&gt;flags))<br />+			return -1;<br />+	} else {<br />+		if (test_bit(key-&gt;bit_nr, &amp;key-&gt;page-&gt;flags))<br />+			return -1;<br />+	}<br />+<br /> 	/*<br />-	 * Stop walking if it's locked.<br />-	 * Is this safe if put_and_wait_on_page_locked() is in use?<br />-	 * Yes: the waker must hold a reference to this page, and if PG_locked<br />-	 * has now already been set by another task, that task must also hold<br />-	 * a reference to the *same usage* of this page; so there is no need<br />-	 * to walk on to wake even the put_and_wait_on_page_locked() callers.<br />+	 * Let the waiter know we have done the page flag<br />+	 * handling for it (and the return value lets the<br />+	 * wakeup logic count exclusive wakeup events).<br /> 	 */<br />-	if (test_bit(key-&gt;bit_nr, &amp;key-&gt;page-&gt;flags))<br />-		return -1;<br />+	ret = (wait-&gt;flags &amp; WQ_FLAG_EXCLUSIVE) != 0;<br />+	wait-&gt;flags |= WQ_FLAG_WOKEN;<br />+	wake_up_state(wait-&gt;private, mode);<br /> <br />-	return autoremove_wake_function(wait, mode, sync, key);<br />+	/*<br />+	 * Ok, we have successfully done what we're waiting for,<br />+	 * and we can unconditionally remove the wait entry.<br />+	 *<br />+	 * Note that this has to be the absolute last thing we do,<br />+	 * since after list_del_init(&amp;wait-&gt;entry) the wait entry<br />+	 * might be de-allocated and the process might even have<br />+	 * exited.<br />+	 *<br />+	 * We _really_ should have a "list_del_init_careful()" to<br />+	 * properly pair with the unlocked "list_empty_careful()"<br />+	 * in finish_wait().<br />+	 */<br />+	smp_mb();<br />+	list_del_init(&amp;wait-&gt;entry);<br />+	return ret;<br /> }<br /> <br /> static void wake_up_page_bit(struct page *page, int bit_nr)<br />&#64;&#64; -1103,16 +1126,22 &#64;&#64; enum behavior {<br /> 			 */<br /> };<br /> <br />+static inline int trylock_page_bit_common(struct page *page, int bit_nr,<br />+	enum behavior behavior)<br />+{<br />+	return behavior == EXCLUSIVE ?<br />+		!test_and_set_bit(bit_nr, &amp;page-&gt;flags) :<br />+		!test_bit(bit_nr, &amp;page-&gt;flags);<br />+}<br />+<br /> static inline int wait_on_page_bit_common(wait_queue_head_t *q,<br /> 	struct page *page, int bit_nr, int state, enum behavior behavior)<br /> {<br /> 	struct wait_page_queue wait_page;<br /> 	wait_queue_entry_t *wait = &amp;wait_page.wait;<br />-	bool bit_is_set;<br /> 	bool thrashing = false;<br /> 	bool delayacct = false;<br /> 	unsigned long pflags;<br />-	int ret = 0;<br /> <br /> 	if (bit_nr == PG_locked &amp;&amp;<br /> 	    !PageUptodate(page) &amp;&amp; PageWorkingset(page)) {<br />&#64;&#64; -1130,48 +1159,42 &#64;&#64; static inline int wait_on_page_bit_common(wait_queue_head_t *q,<br /> 	wait_page.page = page;<br /> 	wait_page.bit_nr = bit_nr;<br /> <br />+	/*<br />+	 * Add ourselves to the wait queue.<br />+	 *<br />+	 * NOTE! This is where we also check the page<br />+	 * state synchronously the last time to see that<br />+	 * somebody didn't just clear the bit. Do the<br />+	 * SetPageWaiters() before that to let anybody<br />+	 * we just miss know they need to wake us up.<br />+	 */<br />+	spin_lock_irq(&amp;q-&gt;lock);<br />+	SetPageWaiters(page);<br />+	if (!trylock_page_bit_common(page, bit_nr, behavior))<br />+		__add_wait_queue_entry_tail(q, wait);<br />+	spin_unlock_irq(&amp;q-&gt;lock);<br />+<br />+	/*<br />+	 * From now on, all the logic will be based on<br />+	 * whether the wait entry is on the queue or not,<br />+	 * and the page bit testing (and setting) will be<br />+	 * done by the wake function, not us.<br />+	 *<br />+	 * We can drop our reference to the page.<br />+	 */<br />+	if (behavior == DROP)<br />+		put_page(page);<br />+<br /> 	for (;;) {<br />-		spin_lock_irq(&amp;q-&gt;lock);<br />-<br />-		if (likely(list_empty(&amp;wait-&gt;entry))) {<br />-			__add_wait_queue_entry_tail(q, wait);<br />-			SetPageWaiters(page);<br />-		}<br />-<br /> 		set_current_state(state);<br /> <br />-		spin_unlock_irq(&amp;q-&gt;lock);<br />-<br />-		bit_is_set = test_bit(bit_nr, &amp;page-&gt;flags);<br />-		if (behavior == DROP)<br />-			put_page(page);<br />-<br />-		if (likely(bit_is_set))<br />-			io_schedule();<br />-<br />-		if (behavior == EXCLUSIVE) {<br />-			if (!test_and_set_bit_lock(bit_nr, &amp;page-&gt;flags))<br />-				break;<br />-		} else if (behavior == SHARED) {<br />-			if (!test_bit(bit_nr, &amp;page-&gt;flags))<br />-				break;<br />-		}<br />-<br />-		if (signal_pending_state(state, current)) {<br />-			ret = -EINTR;<br />+		if (signal_pending_state(state, current))<br /> 			break;<br />-		}<br /> <br />-		if (behavior == DROP) {<br />-			/*<br />-			 * We can no longer safely access page-&gt;flags:<br />-			 * even if CONFIG_MEMORY_HOTREMOVE is not enabled,<br />-			 * there is a risk of waiting forever on a page reused<br />-			 * for something that keeps it locked indefinitely.<br />-			 * But best check for -EINTR above before breaking.<br />-			 */<br />+		if (wait-&gt;flags &amp; WQ_FLAG_WOKEN)<br /> 			break;<br />-		}<br />+<br />+		io_schedule();<br /> 	}<br /> <br /> 	finish_wait(q, wait);<br />&#64;&#64; -1190,7 +1213,7 &#64;&#64; static inline int wait_on_page_bit_common(wait_queue_head_t *q,<br /> 	 * bother with signals either.<br /> 	 */<br /> <br />-	return ret;<br />+	return wait-&gt;flags &amp; WQ_FLAG_WOKEN ? 0 : -EINTR;<br /> }<br /> <br /> void wait_on_page_bit(struct page *page, int bit_nr)<br />-- <br />2.28.0.rc0.3.g1e25d3a62f<br /></pre><div align="center"><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></div></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerr.gif" width="32" height="32" alt="\" /></td></tr><tr><td align="right" valign="bottom">
