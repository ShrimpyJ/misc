    </div></td><td width="32">Â </td></tr><tr><td valign="top"><div class="es-jasper-simpleCalendar" baseurl="/lkml/"></div><div class="threadlist">Messages in this thread</div><ul class="threadlist"><li class="root"><a href="/lkml/2020/9/21/1969">First message in thread</a></li><li><a href="/lkml/2020/9/21/1969">Peter Xu</a><ul><li><a href="/lkml/2020/9/21/1970">Peter Xu</a><ul><li><a href="/lkml/2020/9/21/1999">Jann Horn</a><ul><li><a href="/lkml/2020/9/21/2039">Peter Xu</a><ul><li><a href="/lkml/2020/9/21/2048">Jann Horn</a></li></ul></li></ul></li><li><a href="/lkml/2020/9/21/2087">John Hubbard</a><ul><li><a href="/lkml/2020/9/21/2089">John Hubbard</a></li><li><a href="/lkml/2020/9/22/667">Peter Xu</a><ul><li><a href="/lkml/2020/9/22/751">Jason Gunthorpe</a></li><li><a href="/lkml/2020/9/22/845">John Hubbard</a></li><li><a href="/lkml/2020/9/22/906">John Hubbard</a></li></ul></li></ul></li><li><a href="/lkml/2020/9/26/415">kernel test robot</a></li></ul></li><li><a href="/lkml/2020/9/21/1971">Peter Xu</a><ul><li><a href="/lkml/2020/9/22/108">John Hubbard</a><ul><li><a href="/lkml/2020/9/22/681">Peter Xu</a></li></ul></li><li><a href="/lkml/2020/9/22/292">Oleg Nesterov</a><ul><li><a href="/lkml/2020/9/22/308">Oleg Nesterov</a><ul><li><a href="/lkml/2020/9/22/686">Peter Xu</a></li></ul></li></ul></li><li class="origin"><a href="/lkml/2020/9/23/1027">Linus Torvalds</a><ul><li><a href="/lkml/2020/9/23/1027">Linus Torvalds</a></li></ul></li></ul></li><li><a href="/lkml/2020/9/21/1972">Peter Xu</a></li><li><a href="/lkml/2020/9/21/1978">Peter Xu</a><ul><li><a href="/lkml/2020/9/21/2013">Jann Horn</a><ul><li><a href="/lkml/2020/9/21/2030">John Hubbard</a><ul><li><a href="/lkml/2020/9/21/2038">Jann Horn</a></li></ul></li><li><a href="/lkml/2020/9/21/2037">Peter Xu</a></li></ul></li><li><a href="/lkml/2020/9/22/432">Oleg Nesterov</a><ul><li><a href="/lkml/2020/9/22/473">Oleg Nesterov</a><ul><li><a href="/lkml/2020/9/22/719">Peter Xu</a></li></ul></li></ul></li><li><a href="/lkml/2020/9/24/638">Kirill Tkhai</a><ul><li><a href="/lkml/2020/9/24/861">Peter Xu</a></li></ul></li></ul></li><li><a href="/lkml/2020/9/21/1979">Peter Xu</a><ul><li><a href="/lkml/2020/9/22/83">John Hubbard</a><ul><li><a href="/lkml/2020/9/22/329">Jan Kara</a><ul><li><a href="/lkml/2020/9/22/974">John Hubbard</a></li></ul></li><li><a href="/lkml/2020/9/23/638">Peter Xu</a></li></ul></li><li><a href="/lkml/2020/9/22/445">Jason Gunthorpe</a><ul><li><a href="/lkml/2020/9/23/566">Peter Xu</a><ul><li><a href="/lkml/2020/9/23/639">Yang Shi</a></li><li><a href="/lkml/2020/9/23/749">Jason Gunthorpe</a></li></ul></li></ul></li></ul></li><li><a href="/lkml/2020/9/23/273">Leon Romanovsky</a><ul><li><a href="/lkml/2020/9/23/586">Peter Xu</a></li></ul></li></ul></li></ul><div class="threadlist">Patches in this message</div><ul class="threadlist"><li><a href="/lkml/diff/2020/9/23/754/1">Get diff 1</a></li><li><a href="/lkml/diff/2020/9/23/754/2">Get diff 2</a></li></ul></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerl.gif" width="32" height="32" alt="/" /></td><td class="c" rowspan="2" valign="top" style="padding-top: 1em"><table><tr><td colspan="2"><!--BuySellAds Zone Code--><div id="bsap_1297613" class="bsarocks bsap_5aa49c00cc06c882289a1dd6a5e50b62"></div><!--End BuySellAds Zone Code--></td></tr><tr><td><table><tr><td class="lp">From</td><td class="rp" itemprop="author">Linus Torvalds &lt;&gt;</td></tr><tr><td class="lp">Date</td><td class="rp" itemprop="datePublished">Wed, 23 Sep 2020 10:16:47 -0700</td></tr><tr><td class="lp">Subject</td><td class="rp" itemprop="name">Re: [PATCH 3/5] mm: Rework return value for copy_one_pte()</td></tr></table></td><td><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></td></tr></table><pre itemprop="articleBody">On Mon, Sep 21, 2020 at 2:18 PM Peter Xu &lt;peterx&#64;redhat.com&gt; wrote:<br />&gt;<br />&gt; There's one special path for copy_one_pte() with swap entries, in which<br />&gt; add_swap_count_continuation(GFP_ATOMIC) might fail.  In that case we'll return<br />&gt; the swp_entry_t so that the caller will release the locks and redo the same<br />&gt; thing with GFP_KERNEL.<br />&gt;<br />&gt; It's confusing when copy_one_pte() must return a swp_entry_t (even if all the<br />&gt; ptes are non-swap entries).  More importantly, we face other requirement to<br />&gt; extend this "we need to do something else, but without the locks held" case.<br />&gt;<br />&gt; Rework the return value into something easier to understand, as defined in enum<br />&gt; copy_mm_ret.  We'll pass the swp_entry_t back using the newly introduced union<br />&gt; copy_mm_data parameter.<br /><br />Ok, I'm reading this series, and I do hate this.<br /><br />And I think it's unnecessary.<br /><br />There's a very simple way to avoid this all: split out the<br />"!pte_present(pte)" case from the function entirely.<br /><br />That actually makes the code much more legible: that non-present case<br />is very different, and it's also unlikely() and causes deeper<br />indentation etc.<br /><br />Because it's unlikely, it probably also shouldn't be inline.<br /><br />That unlikely case is also why when then have that special<br />"out_set_pte" label, which should just go away and be copied into the<br />(now uninlined) function.<br /><br />Once that re-organization has been done, the second step is to then<br />just move the "pte_present()" check into the caller, and suddenly all<br />the ugly return value games will go entirely away.<br /><br />I'm attaching the two patches that do this here, but I do want to note<br />how that first patch is much more legible with "--ignore-all-space",<br />and then you really see that the diff is a _pure_ code movement thing.<br />Otherwise it looks like it's doing a big change.<br /><br />Comments?<br /><br />NOTE! The intent here is that now we can easily add new argument (a<br />pre-allocated page or NULL) and a return value to<br />"copy_present_page()": it can return "I needed a temporary page but<br />you hadn't allocated one yet" or "I used up the temporary page you<br />gave me" or "all good, keep the temporary page around for the future".<br /><br />But these two patches are very intentionally meant to be just "this<br />clearly changes NO semantics at all".<br /><br />                   Linus<br />From df3a57d1f6072d07978bafa7dbd9904cdf8f3e13 Mon Sep 17 00:00:00 2001<br />From: Linus Torvalds &lt;torvalds&#64;linux-foundation.org&gt;<br />Date: Wed, 23 Sep 2020 09:56:59 -0700<br />Subject: [PATCH 1/2] mm: split out the non-present case from copy_one_pte()<br /><br />This is a purely mechanical split of the copy_one_pte() function.  It's<br />not immediately obvious when looking at the diff because of the<br />indentation change, but the way to see what is going on in this commit<br />is to use the "-w" flag to not show pure whitespace changes, and you see<br />how the first part of copy_one_pte() is simply lifted out into a<br />separate function.<br /><br />And since the non-present case is marked unlikely, don't make the new<br />function be inlined.  Not that gcc really seems to care, since it looks<br />like it will inline it anyway due to the whole "single callsite for<br />static function" logic.  In fact, code generation with the function<br />split is almost identical to before.  But not marking it inline is the<br />right thing to do.<br /><br />This is pure prep-work and cleanup for subsequent changes.<br /><br />Signed-off-by: Linus Torvalds &lt;torvalds&#64;linux-foundation.org&gt;<br />---<br /> mm/memory.c | 152 ++++++++++++++++++++++++++++------------------------<br /> 1 file changed, 82 insertions(+), 70 deletions(-)<br /><br />diff --git a/mm/memory.c b/mm/memory.c<br />index 469af373ae76..31a3ab7d9aa3 100644<br />--- a/mm/memory.c<br />+++ b/mm/memory.c<br />&#64;&#64; -695,6 +695,84 &#64;&#64; struct page *vm_normal_page_pmd(struct vm_area_struct *vma, unsigned long addr,<br />  * covered by this vma.<br />  */<br /> <br />+static unsigned long<br />+copy_nonpresent_pte(struct mm_struct *dst_mm, struct mm_struct *src_mm,<br />+		pte_t *dst_pte, pte_t *src_pte, struct vm_area_struct *vma,<br />+		unsigned long addr, int *rss)<br />+{<br />+	unsigned long vm_flags = vma-&gt;vm_flags;<br />+	pte_t pte = *src_pte;<br />+	struct page *page;<br />+	swp_entry_t entry = pte_to_swp_entry(pte);<br />+<br />+	if (likely(!non_swap_entry(entry))) {<br />+		if (swap_duplicate(entry) &lt; 0)<br />+			return entry.val;<br />+<br />+		/* make sure dst_mm is on swapoff's mmlist. */<br />+		if (unlikely(list_empty(&amp;dst_mm-&gt;mmlist))) {<br />+			spin_lock(&amp;mmlist_lock);<br />+			if (list_empty(&amp;dst_mm-&gt;mmlist))<br />+				list_add(&amp;dst_mm-&gt;mmlist,<br />+						&amp;src_mm-&gt;mmlist);<br />+			spin_unlock(&amp;mmlist_lock);<br />+		}<br />+		rss[MM_SWAPENTS]++;<br />+	} else if (is_migration_entry(entry)) {<br />+		page = migration_entry_to_page(entry);<br />+<br />+		rss[mm_counter(page)]++;<br />+<br />+		if (is_write_migration_entry(entry) &amp;&amp;<br />+				is_cow_mapping(vm_flags)) {<br />+			/*<br />+			 * COW mappings require pages in both<br />+			 * parent and child to be set to read.<br />+			 */<br />+			make_migration_entry_read(&amp;entry);<br />+			pte = swp_entry_to_pte(entry);<br />+			if (pte_swp_soft_dirty(*src_pte))<br />+				pte = pte_swp_mksoft_dirty(pte);<br />+			if (pte_swp_uffd_wp(*src_pte))<br />+				pte = pte_swp_mkuffd_wp(pte);<br />+			set_pte_at(src_mm, addr, src_pte, pte);<br />+		}<br />+	} else if (is_device_private_entry(entry)) {<br />+		page = device_private_entry_to_page(entry);<br />+<br />+		/*<br />+		 * Update rss count even for unaddressable pages, as<br />+		 * they should treated just like normal pages in this<br />+		 * respect.<br />+		 *<br />+		 * We will likely want to have some new rss counters<br />+		 * for unaddressable pages, at some point. But for now<br />+		 * keep things as they are.<br />+		 */<br />+		get_page(page);<br />+		rss[mm_counter(page)]++;<br />+		page_dup_rmap(page, false);<br />+<br />+		/*<br />+		 * We do not preserve soft-dirty information, because so<br />+		 * far, checkpoint/restore is the only feature that<br />+		 * requires that. And checkpoint/restore does not work<br />+		 * when a device driver is involved (you cannot easily<br />+		 * save and restore device driver state).<br />+		 */<br />+		if (is_write_device_private_entry(entry) &amp;&amp;<br />+		    is_cow_mapping(vm_flags)) {<br />+			make_device_private_entry_read(&amp;entry);<br />+			pte = swp_entry_to_pte(entry);<br />+			if (pte_swp_uffd_wp(*src_pte))<br />+				pte = pte_swp_mkuffd_wp(pte);<br />+			set_pte_at(src_mm, addr, src_pte, pte);<br />+		}<br />+	}<br />+	set_pte_at(dst_mm, addr, dst_pte, pte);<br />+	return 0;<br />+}<br />+<br /> static inline unsigned long<br /> copy_one_pte(struct mm_struct *dst_mm, struct mm_struct *src_mm,<br /> 		pte_t *dst_pte, pte_t *src_pte, struct vm_area_struct *vma,<br />&#64;&#64; -705,75 +783,10 &#64;&#64; copy_one_pte(struct mm_struct *dst_mm, struct mm_struct *src_mm,<br /> 	struct page *page;<br /> <br /> 	/* pte contains position in swap or file, so copy. */<br />-	if (unlikely(!pte_present(pte))) {<br />-		swp_entry_t entry = pte_to_swp_entry(pte);<br />-<br />-		if (likely(!non_swap_entry(entry))) {<br />-			if (swap_duplicate(entry) &lt; 0)<br />-				return entry.val;<br />-<br />-			/* make sure dst_mm is on swapoff's mmlist. */<br />-			if (unlikely(list_empty(&amp;dst_mm-&gt;mmlist))) {<br />-				spin_lock(&amp;mmlist_lock);<br />-				if (list_empty(&amp;dst_mm-&gt;mmlist))<br />-					list_add(&amp;dst_mm-&gt;mmlist,<br />-							&amp;src_mm-&gt;mmlist);<br />-				spin_unlock(&amp;mmlist_lock);<br />-			}<br />-			rss[MM_SWAPENTS]++;<br />-		} else if (is_migration_entry(entry)) {<br />-			page = migration_entry_to_page(entry);<br />-<br />-			rss[mm_counter(page)]++;<br />-<br />-			if (is_write_migration_entry(entry) &amp;&amp;<br />-					is_cow_mapping(vm_flags)) {<br />-				/*<br />-				 * COW mappings require pages in both<br />-				 * parent and child to be set to read.<br />-				 */<br />-				make_migration_entry_read(&amp;entry);<br />-				pte = swp_entry_to_pte(entry);<br />-				if (pte_swp_soft_dirty(*src_pte))<br />-					pte = pte_swp_mksoft_dirty(pte);<br />-				if (pte_swp_uffd_wp(*src_pte))<br />-					pte = pte_swp_mkuffd_wp(pte);<br />-				set_pte_at(src_mm, addr, src_pte, pte);<br />-			}<br />-		} else if (is_device_private_entry(entry)) {<br />-			page = device_private_entry_to_page(entry);<br />-<br />-			/*<br />-			 * Update rss count even for unaddressable pages, as<br />-			 * they should treated just like normal pages in this<br />-			 * respect.<br />-			 *<br />-			 * We will likely want to have some new rss counters<br />-			 * for unaddressable pages, at some point. But for now<br />-			 * keep things as they are.<br />-			 */<br />-			get_page(page);<br />-			rss[mm_counter(page)]++;<br />-			page_dup_rmap(page, false);<br />-<br />-			/*<br />-			 * We do not preserve soft-dirty information, because so<br />-			 * far, checkpoint/restore is the only feature that<br />-			 * requires that. And checkpoint/restore does not work<br />-			 * when a device driver is involved (you cannot easily<br />-			 * save and restore device driver state).<br />-			 */<br />-			if (is_write_device_private_entry(entry) &amp;&amp;<br />-			    is_cow_mapping(vm_flags)) {<br />-				make_device_private_entry_read(&amp;entry);<br />-				pte = swp_entry_to_pte(entry);<br />-				if (pte_swp_uffd_wp(*src_pte))<br />-					pte = pte_swp_mkuffd_wp(pte);<br />-				set_pte_at(src_mm, addr, src_pte, pte);<br />-			}<br />-		}<br />-		goto out_set_pte;<br />-	}<br />+	if (unlikely(!pte_present(pte)))<br />+		return copy_nonpresent_pte(dst_mm, src_mm,<br />+					   dst_pte, src_pte, vma,<br />+					   addr, rss);<br /> <br /> 	/*<br /> 	 * If it's a COW mapping, write protect it both<br />&#64;&#64; -807,7 +820,6 &#64;&#64; copy_one_pte(struct mm_struct *dst_mm, struct mm_struct *src_mm,<br /> 		rss[mm_counter(page)]++;<br /> 	}<br /> <br />-out_set_pte:<br /> 	set_pte_at(dst_mm, addr, dst_pte, pte);<br /> 	return 0;<br /> }<br />-- <br />2.28.0.218.gc12ef3d349<br />From 79a1971c5f14ea3a6e2b0c4caf73a1760db7cab8 Mon Sep 17 00:00:00 2001<br />From: Linus Torvalds &lt;torvalds&#64;linux-foundation.org&gt;<br />Date: Wed, 23 Sep 2020 10:04:16 -0700<br />Subject: [PATCH 2/2] mm: move the copy_one_pte() pte_present check into the<br /> caller<br /><br />This completes the split of the non-present and present pte cases by<br />moving the check for the source pte being present into the single<br />caller, which also means that we clearly separate out the very different<br />return value case for a non-present pte.<br /><br />The present pte case currently always succeeds.<br /><br />This is a pure code re-organization with no semantic change: the intent<br />is to make it much easier to add a new return case to the present pte<br />case for when we do early COW at page table copy time.<br /><br />This was split out from the previous commit simply to make it easy to<br />visually see that there were no semantic changes from this code<br />re-organization.<br /><br />Signed-off-by: Linus Torvalds &lt;torvalds&#64;linux-foundation.org&gt;<br />---<br /> mm/memory.c | 24 ++++++++++++------------<br /> 1 file changed, 12 insertions(+), 12 deletions(-)<br /><br />diff --git a/mm/memory.c b/mm/memory.c<br />index 31a3ab7d9aa3..e315b1f1ef08 100644<br />--- a/mm/memory.c<br />+++ b/mm/memory.c<br />&#64;&#64; -773,8 +773,8 &#64;&#64; copy_nonpresent_pte(struct mm_struct *dst_mm, struct mm_struct *src_mm,<br /> 	return 0;<br /> }<br /> <br />-static inline unsigned long<br />-copy_one_pte(struct mm_struct *dst_mm, struct mm_struct *src_mm,<br />+static inline void<br />+copy_present_pte(struct mm_struct *dst_mm, struct mm_struct *src_mm,<br /> 		pte_t *dst_pte, pte_t *src_pte, struct vm_area_struct *vma,<br /> 		unsigned long addr, int *rss)<br /> {<br />&#64;&#64; -782,12 +782,6 &#64;&#64; copy_one_pte(struct mm_struct *dst_mm, struct mm_struct *src_mm,<br /> 	pte_t pte = *src_pte;<br /> 	struct page *page;<br /> <br />-	/* pte contains position in swap or file, so copy. */<br />-	if (unlikely(!pte_present(pte)))<br />-		return copy_nonpresent_pte(dst_mm, src_mm,<br />-					   dst_pte, src_pte, vma,<br />-					   addr, rss);<br />-<br /> 	/*<br /> 	 * If it's a COW mapping, write protect it both<br /> 	 * in the parent and the child<br />&#64;&#64; -821,7 +815,6 &#64;&#64; copy_one_pte(struct mm_struct *dst_mm, struct mm_struct *src_mm,<br /> 	}<br /> <br /> 	set_pte_at(dst_mm, addr, dst_pte, pte);<br />-	return 0;<br /> }<br /> <br /> static int copy_pte_range(struct mm_struct *dst_mm, struct mm_struct *src_mm,<br />&#64;&#64; -863,10 +856,17 &#64;&#64; static int copy_pte_range(struct mm_struct *dst_mm, struct mm_struct *src_mm,<br /> 			progress++;<br /> 			continue;<br /> 		}<br />-		entry.val = copy_one_pte(dst_mm, src_mm, dst_pte, src_pte,<br />+		if (unlikely(!pte_present(*src_pte))) {<br />+			entry.val = copy_nonpresent_pte(dst_mm, src_mm,<br />+							dst_pte, src_pte,<br /> 							vma, addr, rss);<br />-		if (entry.val)<br />-			break;<br />+			if (entry.val)<br />+				break;<br />+			progress += 8;<br />+			continue;<br />+		}<br />+		copy_present_pte(dst_mm, src_mm, dst_pte, src_pte,<br />+				 vma, addr, rss);<br /> 		progress += 8;<br /> 	} while (dst_pte++, src_pte++, addr += PAGE_SIZE, addr != end);<br /> <br />-- <br />2.28.0.218.gc12ef3d349<br /></pre><div align="center"><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></div></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerr.gif" width="32" height="32" alt="\" /></td></tr><tr><td align="right" valign="bottom">
