    </div></td><td width="32">Â </td></tr><tr><td valign="top"><div class="es-jasper-simpleCalendar" baseurl="/lkml/"></div><div class="threadlist">Messages in this thread</div><ul class="threadlist"><li class="root"><a href="/lkml/2014/11/14/656">First message in thread</a></li><li><a href="/lkml/2014/12/18/640">Linus Torvalds</a><ul><li><a href="/lkml/2014/12/19/146">Peter Zijlstra</a></li><li><a href="/lkml/2014/12/19/244">Dave Jones</a><ul><li><a href="/lkml/2014/12/19/250">Chris Mason</a></li><li class="origin"><a href="/lkml/2014/12/19/334">Linus Torvalds</a><ul><li><a href="/lkml/2014/12/19/334">Peter Zijlstra</a></li><li><a href="/lkml/2014/12/19/335">Linus Torvalds</a><ul><li><a href="/lkml/2014/12/19/352">Linus Torvalds</a></li></ul></li><li><a href="/lkml/2014/12/19/349">Chris Mason</a><ul><li><a href="/lkml/2014/12/19/350">Dave Jones</a></li><li><a href="/lkml/2014/12/19/405">Thomas Gleixner</a></li></ul></li><li><a href="/lkml/2014/12/19/404">Thomas Gleixner</a><ul><li><a href="/lkml/2014/12/19/417">Linus Torvalds</a></li></ul></li></ul></li></ul></li></ul></li></ul></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerl.gif" width="32" height="32" alt="/" /></td><td class="c" rowspan="2" valign="top" style="padding-top: 1em"><table><tr><td colspan="2"><!--BuySellAds Zone Code--><div id="bsap_1297613" class="bsarocks bsap_5aa49c00cc06c882289a1dd6a5e50b62"></div><!--End BuySellAds Zone Code--></td></tr><tr><td><table><tr><td class="lp">Date</td><td class="rp" itemprop="datePublished">Fri, 19 Dec 2014 11:15:21 -0800</td></tr><tr><td class="lp">Subject</td><td class="rp" itemprop="name">Re: frequent lockups in 3.18rc4</td></tr><tr><td class="lp">From</td><td class="rp" itemprop="author">Linus Torvalds &lt;&gt;</td></tr></table></td><td><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></td></tr></table><pre itemprop="articleBody">On Fri, Dec 19, 2014 at 6:55 AM, Dave Jones &lt;davej&#64;redhat.com&gt; wrote:<br />&gt;<br />&gt; Wish DEBUG_SPINLOCK disabled, I see the same behaviour.<br />&gt; Lots of traces spewed, but it seems to run and run (at least so far).<br /><br />Ok, so it's not spinlock debugging.<br /><br />There are some interesting patters here, once again. Lookie:<br /><br />     RIP: 0010:   generic_exec_single+0xea/0x1b0<br />     RIP: 0010:   generic_exec_single+0xee/0x1b0<br />     RIP: 0010:   generic_exec_single+0xea/0x1b0<br />     RIP: 0010:   generic_exec_single+0xea/0x1b0<br />     RIP: 0010:   generic_exec_single+0xee/0x1b0<br />     RIP: 0010:   generic_exec_single+0xee/0x1b0<br />     RIP: 0010:   generic_exec_single+0xea/0x1b0<br />     sched: RT throttling activated<br />     RIP: 0010:   __slab_alloc+0x4e5/0x53b<br />     RIP: 0010:   copy_user_enhanced_fast_string+0x5/0x10<br />     RIP: 0033:   0x412fc8<br />     RIP: 0010:   clear_page_c_e+0x7/0x10<br />     RIP: 0010:   cpuidle_enter_state+0x79/0x190<br />     RIP: 0010:   __slab_alloc+0x4e5/0x53b<br />     RIP: 0010:   find_get_pid+0x1e/0x30<br /><br />so now copy_page_range() is gone, but every single case before the RT<br />throttling is activated is that zap_page_range() followed by the TLB<br />invalidate that we saw last time.<br /><br />And after RT throttling, it's random (not even always trinity), but<br />that's probably because the watchdog thread doesn't run reliably any<br />more.<br /><br />Another pattern in this one: it's CPU#1 that is stuck. Every single<br />time. There are stack traces from other CPU's, but they are all the<br />NMI broadcast *due* to the soft lockup on CPU#1.<br /><br />And that is true even after the RT throttling thing.<br /><br />And let's take another look at your previous one (with lock debugging,<br />but that config detail is clearly not that important - it hasn't<br />really changed anything major except make that lock very visible):<br /><br />     RIP: 0010:   lock_acquire+0xb4/0x120<br />     RIP: 0010:   lock_acquire+0xb4/0x120<br />     RIP: 0010:   generic_exec_single+0xee/0x1b0<br />     RIP: 0010:   lock_acquire+0xb4/0x120<br />     RIP: 0010:   lock_acquire+0xb4/0x120<br />     RIP: 0010:   lock_acquire+0xb4/0x120<br />     RIP: 0010:   lock_acquire+0xb4/0x120<br />     RIP: 0010:   lock_acquire+0xb4/0x120<br />     RIP: 0010:   lock_acquire+0xb4/0x120<br />     sched: RT throttling activated<br />     RIP: 0010:   shmem_write_end+0x65/0xf0<br />     RIP: 0010:   _raw_spin_unlock_irqrestore+0x38/0x60<br />     RIP: 0010:   copy_user_enhanced_fast_string+0x5/0x10<br />     RIP: 0010:   copy_user_enhanced_fast_string+0x5/0x10<br />     RIP: 0010:   __slab_alloc+0x52f/0x58f<br />     RIP: 0010:   map_id_up+0x9/0x80<br />     RIP: 0010:   cpuidle_enter_state+0x79/0x190<br />     RIP: 0010:   unmap_single_vma+0x7d9/0x900<br />     RIP: 0010:   cpuidle_enter_state+0x79/0x190<br /><br />same pattern: after the RT throttling, it's random because the<br />watchdog is no longer sane, before that it's always reliably either<br />the lock_acquire as part of copy_page_range(), or it's that TLB flush<br />as part of zap_page_range().<br /><br />And the CPU patterns are interesting too:<br /><br />   NMI watchdog: BUG: soft lockup - CPU#1 stuck for 22s! [trinity-c195:20128]<br />   NMI watchdog: BUG: soft lockup - CPU#1 stuck for 22s! [trinity-c195:20128]<br />   NMI watchdog: BUG: soft lockup - CPU#2 stuck for 22s! [trinity-c154:22823]<br />   NMI watchdog: BUG: soft lockup - CPU#1 stuck for 22s! [trinity-c195:20128]<br />   NMI watchdog: BUG: soft lockup - CPU#1 stuck for 22s! [trinity-c195:20128]<br />   NMI watchdog: BUG: soft lockup - CPU#1 stuck for 22s! [trinity-c195:20128]<br />   NMI watchdog: BUG: soft lockup - CPU#1 stuck for 22s! [trinity-c195:20128]<br />   NMI watchdog: BUG: soft lockup - CPU#1 stuck for 22s! [trinity-c195:20128]<br />   NMI watchdog: BUG: soft lockup - CPU#1 stuck for 22s! [trinity-c195:20128]<br /><br />CPU#1 again, *except* for the third lockup, which happens to match the<br />exact same pattern of copy_page_range() (CPU#1) vs zap_page_range()<br />(CPU#2).<br /><br />It's also the case that before the RT throttling, it really does seem<br />to be one particular thread (ie trinity-c195.20128 does the<br />copy_page_range on your previous one, and in the newer one it's<br />trinity-c205:636 that does the zap_page_range(). So those threads<br />really seem to be stuck for real. The fact that they *eventually* go<br />away at all is interesting in itself.<br /><br />And that "generic_exec_single()" place where it is stuck is the<br />instruction after the "pause" (aka "cpu_relax()") in the final<br />"csd_lock_wait()" once more. So it's waiting on some CPU to pick up<br />the IPI, and that never happens.<br /><br />Here's another pattern. In your latest thing, every single time that<br />CPU1 is waiting for some other CPU to pick up the IPI, we have CPU0<br />doing this:<br /><br />[24998.060963] NMI backtrace for cpu 0<br />[24998.061989] CPU: 0 PID: 2940 Comm: trinity-c150 Not tainted 3.18.0+ #108<br />[24998.064073] task: ffff8801bf3536b0 ti: ffff880197e0c000 task.ti:<br />ffff880197e0c000<br />[24998.065137] RIP: 0010:[&lt;ffffffff8103e006&gt;]  [&lt;ffffffff8103e006&gt;]<br />read_hpet+0x16/0x20<br />[24998.083577]  [&lt;ffffffff810e0d3e&gt;] ktime_get+0x3e/0xa0<br />[24998.084450]  [&lt;ffffffff810e9cd3&gt;] tick_sched_timer+0x23/0x160<br />[24998.085315]  [&lt;ffffffff810daf96&gt;] __run_hrtimer+0x76/0x1f0<br />[24998.086173]  [&lt;ffffffff810e9cb0&gt;] ? tick_init_highres+0x20/0x20<br />[24998.087025]  [&lt;ffffffff810db2e7&gt;] hrtimer_interrupt+0x107/0x260<br />[24998.087877]  [&lt;ffffffff81031a4b&gt;] local_apic_timer_interrupt+0x3b/0x70<br />[24998.088732]  [&lt;ffffffff8179bca5&gt;] smp_apic_timer_interrupt+0x45/0x60<br />[24998.089583]  [&lt;ffffffff8179a0df&gt;] apic_timer_interrupt+0x6f/0x80<br />[24998.090435]  &lt;EOI&gt;<br />[24998.091279]  [&lt;ffffffff810da66e&gt;] ? __remove_hrtimer+0x4e/0xa0<br />[24998.092118]  [&lt;ffffffff812c7c7a&gt;] ? ipcget+0x8a/0x1e0<br />[24998.092951]  [&lt;ffffffff812c7c6c&gt;] ? ipcget+0x7c/0x1e0<br />[24998.093779]  [&lt;ffffffff812c8d6d&gt;] SyS_msgget+0x4d/0x70<br /><br />and I think that's the smoking gun. The reason CPU0 isn't picking up<br />any IPI's is because it is in some endless loop around read_hpet().<br /><br />There is even time information in the register dump:<br /><br /> RAX: 0000000061fece8a RBX: 0000000000510792 RCX: 0000000000000000<br /> RAX: 0000000079e588fc RBX: 0000000000511d6e RCX: 0000000000000000<br /> RAX: 0000000091ca7f65 RBX: 0000000000513346 RCX: 0000000000000000<br /> RAX: 00000000a9afbd0d RBX: 000000000051491e RCX: 0000000000000000<br /> RAX: 00000000cbd1340c RBX: 000000000051684a RCX: 0000000000000000<br /> RAX: 00000000fb9d303f RBX: 00000000005193fc RCX: 0000000000000000<br /> RAX: 000000002b67efe4 RBX: 000000000051c224 RCX: 0000000000000004<br /><br />That RAX value is the value we just read from the HPET, and RBX seems<br />to be monotonically increasing too, so it's likely the sequence<br />counter in ktime_get().<br /><br />So it's not stuck *inside* read_hpet(), and it's almost certainly not<br />the loop over the sequence counter in ktime_get() either (it's not<br />increasing *that* quickly). But some basically infinite __run_hrtimer<br />thing or something?<br /><br />In your earlier trace (with spinlock debugging), the softlockup<br />detection was in lock_acquire for copy_page_range(), but CPU2 was<br />always in that "generic_exec_single" due to a TLB flush from that<br />zap_page_range thing again. But there are no timer traces from that<br />one, so I dunno.<br /><br />Anyway, I do think we're getting somewhere. Your traces are<br />interesting and have real patterns in them. Which is very different<br />from the mess it used to be.<br /><br />                            Linus<br /><br /><br /></pre><div align="center"><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></div></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerr.gif" width="32" height="32" alt="\" /></td></tr><tr><td align="right" valign="bottom">
