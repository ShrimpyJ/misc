    </div></td><td width="32">Â </td></tr><tr><td valign="top"><div class="es-jasper-simpleCalendar" baseurl="/lkml/"></div><div class="threadlist">Messages in this thread</div><ul class="threadlist"><li class="root"><a href="/lkml/2014/11/14/656">First message in thread</a></li><li><a href="/lkml/2014/12/14/305">Dave Jones</a><ul><li><a href="/lkml/2014/12/14/311">Linus Torvalds</a><ul><li><a href="/lkml/2014/12/14/313">Dave Jones</a></li><li class="origin"><a href="/lkml/2014/12/15/20">Linus Torvalds</a><ul><li><a href="/lkml/2014/12/15/20">Dave Jones</a><ul><li><a href="/lkml/2014/12/15/651">Linus Torvalds</a></li></ul></li><li><a href="/lkml/2014/12/15/279">Borislav Petkov</a></li><li><a href="/lkml/2014/12/18/447">Andy Lutomirski</a><ul><li><a href="/lkml/2014/12/18/458">Linus Torvalds</a></li><li><a href="/lkml/2014/12/18/459">Dave Jones</a></li></ul></li></ul></li><li><a href="/lkml/2014/12/17/342">Dave Jones</a><ul><li><a href="/lkml/2014/12/17/365">Dave Jones</a><ul><li><a href="/lkml/2014/12/17/369">Dave Jones</a></li><li><a href="/lkml/2014/12/17/379">Linus Torvalds</a></li></ul></li><li><a href="/lkml/2014/12/17/374">Linus Torvalds</a></li></ul></li></ul></li></ul></li></ul></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerl.gif" width="32" height="32" alt="/" /></td><td class="c" rowspan="2" valign="top" style="padding-top: 1em"><table><tr><td colspan="2"><!--BuySellAds Zone Code--><script type="text/javascript" src="//pagead2.googlesyndication.com/pagead/show_ads.js"></script><!--End BuySellAds Zone Code--></td></tr><tr><td><table><tr><td class="lp">Date</td><td class="rp" itemprop="datePublished">Sun, 14 Dec 2014 21:47:26 -0800</td></tr><tr><td class="lp">Subject</td><td class="rp" itemprop="name">Re: frequent lockups in 3.18rc4</td></tr><tr><td class="lp">From</td><td class="rp" itemprop="author">Linus Torvalds &lt;&gt;</td></tr></table></td><td><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></td></tr></table><pre itemprop="articleBody">On Sun, Dec 14, 2014 at 4:38 PM, Linus Torvalds<br />&lt;torvalds&#64;linux-foundation.org&gt; wrote:<br />&gt;<br />&gt; Can anybody make sense of that backtrace, keeping in mind that we're<br />&gt; looking for some kind of endless loop where we don't make progress?<br /><br />So looking at all the backtraces, which is kind of messy because<br />there's some missing data (presumably buffers overflowed from all the<br />CPU's printing at the same time), it looks  like:<br /><br /> - CPU 0 is missing. No idea why.<br /> - CPU's 1-3 all have the same trace for<br /><br />    int_signal -&gt;<br />    do_notify_resume -&gt;<br />    do_signal -&gt;<br />      ....<br />    page_fault -&gt;<br />    do_page_fault<br /><br />and "save_xstate_sig+0x81" shows up on all stacks, although only on<br />CPU1 does it show up as a "guaranteed" part of the stack chain (ie it<br />matches frame pointer data too). CPU1 also has that __clear_user show<br />up (which is called from save_xstate_sig), but not other CPU's.  CPU2<br />and CPU3 have "save_xstate_sig+0x98" in addition to that +0x81 thing.<br /><br />My guess is that "save_xstate_sig+0x81" is the instruction after the<br />__clear_user call, and that CPU1 took the fault in __clear_user(),<br />while CPU2 and CPU3 took the fault at "save_xstate_sig+0x98" instead,<br />which I'd guess is the<br /><br />        xsave64 (%rdi)<br /><br />and in fact, with CONFIG_FTRACE on, my own kernel build gives exactly<br />those two offsets for those things in save_xstate_sig().<br /><br />So I'm pretty certain that on all three CPU's, we had page faults for<br />save_xstate_sig() accessing user space, with the only difference being<br />that on CPU1 it happened from __clear_user, while on CPU's 2/3 it<br />happened on the xsaveq instruction itself.<br /><br />That sounds like much more than coincidence. I have no idea where CPU0<br />is hiding, and all CPU's were at different stages of actually handling<br />the fault, but that's to be expected if the page fault just keeps<br />repeating.<br /><br />In fact, CPU2 shows up three different times, and the call trace<br />changes in between, so it's "making progress", just never getting out<br />of that loop. The traces are<br /><br />    pagecache_get_page+0x0/0x220<br />    ? lookup_swap_cache+0x2a/0x70<br />    handle_mm_fault+0x401/0xe90<br />    ? __do_page_fault+0x198/0x5c0<br />    __do_page_fault+0x1fc/0x5c0<br />    ? trace_hardirqs_on_thunk+0x3a/0x3f<br />    ? __do_softirq+0x1ed/0x310<br />    ? retint_restore_args+0xe/0xe<br />    ? trace_hardirqs_off_thunk+0x3a/0x3c<br />    do_page_fault+0xc/0x10<br />    page_fault+0x22/0x30<br />    ? save_xstate_sig+0x98/0x220<br />    ? save_xstate_sig+0x81/0x220<br />    do_signal+0x5c7/0x740<br />    ? _raw_spin_unlock_irq+0x30/0x40<br />    do_notify_resume+0x65/0x80<br />    ? trace_hardirqs_on_thunk+0x3a/0x3f<br />    int_signal+0x12/0x17<br /><br />and<br /><br />    ? __lock_acquire.isra.31+0x22c/0x9f0<br />    ? lock_acquire+0xb4/0x120<br />    ? __do_page_fault+0x198/0x5c0<br />    down_read_trylock+0x5a/0x60<br />    ? __do_page_fault+0x198/0x5c0<br />    __do_page_fault+0x198/0x5c0<br />    ? __do_softirq+0x1ed/0x310<br />    ? retint_restore_args+0xe/0xe<br />    ? __do_page_fault+0xd8/0x5c0<br />    ? trace_hardirqs_off_thunk+0x3a/0x3c<br />    do_page_fault+0xc/0x10<br />    page_fault+0x22/0x30<br />    ? save_xstate_sig+0x98/0x220<br />    ? save_xstate_sig+0x81/0x220<br />    do_signal+0x5c7/0x740<br />    ? _raw_spin_unlock_irq+0x30/0x40<br />    do_notify_resume+0x65/0x80<br />    ? trace_hardirqs_on_thunk+0x3a/0x3f<br />    int_signal+0x12/0x17<br /><br />and<br /><br />    lock_acquire+0x40/0x120<br />    down_read_trylock+0x5a/0x60<br />    ? __do_page_fault+0x198/0x5c0<br />    __do_page_fault+0x198/0x5c0<br />    ? trace_hardirqs_on_thunk+0x3a/0x3f<br />    ? trace_hardirqs_on_thunk+0x3a/0x3f<br />    ? __do_softirq+0x1ed/0x310<br />    ? retint_restore_args+0xe/0xe<br />    ? trace_hardirqs_off_thunk+0x3a/0x3c<br />    do_page_fault+0xc/0x10<br />    page_fault+0x22/0x30<br />    ? save_xstate_sig+0x98/0x220<br />    ? save_xstate_sig+0x81/0x220<br />    do_signal+0x5c7/0x740<br />    ? _raw_spin_unlock_irq+0x30/0x40<br />    do_notify_resume+0x65/0x80<br />    ? trace_hardirqs_on_thunk+0x3a/0x3f<br />    int_signal+0x12/0x17<br /><br />so it's always in __do_page_fault, but at sometimes it has gotten into<br />handle_mm_fault too. So it really really looks like it is taking an<br />endless stream of page faults on that "xsaveq" instruction. Presumably<br />the page faulting never actually makes any progress, even though it<br />*thinks* the page tables are fine.<br /><br />DaveJ - you've seen that "endless page faults" behavior before. You<br />had a few traces that showed it. That was in that whole "pipe/page<br />fault oddness." email thread, where you would get endless faults in<br />copy_page_to_iter() with an error_code=0x2.<br /><br />That was the one where I chased it down to "page table entry must be<br />marked with _PAGE_PROTNONE", but VM_WRITE in the vma, because your<br />machine was alive enough that you got traces out of the endless loop.<br /><br />Very odd.<br /><br />              Linus<br /><br /><br /></pre><div align="center"><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></div></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerr.gif" width="32" height="32" alt="\" /></td></tr><tr><td align="right" valign="bottom">
