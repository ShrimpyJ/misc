    </div></td><td width="32">Â </td></tr><tr><td valign="top"><div class="es-jasper-simpleCalendar" baseurl="/lkml/"></div><div class="threadlist">Messages in this thread</div><ul class="threadlist"><li class="root"><a href="/lkml/2014/11/27/472">First message in thread</a></li><li><a href="/lkml/2014/11/27/472">Torvald Riegel</a><ul><li class="origin"><a href="/lkml/2014/12/1/250">Linus Torvalds</a><ul><li><a href="/lkml/2014/12/1/250">Torvald Riegel</a><ul><li><a href="/lkml/2014/12/1/582">Linus Torvalds</a><ul><li><a href="/lkml/2014/12/1/685">Torvald Riegel</a></li></ul></li></ul></li><li><a href="/lkml/2015/2/11/245">Jiri Kosina</a></li></ul></li></ul></li></ul></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerl.gif" width="32" height="32" alt="/" /></td><td class="c" rowspan="2" valign="top" style="padding-top: 1em"><table><tr><td colspan="2"><!--BuySellAds Zone Code--><div id="bsap_1297613" class="bsarocks bsap_5aa49c00cc06c882289a1dd6a5e50b62"></div><!--End BuySellAds Zone Code--></td></tr><tr><td><table><tr><td class="lp">Date</td><td class="rp" itemprop="datePublished">Thu, 27 Nov 2014 11:38:11 -0800</td></tr><tr><td class="lp">Subject</td><td class="rp" itemprop="name">Re: POSIX mutex destruction requirements vs. futexes</td></tr><tr><td class="lp">From</td><td class="rp" itemprop="author">Linus Torvalds &lt;&gt;</td></tr></table></td><td><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></td></tr></table><pre itemprop="articleBody">On Thu, Nov 27, 2014 at 6:27 AM, Torvald Riegel &lt;triegel&#64;redhat.com&gt; wrote:<br />&gt;<br />&gt; Using reference-counting in critical sections to decide when the mutex<br />&gt; protecting the critical section can be destroyed has been recently<br />&gt; discussed on LKML.   For example, something like this is supposed to<br />&gt; work:<br />&gt;<br />&gt; int free = 0;<br />&gt;<br />&gt;     mutex_lock(&amp;s-&gt;lock);<br />&gt;     if (--s-&gt;refcount == 0)<br />&gt;         free = 1<br />&gt;     mutex_unlock(&amp;s-&gt;lock);<br />&gt;     if (free)<br />&gt;         kfree(s);<br /><br />Yeah, this is a nasty case. We've had this bug in the kernel, and only<br />allow self-locking data structures with spinlocks (in which the unlock<br />operation is guaranteed to release the lock and never touch the data<br />structure afterwards in any way - no "unlock fastpath followed by<br />still touching it").<br /><br /><br />&gt; This requirement is tough to implement for glibc -- or with futexes in<br />&gt; general -- because what one would like to do in a mutex unlock<br />&gt; implementation based on futexes is the following, roughly:<br />&gt;<br />&gt; lock():<br />&gt;   while (1) {<br />&gt;     // fast path: assume uncontended lock<br />&gt;     if (atomic_compare_exchange_acquire(&amp;futex, NOT_ACQUIRED, ACQUIRED)<br />&gt;         == SUCCESS)<br />&gt;       return;<br />&gt;     // slow path: signal that there is a slow-path waiter and block<br />&gt;     prev = atomic_exchange(&amp;futex, ACQUIRED_AND_WAITERS);<br />&gt;     if (prev == NOT_ACQUIRED) return;<br />&gt;     futex_wait(&amp;futex, ACQUIRED_AND_WAITERS, ...);<br />&gt;   }<br />&gt;<br />&gt; unlock():<br />&gt;   // fast path unlock<br />&gt;   prev = atomic_exchange_release(&amp;futex, NOT_ACQUIRED);<br />&gt;   // slow path unlock<br />&gt;   if (prev == ACQUIRED_AND_WAITERS)<br />&gt;     futex_wake(&amp;futex, ...);<br /><br />Yup.<br /><br />&gt; This means that in the second example above, futex_wake can be<br />&gt; concurrent with whatever happens on the mutex' memory location after the<br />&gt; mutex has been destroyed.  Examples are:<br />&gt;       * The memory is unmapped.  futex_wake will return an error.  OK.<br />&gt;       * The memory is reused, but not for a futex.  No thread will get<br />&gt;         woken.  OK.<br />&gt;       * The memory is reused for another glibc mutex.  The slow-path<br />&gt;         futex wake will now hit another, unrelated futex -- but the<br />&gt;         mutex implementation is robust to such spurious wake-ups anyway,<br />&gt;         because it can always happen when a mutex is acquired and<br />&gt;         released more than once.  OK.<br />&gt;       * The memory is reused for another futex in some custom data<br />&gt;         structure that expects there is just one wait/wake cycle, and<br />&gt;         relies on  FUTEX_WAIT returning 0 to mean that this is caused by<br />&gt;         the matching FUTEX_WAKE call by *this* data structure.  Not OK,<br />&gt;         because now the delayed slow-path wake-up introduces a spurious<br />&gt;         wake-up in an unrelated futex.<br />&gt;<br />&gt; Thus, introducing spurious wake-ups is the core issue.<br /><br />So my gut feeling is that we should just try to see if we can live<br />with spurious wakeups, ie your:<br /><br />&gt; (1)  Allow spurious wake-ups from FUTEX_WAIT.<br /><br />because afaik that is what we actually *do* today (we'll wake up<br />whoever re-used that location in another thread), and it's mainly<br />about the whole documentation issue. No?<br /><br />                      Linus<br /><br /><br /></pre><div align="center"><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></div></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerr.gif" width="32" height="32" alt="\" /></td></tr><tr><td align="right" valign="bottom">
