    </div></td><td width="32">Â </td></tr><tr><td valign="top"><div class="es-jasper-simpleCalendar" baseurl="/lkml/"></div><div class="threadlist">Messages in this thread</div><ul class="threadlist"><li class="root"><a href="/lkml/2003/12/27/73">First message in thread</a></li><li><a href="/lkml/2003/12/27/135">Linus Torvalds</a><ul><li><a href="/lkml/2003/12/28/41">William Lee Irwin III</a><ul><li><a href="/lkml/2003/12/28/109">Mike Fedyk</a><ul><li><a href="/lkml/2003/12/28/125">William Lee Irwin III</a><ul><li><a href="/lkml/2003/12/28/135">Linus Torvalds</a></li></ul></li></ul></li></ul></li><li><a href="/lkml/2003/12/29/184">(Eric W. Biederman)</a><ul><li class="origin"><a href="">Linus Torvalds</a></li></ul></li></ul></li></ul></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerl.gif" width="32" height="32" alt="/" /></td><td class="c" rowspan="2" valign="top" style="padding-top: 1em"><table><tr><td colspan="2"><!--BuySellAds Zone Code--><div id="bsap_1297613" class="bsarocks bsap_5aa49c00cc06c882289a1dd6a5e50b62"></div><!--End BuySellAds Zone Code--></td></tr><tr><td><table><tr><td class="lp">Date</td><td class="rp" itemprop="datePublished">Mon, 29 Dec 2003 13:35:58 -0800 (PST)</td></tr><tr><td class="lp">From</td><td class="rp" itemprop="author">Linus Torvalds &lt;&gt;</td></tr><tr><td class="lp">Subject</td><td class="rp" itemprop="name">Re: Page Colouring (was: 2.6.0 Huge pages not working as expected)</td></tr></table></td><td><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></td></tr></table><pre itemprop="articleBody"><br /><br />On Mon, 29 Dec 2003, Eric W. Biederman wrote:<br />&gt;<br />&gt; Linus Torvalds &lt;torvalds&#64;osdl.org&gt; writes:<br />&gt; &gt; <br />&gt; &gt; Why? Because the fact is, that as memory gets further and further away <br />&gt; &gt; from CPU's, caches have gotten further and further away from being direct <br />&gt; &gt; mapped. <br />&gt; <br />&gt; Except for L1 caches.  The hit of an associate lookup there is inherently<br />&gt; costly.<br /><br />Having worked for a hardware company, and talked to hardware engineers, I <br />can say that it generally isn't all that true.<br /><br />The reason is that you can start the lookup before you even do the TLB <br />lookup, and in fact you _want_ highly associative L1 caches to do that.<br /><br />For example, if you have a 16kB L1 cache, and a 4kB page size, and you<br />want your memory accesses to go fast, you definitely want to index the L1<br />by the virtual access, which means that you can only use the low 12 bits<br />for indexing.<br /><br />So what you do is you make your L1 be 4-way set-associative, so that by <br />the time the TLB lookup is done, you've already looked up the index, and <br />you only have to compare the TAG with one of the four possible ways.<br /><br />In short: you actually _want_ your L1 to be associative, because it's the <br />best way to avoid having nasty alias issues.<br /><br />The only people who have a direct-mapped L1 are one of:<br /> - crazy and/or stupid<br /> - really cheap (mainly embedded space)<br /> - not high-performance anyway (ie their L1 is really small)<br /> - really sorry, and are fixing it.<br /> - really _really_ sorry, and have a virtually indexed cache. In which <br />   case page coloring doesn't matter anyway.<br /><br />Notice how high performance is _not_ on the list. Because you simply can't <br />_get_ high performance with a direct-mapped L1. Those days are long gone.<br /><br />There is another reason why L1's have long since moved away from<br />direct-mapped: the miss ratio goes up quote a bit for the same size cache.  <br />And things like OoO are pretty good at hiding one cycle of latency (OoO is<br />_not_ good at hiding memory latency, but one or two cycles are usually<br />ok), so even if having a larger L1 (and thus inherently more complex - not<br />only in associativity) means that you end up having an extra cycle access,<br />it's likely a win.<br /><br />This is, for example, what alpha did between 21164 and the 21264: when<br />they went out-of-order, they did all the simulation to prove that it was<br />much more efficient to have a larger L1 with a higher hit ratio, even if<br />the latency was one cycle higher than the 21164 which was strictly<br />in-order.<br /><br />In short, I'll bet you a dollar that you won't see a single direct-mapped <br />L1 _anywhere_ where it matters. They are already pretty much gone. Can you <br />name one that doesn't fit the four criteria above?<br /><br />		Linus<br />-<br />To unsubscribe from this list: send the line "unsubscribe linux-kernel" in<br />the body of a message to majordomo&#64;vger.kernel.org<br />More majordomo info at  <a href="http://vger.kernel.org/majordomo-info.html">http://vger.kernel.org/majordomo-info.html</a><br />Please read the FAQ at  <a href="http://www.tux.org/lkml/">http://www.tux.org/lkml/</a><br /><br /></pre><div align="center"><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></div></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerr.gif" width="32" height="32" alt="\" /></td></tr><tr><td align="right" valign="bottom">
