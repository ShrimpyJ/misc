    </div></td><td width="32">Â </td></tr><tr><td valign="top"><div class="es-jasper-simpleCalendar" baseurl="/lkml/"></div><div class="threadlist">Messages in this thread</div><ul class="threadlist"><li class="root"><a href="/lkml/2012/11/22/263">First message in thread</a></li><li><a href="/lkml/2012/11/22/374">Ingo Molnar</a><ul><li><a href="/lkml/2012/12/3/540">David Rientjes</a><ul><li class="origin"><a href="/lkml/2012/12/20/450">Linus Torvalds</a><ul><li><a href="/lkml/2012/12/20/450">David Rientjes</a><ul><li><a href="/lkml/2012/12/21/172">Mel Gorman</a></li></ul></li></ul></li></ul></li></ul></li></ul></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerl.gif" width="32" height="32" alt="/" /></td><td class="c" rowspan="2" valign="top" style="padding-top: 1em"><table><tr><td colspan="2"><!--BuySellAds Zone Code--><div id="bsap_1297613" class="bsarocks bsap_5aa49c00cc06c882289a1dd6a5e50b62"></div><!--End BuySellAds Zone Code--></td></tr><tr><td><table><tr><td class="lp">From</td><td class="rp" itemprop="author">Linus Torvalds &lt;&gt;</td></tr><tr><td class="lp">Date</td><td class="rp" itemprop="datePublished">Thu, 20 Dec 2012 10:34:25 -0800</td></tr><tr><td class="lp">Subject</td><td class="rp" itemprop="name">Re: [patch] mm, mempolicy: Introduce spinlock to read shared policy tree</td></tr></table></td><td><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></td></tr></table><pre itemprop="articleBody">Going through some old emails before -rc1 rlease..<br /><br />What is the status of this patch? The patch that is reported to cause<br />the problem hasn't been merged, but that mpol_misplaced() thing did<br />happen in commit 771fb4d806a9. And it looks like it's called from<br />numa_migrate_prep() under the pte map lock. Or am I missing something?<br />See commit 9532fec118d ("mm: numa: Migrate pages handled during a<br />pmd_numa hinting fault").<br /><br />Am I missing something? Mel, please take another look.<br /><br />I despise these kinds of dual-locking models, and am wondering if we<br />can't have *just* the spinlock?<br /><br />            Linus<br /><br />On Mon, Dec 3, 2012 at 4:56 PM, David Rientjes &lt;rientjes&#64;google.com&gt; wrote:<br />&gt; From: Peter Zijlstra &lt;a.p.zijlstra&#64;chello.nl&gt;<br />&gt;<br />&gt; Sasha was fuzzing with trinity and reported the following problem:<br />&gt;<br />&gt; BUG: sleeping function called from invalid context at kernel/mutex.c:269<br />&gt; in_atomic(): 1, irqs_disabled(): 0, pid: 6361, name: trinity-main<br />&gt; 2 locks held by trinity-main/6361:<br />&gt;  #0:  (&amp;mm-&gt;mmap_sem){++++++}, at: [&lt;ffffffff810aa314&gt;] __do_page_fault+0x1e4/0x4f0<br />&gt;  #1:  (&amp;(&amp;mm-&gt;page_table_lock)-&gt;rlock){+.+...}, at: [&lt;ffffffff8122f017&gt;] handle_pte_fault+0x3f7/0x6a0<br />&gt; Pid: 6361, comm: trinity-main Tainted: G        W 3.7.0-rc2-next-20121024-sasha-00001-gd95ef01-dirty #74<br />&gt; Call Trace:<br />&gt;  [&lt;ffffffff8114e393&gt;] __might_sleep+0x1c3/0x1e0<br />&gt;  [&lt;ffffffff83ae5209&gt;] mutex_lock_nested+0x29/0x50<br />&gt;  [&lt;ffffffff8124fc3e&gt;] mpol_shared_policy_lookup+0x2e/0x90<br />&gt;  [&lt;ffffffff81219ebe&gt;] shmem_get_policy+0x2e/0x30<br />&gt;  [&lt;ffffffff8124e99a&gt;] get_vma_policy+0x5a/0xa0<br />&gt;  [&lt;ffffffff8124fce1&gt;] mpol_misplaced+0x41/0x1d0<br />&gt;  [&lt;ffffffff8122f085&gt;] handle_pte_fault+0x465/0x6a0<br />&gt;<br />&gt; do_numa_page() calls the new mpol_misplaced() function introduced by<br />&gt; "sched, numa, mm: Add the scanning page fault machinery" in the page fault<br />&gt; patch while holding mm-&gt;page_table_lock and then<br />&gt; mpol_shared_policy_lookup() ends up trying to take the shared policy<br />&gt; mutex.<br />&gt;<br />&gt; The fix is to protect the shared policy tree with both a spinlock and<br />&gt; mutex; both must be held to modify the tree, but only one is required to<br />&gt; read the tree.  This allows sp_lookup() to grab the spinlock for read.<br />&gt;<br />&gt; [rientjes&#64;google.com: wrote changelog]<br />&gt; Reported-by: Sasha Levin &lt;levinsasha928&#64;gmail.com&gt;<br />&gt; Tested-by: Sasha Levin &lt;levinsasha928&#64;gmail.com&gt;<br />&gt; Signed-off-by: David Rientjes &lt;rientjes&#64;google.com&gt;<br />&gt; ---<br />&gt;  include/linux/mempolicy.h |    1 +<br />&gt;  mm/mempolicy.c            |   23 ++++++++++++++++++-----<br />&gt;  2 files changed, 19 insertions(+), 5 deletions(-)<br />&gt;<br />&gt; diff --git a/include/linux/mempolicy.h b/include/linux/mempolicy.h<br />&gt; --- a/include/linux/mempolicy.h<br />&gt; +++ b/include/linux/mempolicy.h<br />&gt; &#64;&#64; -133,6 +133,7 &#64;&#64; struct sp_node {<br />&gt;<br />&gt;  struct shared_policy {<br />&gt;         struct rb_root root;<br />&gt; +       spinlock_t lock;<br />&gt;         struct mutex mutex;<br />&gt;  };<br />&gt;<br />&gt; diff --git a/mm/mempolicy.c b/mm/mempolicy.c<br />&gt; --- a/mm/mempolicy.c<br />&gt; +++ b/mm/mempolicy.c<br />&gt; &#64;&#64; -2090,12 +2090,20 &#64;&#64; bool __mpol_equal(struct mempolicy *a, struct mempolicy *b)<br />&gt;   *<br />&gt;   * Remember policies even when nobody has shared memory mapped.<br />&gt;   * The policies are kept in Red-Black tree linked from the inode.<br />&gt; - * They are protected by the sp-&gt;lock spinlock, which should be held<br />&gt; - * for any accesses to the tree.<br />&gt; + *<br />&gt; + * The rb-tree is locked using both a mutex and a spinlock. Every modification<br />&gt; + * to the tree must hold both the mutex and the spinlock, lookups can hold<br />&gt; + * either to observe a stable tree.<br />&gt; + *<br />&gt; + * In particular, sp_insert() and sp_delete() take the spinlock, whereas<br />&gt; + * sp_lookup() doesn't, this so users have choice.<br />&gt; + *<br />&gt; + * shared_policy_replace() and mpol_free_shared_policy() take the mutex<br />&gt; + * and call sp_insert(), sp_delete().<br />&gt;   */<br />&gt;<br />&gt;  /* lookup first element intersecting start-end */<br />&gt; -/* Caller holds sp-&gt;mutex */<br />&gt; +/* Caller holds either sp-&gt;lock and/or sp-&gt;mutex */<br />&gt;  static struct sp_node *<br />&gt;  sp_lookup(struct shared_policy *sp, unsigned long start, unsigned long end)<br />&gt;  {<br />&gt; &#64;&#64; -2134,6 +2142,7 &#64;&#64; static void sp_insert(struct shared_policy *sp, struct sp_node *new)<br />&gt;         struct rb_node *parent = NULL;<br />&gt;         struct sp_node *nd;<br />&gt;<br />&gt; +       spin_lock(&amp;sp-&gt;lock);<br />&gt;         while (*p) {<br />&gt;                 parent = *p;<br />&gt;                 nd = rb_entry(parent, struct sp_node, nd);<br />&gt; &#64;&#64; -2146,6 +2155,7 &#64;&#64; static void sp_insert(struct shared_policy *sp, struct sp_node *new)<br />&gt;         }<br />&gt;         rb_link_node(&amp;new-&gt;nd, parent, p);<br />&gt;         rb_insert_color(&amp;new-&gt;nd, &amp;sp-&gt;root);<br />&gt; +       spin_unlock(&amp;sp-&gt;lock);<br />&gt;         pr_debug("inserting %lx-%lx: %d\n", new-&gt;start, new-&gt;end,<br />&gt;                  new-&gt;policy ? new-&gt;policy-&gt;mode : 0);<br />&gt;  }<br />&gt; &#64;&#64; -2159,13 +2169,13 &#64;&#64; mpol_shared_policy_lookup(struct shared_policy *sp, unsigned long idx)<br />&gt;<br />&gt;         if (!sp-&gt;root.rb_node)<br />&gt;                 return NULL;<br />&gt; -       mutex_lock(&amp;sp-&gt;mutex);<br />&gt; +       spin_lock(&amp;sp-&gt;lock);<br />&gt;         sn = sp_lookup(sp, idx, idx+1);<br />&gt;         if (sn) {<br />&gt;                 mpol_get(sn-&gt;policy);<br />&gt;                 pol = sn-&gt;policy;<br />&gt;         }<br />&gt; -       mutex_unlock(&amp;sp-&gt;mutex);<br />&gt; +       spin_unlock(&amp;sp-&gt;lock);<br />&gt;         return pol;<br />&gt;  }<br />&gt;<br />&gt; &#64;&#64; -2178,8 +2188,10 &#64;&#64; static void sp_free(struct sp_node *n)<br />&gt;  static void sp_delete(struct shared_policy *sp, struct sp_node *n)<br />&gt;  {<br />&gt;         pr_debug("deleting %lx-l%lx\n", n-&gt;start, n-&gt;end);<br />&gt; +       spin_lock(&amp;sp-&gt;lock);<br />&gt;         rb_erase(&amp;n-&gt;nd, &amp;sp-&gt;root);<br />&gt;         sp_free(n);<br />&gt; +       spin_unlock(&amp;sp-&gt;lock);<br />&gt;  }<br />&gt;<br />&gt;  static struct sp_node *sp_alloc(unsigned long start, unsigned long end,<br />&gt; &#64;&#64; -2264,6 +2276,7 &#64;&#64; void mpol_shared_policy_init(struct shared_policy *sp, struct mempolicy *mpol)<br />&gt;         int ret;<br />&gt;<br />&gt;         sp-&gt;root = RB_ROOT;             /* empty tree == default mempolicy */<br />&gt; +       spin_lock_init(&amp;sp-&gt;lock);<br />&gt;         mutex_init(&amp;sp-&gt;mutex);<br />&gt;<br />&gt;         if (mpol) {<br /><br /><br /></pre><div align="center"><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></div></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerr.gif" width="32" height="32" alt="\" /></td></tr><tr><td align="right" valign="bottom">
