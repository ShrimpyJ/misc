    </div></td><td width="32">Â </td></tr><tr><td valign="top"><div class="es-jasper-simpleCalendar" baseurl="/lkml/"></div><div class="threadlist">Messages in this thread</div><ul class="threadlist"><li class="root"><a href="/lkml/2016/12/19/416">First message in thread</a></li><li><a href="/lkml/2016/12/21/225">"Jason A. Donenfeld"</a><ul><li><a href="/lkml/2016/12/21/296">"George Spelvin"</a><ul><li><a href="/lkml/2016/12/21/306">"Jason A. Donenfeld"</a></li><li><a href="/lkml/2016/12/21/313">Rik van Riel</a></li><li class="origin"><a href="/lkml/2016/12/21/367">Linus Torvalds</a><ul><li><a href="/lkml/2016/12/21/367">"George Spelvin"</a></li><li><a href="/lkml/2016/12/21/581">Andy Lutomirski</a></li></ul></li></ul></li></ul></li></ul></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerl.gif" width="32" height="32" alt="/" /></td><td class="c" rowspan="2" valign="top" style="padding-top: 1em"><table><tr><td colspan="2"><!--BuySellAds Zone Code--><div id="bsap_1297613" class="bsarocks bsap_5aa49c00cc06c882289a1dd6a5e50b62"></div><!--End BuySellAds Zone Code--></td></tr><tr><td><table><tr><td class="lp">From</td><td class="rp" itemprop="author">Linus Torvalds &lt;&gt;</td></tr><tr><td class="lp">Date</td><td class="rp" itemprop="datePublished">Wed, 21 Dec 2016 09:25:01 -0800</td></tr><tr><td class="lp">Subject</td><td class="rp" itemprop="name">Re: HalfSipHash Acceptable Usage</td></tr></table></td><td><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></td></tr></table><pre itemprop="articleBody">On Wed, Dec 21, 2016 at 7:55 AM, George Spelvin<br />&lt;linux&#64;sciencehorizons.net&gt; wrote:<br />&gt;<br />&gt; How much does kernel_fpu_begin()/kernel_fpu_end() cost?<br /><br />It's now better than it used to be, but it's absolutely disastrous<br />still. We're talking easily many hundreds of cycles. Under some loads,<br />thousands.<br /><br />And I warn you already: it will _benchmark_ a hell of a lot better<br />than it will work in reality. In benchmarks, you'll hit all the<br />optimizations ("oh, I've already saved away all the FP registers, no<br />need to do it again").<br /><br />In contrast, in reality, especially with things like "do it once or<br />twice per incoming packet", you'll easily hit the absolute worst<br />cases, where not only does it take a few hundred cycles to save the FP<br />state, you'll then return to user space in between packets, which<br />triggers the slow-path return code and reloads the FP state, which is<br />another few hundred cycles plus.<br /><br />Similarly, in benchmarks you'll hit the "modern CPU's power on the AVX<br />unit and keep it powered up for a while afterwards", while in real<br />life you would quite easily hit the "oh, AVX is powered down because<br />we were idle, now it powers up at half speed which is another latency<br />hit _and_ the AVX unit won't run full out anyway".<br /><br />Don't do it. There are basically no real situations where the AVX<br />state optimizations help for the kernel. We just don't have the loop<br />counts to make up for the problems it causes.<br /><br />The one exception is likely if you're doing things like<br />high-throughput disk IO encryption, and then you'd be much better off<br />using SHA256 instead (which often has hw encryption on modern CPU's -<br />both x86 and ARM).<br /><br />(I'm sure that you could see it on some high-throughput network<br />benchmark too when the benchmark entirely saturates the CPU. And then<br />in real life it would suck horribly for all the reasons above).<br /><br />                Linus<br /><br /></pre><div align="center"><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></div></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerr.gif" width="32" height="32" alt="\" /></td></tr><tr><td align="right" valign="bottom">
