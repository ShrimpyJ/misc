    </div></td><td width="32">Â </td></tr><tr><td valign="top"><div class="es-jasper-simpleCalendar" baseurl="/lkml/"></div><div class="threadlist">Messages in this thread</div><ul class="threadlist"><li class="root"><a href="/lkml/2016/11/21/748">First message in thread</a></li><li><a href="/lkml/2016/11/29/751">Linus Torvalds</a><ul><li><a href="/lkml/2016/11/30/545">Marc MERLIN</a><ul><li class="origin"><a href="/lkml/2016/11/30/565">Linus Torvalds</a><ul><li><a href="/lkml/2016/11/30/565">Marc MERLIN</a></li><li><a href="/lkml/2016/11/30/569">Jens Axboe</a></li><li><a href="/lkml/2016/11/30/631">Tejun Heo</a><ul><li><a href="/lkml/2016/12/1/310">Kent Overstreet</a></li></ul></li></ul></li></ul></li></ul></li></ul><div class="threadlist">Patch in this message</div><ul class="threadlist"><li><a href="/lkml/diff/2016/11/30/560/1">Get diff 1</a></li></ul></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerl.gif" width="32" height="32" alt="/" /></td><td class="c" rowspan="2" valign="top" style="padding-top: 1em"><table><tr><td colspan="2"><!--BuySellAds Zone Code--><div id="bsap_1297613" class="bsarocks bsap_5aa49c00cc06c882289a1dd6a5e50b62"></div><!--End BuySellAds Zone Code--></td></tr><tr><td><table><tr><td class="lp">From</td><td class="rp" itemprop="author">Linus Torvalds &lt;&gt;</td></tr><tr><td class="lp">Date</td><td class="rp" itemprop="datePublished">Wed, 30 Nov 2016 10:14:50 -0800</td></tr><tr><td class="lp">Subject</td><td class="rp" itemprop="name">Re: 4.8.8 kernel trigger OOM killer repeatedly when I have lots of RAM that should be free</td></tr></table></td><td><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></td></tr></table><pre itemprop="articleBody">On Wed, Nov 30, 2016 at 9:47 AM, Marc MERLIN &lt;marc&#64;merlins.org&gt; wrote:<br />&gt;<br />&gt; I gave it a thought again, I think it is exactly the nasty situation you<br />&gt; described.<br />&gt; bcache takes I/O quickly while sending to SSD cache. SSD fills up, now<br />&gt; bcache can't handle IO as quickly and has to hang until the SSD has been<br />&gt; flushed to spinning rust drives.<br />&gt; This actually is exactly the same as filling up the cache on a USB key<br />&gt; and now you're waiting for slow writes to flash, is it not?<br /><br />It does sound like you might hit exactly the same kind of situation, yes.<br /><br />And the fact that you have dmcrypt running too just makes things pile<br />up more. All those IO's end up slowed down by the scheduling too.<br /><br />Anyway, none of this seems new per se. I'm adding Kent and Jens to the<br />cc (Tejun already was), in the hope that maybe they have some idea how<br />to control the nasty worst-case behavior wrt workqueue lockup (it's<br />not really a "lockup", it looks like it's just hundreds of workqueues<br />all waiting for IO to complete and much too deep IO queues).<br /><br />I think it's the traditional "throughput is much easier to measure and<br />improve" situation, where making queues big help some throughput<br />situation, but ends up causing chaos when things go south.<br /><br />And I think your NMI watchdog then turns the "system is no longer<br />responsive" into an actual kernel panic.<br /><br />&gt; With your dirty ratio workaround, I was able to re-enable bcache and<br />&gt; have it not fall over, but only barely. I recorded over a hundred<br />&gt; workqueues in flight during the copy at some point (just not enough<br />&gt; to actually kill the kernel this time).<br />&gt;<br />&gt; I've started a bcache followp on this here:<br />&gt; <a href="https://marc.info/?l=linux-bcache&amp;m=148052441423532&amp;w=2">http://marc.info/?l=linux-bcache&amp;m=148052441423532&amp;w=2</a><br />&gt; <a href="https://marc.info/?l=linux-bcache&amp;m=148052620524162&amp;w=2">http://marc.info/?l=linux-bcache&amp;m=148052620524162&amp;w=2</a><br />&gt;<br />&gt; A full traceback showing the pilup of requests is here:<br />&gt; <a href="https://marc.info/?l=linux-bcache&amp;m=147949497808483&amp;w=2">http://marc.info/?l=linux-bcache&amp;m=147949497808483&amp;w=2</a><br />&gt;<br />&gt; and there:<br />&gt; <a href="https://pastebin.com/rJ5RKUVm">http://pastebin.com/rJ5RKUVm</a><br />&gt; (2 different ones but mostly the same result)<br /><br />Tejun/Kent - any way to just limit the workqueue depth for bcache?<br />Because that really isn't helping, and things *will* time out and<br />cause those problems when you have hundreds of IO's queued on a disk<br />that likely as a write iops around ~100..<br /><br />And I really wonder if we should do the "big hammer" approach to the<br />dirty limits on non-HIGHMEM machines too (approximate the<br />"vm_highmem_is_dirtyable" by just limiting global_dirtyable_memory()<br />to 1 GB).<br /><br />That would make the default dirty limits be 100/200MB (for soft/hard<br />throttling), which really is much more reasonable than gigabytes and<br />gigabytes of dirty data.<br /><br />Of course, no way do we do that during rc7..<br /><br />                    Linus<br /> mm/page-writeback.c | 9 ++++++++-<br /> 1 file changed, 8 insertions(+), 1 deletion(-)<br /><br />diff --git a/mm/page-writeback.c b/mm/page-writeback.c<br />index 439cc63ad903..26ecbdecb815 100644<br />--- a/mm/page-writeback.c<br />+++ b/mm/page-writeback.c<br />&#64;&#64; -352,6 +352,10 &#64;&#64; static unsigned long highmem_dirtyable_memory(unsigned long total)<br /> #endif<br /> }<br /> <br />+/* Limit dirtyable memory to 1GB */<br />+#define PAGES_IN_GB(x) ((x) &lt;&lt; (30 - PAGE_SHIFT))<br />+#define MAX_DIRTYABLE_LOWMEM_PAGES PAGES_IN_GB(1)<br />+<br /> /**<br />  * global_dirtyable_memory - number of globally dirtyable pages<br />  *<br />&#64;&#64; -373,8 +377,11 &#64;&#64; static unsigned long global_dirtyable_memory(void)<br /> 	x += global_node_page_state(NR_INACTIVE_FILE);<br /> 	x += global_node_page_state(NR_ACTIVE_FILE);<br /> <br />-	if (!vm_highmem_is_dirtyable)<br />+	if (!vm_highmem_is_dirtyable) {<br /> 		x -= highmem_dirtyable_memory(x);<br />+		if (x &gt; MAX_DIRTYABLE_LOWMEM_PAGES)<br />+			x = MAX_DIRTYABLE_LOWMEM_PAGES;<br />+	}<br /> <br /> 	return x + 1;	/* Ensure that we never return 0 */<br /> }</pre><div align="center"><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></div></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerr.gif" width="32" height="32" alt="\" /></td></tr><tr><td align="right" valign="bottom">
