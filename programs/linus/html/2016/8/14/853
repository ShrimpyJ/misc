    </div></td><td width="32">Â </td></tr><tr><td valign="top"><div class="es-jasper-simpleCalendar" baseurl="/lkml/"></div><div class="threadlist">Messages in this thread</div><ul class="threadlist"><li class="root"><a href="/lkml/2016/8/9/440">First message in thread</a></li><li><a href="/lkml/2016/8/12/429">Linus Torvalds</a><ul><li><a href="/lkml/2016/8/14/38">Fengguang Wu</a></li><li><a href="/lkml/2016/8/14/850">Dave Chinner</a><ul><li class="origin"><a href="/lkml/2016/8/14/862">Linus Torvalds</a><ul><li><a href="/lkml/2016/8/14/862">Dave Chinner</a><ul><li><a href="/lkml/2016/8/14/867">Linus Torvalds</a></li></ul></li></ul></li></ul></li><li><a href="/lkml/2016/8/15/247">Fengguang Wu</a></li></ul></li></ul></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerl.gif" width="32" height="32" alt="/" /></td><td class="c" rowspan="2" valign="top" style="padding-top: 1em"><table><tr><td colspan="2"><!--BuySellAds Zone Code--><div id="bsap_1297613" class="bsarocks bsap_5aa49c00cc06c882289a1dd6a5e50b62"></div><!--End BuySellAds Zone Code--></td></tr><tr><td><table><tr><td class="lp">From</td><td class="rp" itemprop="author">Linus Torvalds &lt;&gt;</td></tr><tr><td class="lp">Date</td><td class="rp" itemprop="datePublished">Sun, 14 Aug 2016 18:37:33 -0700</td></tr><tr><td class="lp">Subject</td><td class="rp" itemprop="name">Re: [LKP] [lkp] [xfs] 68a9f5e700: aim7.jobs-per-min -13.6% regression</td></tr></table></td><td><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></td></tr></table><pre itemprop="articleBody">On Sun, Aug 14, 2016 at 5:48 PM, Dave Chinner &lt;david&#64;fromorbit.com&gt; wrote:<br />&gt;&gt;<br />&gt;&gt; Does this attached patch help your contention numbers?<br />&gt;<br />&gt; No. If anything, it makes it worse. Without the patch, I was<br />&gt; measuring 36-37% in _raw_spin_unlock_irqrestore. With the patch, it<br />&gt; is 42-43%. Write throughtput is the same at ~505MB/s.<br /><br />Not helping any I can see, but I don't see how it could hurt...<br /><br />Did you perhaps test it together with the other patches that improved<br />xfs performance? If other things improve, then I'd expect the<br />contention to get worse.<br /><br />Not that it matters. Clearly that patch isn't even a stop-gap solution.<br /><br />&gt; There's a couple of interesting things showing up in the profile:<br />&gt;<br />&gt;   41.64%  [kernel]  [k] _raw_spin_unlock_irqrestore<br /><br />Actually, you didn't point this one out, but *this* is the real kicker.<br /><br />There's no way a *unlock* should show up that high. It's not spinning.<br />It's doing a single store and a pushq/popfq sequence.<br /><br />Sure, it's going to take a cross-node cachemiss in the presence of<br />contention, but even then it should never be more expensive than the<br />locking side - which will *also* do the node changes.<br /><br />So there's something really odd in your profile. I don't think that's valid.<br /><br />Maybe your symbol table came from a old kernel, and functions moved<br />around enough that the profile attributions ended up bogus.<br /><br />I suspect it's actually supposed to be _raw_spin_lock_irqrestore()<br />which is right next to that function. Although I'd actually expect<br />that if it's lock contention, you should see the contention mostly in<br />queued_spin_lock_slowpath().<br /><br />Unless you have spinlock debugging turned on, in which case your<br />contention is all from *that*. That's possible, of course.<br /><br />&gt;    7.92%  [kernel]  [k] copy_user_generic_string<br />&gt;    5.87%  [kernel]  [k] _raw_spin_unlock_irq<br />&gt;    3.18%  [kernel]  [k] do_raw_spin_lock<br />&gt;    2.51%  [kernel]  [k] cancel_dirty_page         &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;<br />...<br />&gt; Why are we even calling into cancel_dirty_page() if the page isn't<br />&gt; dirty? xfs_vm_release_page() won't let dirty pages through to<br />&gt; try_to_free_buffers(), so all this is just pure overhead for XFS.<br /><br />See above: there's something screwy with your profile, you should<br />check that first. Maybe it's not actually cancel_dirty_page() but<br />something close-by.<br /><br />(Although I don't see anything closeby normally, so even if the<br />spin_unlock_irq is bogus, I think *that* part may be incorrect.<br /><br />Anyway, the reason you'd get cancel_dirty_page() is either due to<br />truncate, or due to try_to_free_buffers() having dropped the buffers<br />successfully because the filesystem had already written them out, but<br />the page is still marked dirty.<br /><br />&gt; FWIW, this is not under the mapping-&gt;tree_lock, but the profile shows<br />&gt; that reclaiming bufferheads is roughly 20% of all the work kswapd is<br />&gt; doing.<br /><br />Well, that may not actually be wrong. That's the most expensive part<br />of reclaiming memory.<br /><br />But please double-check your profile, because something is seriously<br />wrong in it.<br /><br />            Linus<br /><br /></pre><div align="center"><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></div></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerr.gif" width="32" height="32" alt="\" /></td></tr><tr><td align="right" valign="bottom">
