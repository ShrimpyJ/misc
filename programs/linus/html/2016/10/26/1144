    </div></td><td width="32">Â </td></tr><tr><td valign="top"><div class="es-jasper-simpleCalendar" baseurl="/lkml/"></div><div class="threadlist">Messages in this thread</div><ul class="threadlist"><li class="root"><a href="/lkml/2016/10/11/389">First message in thread</a></li><li><a href="/lkml/2016/10/26/958">Linus Torvalds</a><ul><li><a href="/lkml/2016/10/26/1025">Chris Mason</a><ul><li><a href="/lkml/2016/10/26/1135">Chris Mason</a><ul><li><a href="/lkml/2016/10/26/1156">Linus Torvalds</a><ul><li><a href="/lkml/2016/10/26/1165">Dave Jones</a></li></ul></li></ul></li><li class="origin"><a href="/lkml/2016/10/26/1189">Linus Torvalds</a><ul><li><a href="/lkml/2016/10/26/1189">Chris Mason</a></li></ul></li></ul></li></ul></li></ul></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerl.gif" width="32" height="32" alt="/" /></td><td class="c" rowspan="2" valign="top" style="padding-top: 1em"><table><tr><td colspan="2"><!--BuySellAds Zone Code--><div id="bsap_1297613" class="bsarocks bsap_5aa49c00cc06c882289a1dd6a5e50b62"></div><!--End BuySellAds Zone Code--></td></tr><tr><td><table><tr><td class="lp">From</td><td class="rp" itemprop="author">Linus Torvalds &lt;&gt;</td></tr><tr><td class="lp">Date</td><td class="rp" itemprop="datePublished">Wed, 26 Oct 2016 15:07:10 -0700</td></tr><tr><td class="lp">Subject</td><td class="rp" itemprop="name">Re: bio linked list corruption.</td></tr></table></td><td><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></td></tr></table><pre itemprop="articleBody">On Wed, Oct 26, 2016 at 1:00 PM, Chris Mason &lt;clm&#64;fb.com&gt; wrote:<br />&gt;<br />&gt; Today I turned off every CONFIG_DEBUG_* except for list debugging, and<br />&gt; ran dbench 2048:<br />&gt;<br />&gt; [ 2759.118711] WARNING: CPU: 2 PID: 31039 at lib/list_debug.c:33 __list_add+0xbe/0xd0<br />&gt; [ 2759.119652] list_add corruption. prev-&gt;next should be next (ffffe8ffffc80308), but was ffffc90000ccfb88. (prev=ffff880128522380).<br />&gt; [ 2759.121039] Modules linked in: crc32c_intel i2c_piix4 aesni_intel aes_x86_64 virtio_net glue_helper i2c_core lrw floppy gf128mul serio_raw pcspkr button ablk_helper cryptd sch_fq_codel autofs4 virtio_blk<br />&gt; [ 2759.124369] CPU: 2 PID: 31039 Comm: dbench Not tainted 4.9.0-rc1-15246-g4ce9206-dirty #317<br />&gt; [ 2759.125077] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.9.0-1.fc24 04/01/2014<br />&gt; [ 2759.125077]  ffffc9000f6fb868 ffffffff814fe4ff ffffffff8151cb5e ffffc9000f6fb8c8<br />&gt; [ 2759.125077]  ffffc9000f6fb8c8 0000000000000000 ffffc9000f6fb8b8 ffffffff81064bbf<br />&gt; [ 2759.127444]  ffff880128523680 0000002139968000 ffff880138b7a4a0 ffff880128523540<br />&gt; [ 2759.127444] Call Trace:<br />&gt; [ 2759.127444]  [&lt;ffffffff814fe4ff&gt;] dump_stack+0x53/0x74<br />&gt; [ 2759.127444]  [&lt;ffffffff8151cb5e&gt;] ? __list_add+0xbe/0xd0<br />&gt; [ 2759.127444]  [&lt;ffffffff81064bbf&gt;] __warn+0xff/0x120<br />&gt; [ 2759.127444]  [&lt;ffffffff81064c99&gt;] warn_slowpath_fmt+0x49/0x50<br />&gt; [ 2759.127444]  [&lt;ffffffff8151cb5e&gt;] __list_add+0xbe/0xd0<br />&gt; [ 2759.127444]  [&lt;ffffffff814df338&gt;] blk_sq_make_request+0x388/0x580<br /><br />Ok, that's definitely the same one that Dave started out seeing.<br /><br />The fact that it is that reliable - two different machines, two very<br />different loads (dbench looks nothing like trinity) really makes me<br />think that maybe the problem really is in the block plugging after<br />all.<br /><br />It very much does not smell like random stack corruption. It's simply<br />not random enough.<br /><br />And I just noticed something: I originally thought that this is the<br />"list_add_tail()" to the plug - which is the only "list_add()" variant<br />in that function.<br /><br />But that never made sense, because the whole "but was" isn't a stack<br />address, and "next" in "list_add_tail()" is basically fixed, and would<br />have to be the stack.<br /><br />But I now notice that there's actually another "list_add()" variant<br />there, and it's the one from __blk_mq_insert_request() that gets<br />inlined into blk_mq_insert_request(), which then gets inlined into<br />blk_mq_make_request().<br /><br />And that actually makes some sense just looking at the offsets too:<br /><br />     blk_sq_make_request+0x388/0x580<br /><br />so it's somewhat at the end of blk_sq_make_request(). So it's not unlikely.<br /><br />And there it makes perfect sense that the "next should be" value is<br />*not* on the stack.<br /><br />Chris, if you built with debug info, you can try<br /><br />    ./scripts/faddr2line /boot/vmlinux blk_sq_make_request+0x388<br /><br />to get what line that blk_sq_make_request+0x388 address actually is. I<br />think it's the<br /><br />                list_add_tail(&amp;rq-&gt;queuelist, &amp;ctx-&gt;rq_list);<br /><br />in __blk_mq_insert_req_list() (when it's inlined from<br />blk_sq_make_request(), "at_head" will be false.<br /><br />So it smells like "&amp;ctx-&gt;rq_list" might be corrupt.<br /><br />And that actually seems much more likely than the "plug" list, because<br />while the plug is entirely thread-local (and thus shouldn't have any<br />races), the ctx-&gt;rq_list very much is not.<br /><br />Jens?<br /><br />For example, should we have a<br /><br />    BUG_ON(ctx != rq-&gt;mq_ctx);<br /><br />in blk_mq_merge_queue_io()? Because it locks ctx-&gt;lock, but then<br />__blk_mq_insert_request() will insert things onto the queues of<br />rq-&gt;mq_ctx.<br /><br />blk_mq_insert_requests() has similar issues, but there has that BUG_ON().<br /><br />The locking there really is *very* messy. All the lockers do<br /><br />        spin_lock(&amp;ctx-&gt;lock);<br />        ...<br />        spin_unlock(&amp;ctx-&gt;lock);<br /><br />but then __blk_mq_insert_request() and __blk_mq_insert_req_list don't<br />act on "ctx", but on "ctx = rq-&gt;mq_ctx", so if you ever get those<br />wrong, you're completely dead.<br /><br />Now, I'm not seeing why they'd be wrong, and why they'd be associated<br />with the VMAP_STACK thing, but it could just be an unlucky timing<br />thing.<br /><br />           Linus<br /><br /></pre><div align="center"><div class="shariff" data-services="[&quot;reddit&quot;]" data-theme="grey" data-lang="en" data-backend-url="//shariff.lkml.org/index.php"></div></div></td><td width="32" rowspan="2" class="c" valign="top"><img src="/images/icornerr.gif" width="32" height="32" alt="\" /></td></tr><tr><td align="right" valign="bottom">
